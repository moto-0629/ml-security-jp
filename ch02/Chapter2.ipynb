{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter2.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ivcg5OTwyTo"
      },
      "source": [
        "![表紙](https://www.oreilly.co.jp/books/images/picture978-4-87311-907-6.gif)\n",
        "\n",
        "このノートブックはオライリー・ジャパンより発行の書籍[『セキュリティエンジニアのための機械学習』](https://www.oreilly.co.jp/books/9784873119076/)のサンプルコードです。コードの解説等は書籍をご参照ください。なお、このコードを動作させた結果について、著者およびオライリー・ジャパンは一切の責任を負いません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU0KMWs5x3Z6"
      },
      "source": [
        "##ロジスティック回帰を使用したフィッシング検出器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfDbq4x8kAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a0a9b0-5f22-4e03-facf-06bd18178cac"
      },
      "source": [
        "!wget https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/dataset.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-22 09:19:26--  https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/dataset.csv [following]\n",
            "--2025-07-22 09:19:27--  https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788720 (770K) [text/plain]\n",
            "Saving to: ‘dataset.csv.1’\n",
            "\n",
            "dataset.csv.1       100%[===================>] 770.23K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-22 09:19:27 (21.9 MB/s) - ‘dataset.csv.1’ saved [788720/788720]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7hYR1Y2Ripa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f223d36d-625d-415d-d1bd-fa470c3d1d8a"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRGDVT7mYeh"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "training_data = np.genfromtxt('dataset.csv', delimiter=',', dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "scikit learn →　機械学習万能モジュール（すごく大きい）\n",
        "\n",
        "# 2値分類\n",
        "\n",
        " -  ２つの領域に分ける\n",
        " - True・false の判定\n",
        "\n"
      ],
      "metadata": {
        "id": "sfCjoN9IV9B0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aTvRm9-gAXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b580150-ea9a-4239-9866-ef9a6757700c"
      },
      "source": [
        "X = training_data[:,:-1]\n",
        "y = training_data[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "classifier = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "# 訓練用データを使って検出器を訓練する。\n",
        "classifier.fit(X_train, y_train)\n",
        "# 予測させる。\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# このフィッシング検出器の正解率を出力させる。\n",
        "accuracy = 100.0 * accuracy_score(y_test, predictions)\n",
        "print(\"The accuracy of your Logistic Regression on testing data is: {}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of your Logistic Regression on testing data is: 92.17548620533695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X, y, test_size=0.2 →学習用に２割使う\n"
      ],
      "metadata": {
        "id": "tJ05ezn_YL4H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTAgzVwU7G47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d36ed04-1646-4dd1-beee-c5ec81ddb171"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 交差検証(5分割)による汎化性能の評価\n",
        "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
        "# 評価結果の出力\n",
        "print(\"Evaluated score by cross-validation(k=5): {}\".format(100 * scores.mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated score by cross-validation(k=5): 92.8766156199402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "交差検証　→データを分割し、一部を学習に　残りをテストにする\n",
        "\n",
        "CV　分割数"
      ],
      "metadata": {
        "id": "oBP00CBRY9Mc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7kMWWXyxlQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa92deb8-e0c0-4d8c-c5db-10c28f53ce54"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "class Objective:\n",
        "    def __init__(self, X, y):\n",
        "        # 変数X,yの初期化\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # ターゲットのハイパーパラメータの設定\n",
        "        params = {\n",
        "            # 最適化に使用するアルゴリズムの候補をカテゴリとして指定\n",
        "            'solver' : trial.suggest_categorical('solver',\\\n",
        "                    ['newton-cg', 'lbfgs', \\\n",
        "                    'liblinear', 'sag', 'saga']),\n",
        "            # 正則化の強さに0.0001から10までを指定\n",
        "            'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
        "            # ソルバーが収束するまでの最大反復回数\n",
        "            'max_iter': trial.suggest_int('max_iter', 100, 100000)\n",
        "            }\n",
        "\n",
        "        model = LogisticRegression(**params)\n",
        "\n",
        "        # 評価指標として正解率の最大化を目指す\n",
        "        scores = cross_validate(model,\n",
        "                                X=self.X, y=self.y,\n",
        "                                scoring='accuracy',\n",
        "                                n_jobs=-1)\n",
        "        return scores['test_score'].mean()\n",
        "\n",
        "# ハイパーパラメータの探索\n",
        "objective = Objective(X_train, y_train)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, timeout=60)\n",
        "# ベストのパラメータの出力\n",
        "print('params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-15 09:56:07,000] A new study created in memory with name: no-name-86825dfd-546b-4acc-87d0-a43d776852f6\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:09,518] Trial 0 finished with value: 0.918702311554704 and parameters: {'solver': 'liblinear', 'C': 0.0018049340075545805, 'max_iter': 59199}. Best is trial 0 with value: 0.918702311554704.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:09,708] Trial 1 finished with value: 0.9266176022959517 and parameters: {'solver': 'lbfgs', 'C': 0.015480884455491095, 'max_iter': 23123}. Best is trial 1 with value: 0.9266176022959517.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:09,994] Trial 2 finished with value: 0.9295578195621423 and parameters: {'solver': 'liblinear', 'C': 0.07719026028917715, 'max_iter': 64386}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:10,320] Trial 3 finished with value: 0.9211898482922324 and parameters: {'solver': 'sag', 'C': 0.0023381503842627893, 'max_iter': 60367}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:10,720] Trial 4 finished with value: 0.9286530340274564 and parameters: {'solver': 'liblinear', 'C': 1.6258481513145295, 'max_iter': 95564}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:11,366] Trial 5 finished with value: 0.9292185169932651 and parameters: {'solver': 'sag', 'C': 0.6016721111484846, 'max_iter': 2789}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:11,656] Trial 6 finished with value: 0.9139535463704984 and parameters: {'solver': 'sag', 'C': 0.000793142763383418, 'max_iter': 43889}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:11,846] Trial 7 finished with value: 0.9113530153549441 and parameters: {'solver': 'liblinear', 'C': 0.00032732502982219246, 'max_iter': 23274}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:13,290] Trial 8 finished with value: 0.9280877429025269 and parameters: {'solver': 'saga', 'C': 3.4333786925564103, 'max_iter': 99402}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:13,710] Trial 9 finished with value: 0.9225469306738219 and parameters: {'solver': 'saga', 'C': 0.005910226360872148, 'max_iter': 24300}. Best is trial 2 with value: 0.9295578195621423.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:13,959] Trial 10 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1214778307489247, 'max_iter': 76653}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:14,186] Trial 11 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1300508138265035, 'max_iter': 76124}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:14,428] Trial 12 finished with value: 0.9296708777871283 and parameters: {'solver': 'newton-cg', 'C': 0.16447248601117248, 'max_iter': 80043}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:14,670] Trial 13 finished with value: 0.9297839360121142 and parameters: {'solver': 'newton-cg', 'C': 0.14114174979216274, 'max_iter': 72950}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:14,905] Trial 14 finished with value: 0.9289923365963336 and parameters: {'solver': 'newton-cg', 'C': 0.026622764264480934, 'max_iter': 84279}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:15,165] Trial 15 finished with value: 0.9291053948213195 and parameters: {'solver': 'newton-cg', 'C': 0.4850297524337857, 'max_iter': 44390}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:15,423] Trial 16 finished with value: 0.9292185169932651 and parameters: {'solver': 'newton-cg', 'C': 0.6012136332695373, 'max_iter': 86584}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:15,643] Trial 17 finished with value: 0.9295577556151826 and parameters: {'solver': 'lbfgs', 'C': 0.05797887544424285, 'max_iter': 72025}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:15,909] Trial 18 finished with value: 0.927974684677541 and parameters: {'solver': 'newton-cg', 'C': 9.863956897774132, 'max_iter': 52353}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:16,160] Trial 19 finished with value: 0.9292185169932651 and parameters: {'solver': 'newton-cg', 'C': 0.24070794040807264, 'max_iter': 71802}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:16,379] Trial 20 finished with value: 0.9252606478082818 and parameters: {'solver': 'newton-cg', 'C': 0.01102450523029241, 'max_iter': 89449}. Best is trial 10 with value: 0.9298969942371.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:16,608] Trial 21 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.09119527117049941, 'max_iter': 74881}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:16,837] Trial 22 finished with value: 0.9294446973901968 and parameters: {'solver': 'newton-cg', 'C': 0.05651505422820654, 'max_iter': 78573}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:17,067] Trial 23 finished with value: 0.9293316391652107 and parameters: {'solver': 'newton-cg', 'C': 0.033945219875754815, 'max_iter': 64580}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:17,258] Trial 24 finished with value: 0.8657854349288527 and parameters: {'solver': 'newton-cg', 'C': 0.0001097345970988454, 'max_iter': 93910}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:18,230] Trial 25 finished with value: 0.9286530979744161 and parameters: {'solver': 'saga', 'C': 1.6068076314062276, 'max_iter': 50350}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:18,462] Trial 26 finished with value: 0.9286531619213759 and parameters: {'solver': 'lbfgs', 'C': 0.2858623141638485, 'max_iter': 77174}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:18,704] Trial 27 finished with value: 0.924582170564447 and parameters: {'solver': 'newton-cg', 'C': 0.009106710948233919, 'max_iter': 37462}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:18,995] Trial 28 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.10884731179423959, 'max_iter': 69196}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:19,259] Trial 29 finished with value: 0.9219813837610532 and parameters: {'solver': 'newton-cg', 'C': 0.0030857655393648534, 'max_iter': 58421}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:19,509] Trial 30 finished with value: 0.9285399758024704 and parameters: {'solver': 'lbfgs', 'C': 0.023231557166445767, 'max_iter': 85526}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:19,817] Trial 31 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10189992129402047, 'max_iter': 68914}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:20,091] Trial 32 finished with value: 0.9292186448871848 and parameters: {'solver': 'newton-cg', 'C': 0.04563337073743209, 'max_iter': 66465}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:20,411] Trial 33 finished with value: 0.9287662201463618 and parameters: {'solver': 'newton-cg', 'C': 0.35824355447723927, 'max_iter': 55908}. Best is trial 21 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:20,769] Trial 34 finished with value: 0.9301231106870718 and parameters: {'solver': 'liblinear', 'C': 0.08488840737202236, 'max_iter': 78717}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:21,061] Trial 35 finished with value: 0.9295578195621423 and parameters: {'solver': 'liblinear', 'C': 0.07848873327145496, 'max_iter': 61235}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:21,415] Trial 36 finished with value: 0.9286530979744161 and parameters: {'solver': 'liblinear', 'C': 0.9100634416619211, 'max_iter': 81634}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:21,705] Trial 37 finished with value: 0.9276352542147441 and parameters: {'solver': 'liblinear', 'C': 0.019612762703203262, 'max_iter': 89884}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:22,026] Trial 38 finished with value: 0.9229990996268056 and parameters: {'solver': 'sag', 'C': 0.004986019408570147, 'max_iter': 64069}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:22,391] Trial 39 finished with value: 0.9284269175774845 and parameters: {'solver': 'liblinear', 'C': 1.1777228897746348, 'max_iter': 887}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:22,947] Trial 40 finished with value: 0.9291054587682792 and parameters: {'solver': 'sag', 'C': 0.23067528754317052, 'max_iter': 94220}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:23,239] Trial 41 finished with value: 0.9298969942371 and parameters: {'solver': 'liblinear', 'C': 0.1214017975030536, 'max_iter': 74791}. Best is trial 34 with value: 0.9301231106870718.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:23,671] Trial 42 finished with value: 0.9303491631900837 and parameters: {'solver': 'saga', 'C': 0.09535960119460092, 'max_iter': 77629}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:24,126] Trial 43 finished with value: 0.930122982793152 and parameters: {'solver': 'saga', 'C': 0.08605288705423046, 'max_iter': 67300}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:24,561] Trial 44 finished with value: 0.9295577556151825 and parameters: {'solver': 'saga', 'C': 0.03852370226545158, 'max_iter': 68902}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:24,943] Trial 45 finished with value: 0.9259391250521167 and parameters: {'solver': 'saga', 'C': 0.013183025649056787, 'max_iter': 82309}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:25,380] Trial 46 finished with value: 0.9300099245681661 and parameters: {'solver': 'saga', 'C': 0.0804134523884008, 'max_iter': 13917}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:25,866] Trial 47 finished with value: 0.9292185169932651 and parameters: {'solver': 'saga', 'C': 0.2065818191616787, 'max_iter': 60784}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:26,305] Trial 48 finished with value: 0.9180238343108691 and parameters: {'solver': 'saga', 'C': 0.001314306676213895, 'max_iter': 37001}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:26,817] Trial 49 finished with value: 0.9287662201463618 and parameters: {'solver': 'saga', 'C': 0.3818301167300416, 'max_iter': 68402}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:28,115] Trial 50 finished with value: 0.9282008650744726 and parameters: {'solver': 'saga', 'C': 2.756204396022191, 'max_iter': 89492}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:28,561] Trial 51 finished with value: 0.9300099245681661 and parameters: {'solver': 'saga', 'C': 0.07963621433086995, 'max_iter': 7029}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:29,013] Trial 52 finished with value: 0.9300099245681661 and parameters: {'solver': 'saga', 'C': 0.08366438391202582, 'max_iter': 16665}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:29,455] Trial 53 finished with value: 0.9296708777871283 and parameters: {'solver': 'saga', 'C': 0.16015890230050694, 'max_iter': 15045}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:29,897] Trial 54 finished with value: 0.9291055227152392 and parameters: {'solver': 'saga', 'C': 0.05249048245443975, 'max_iter': 31436}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:30,174] Trial 55 finished with value: 0.928766156199402 and parameters: {'solver': 'liblinear', 'C': 0.03337458431181525, 'max_iter': 54816}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:31,015] Trial 56 finished with value: 0.9292185169932651 and parameters: {'solver': 'sag', 'C': 0.6545231576783775, 'max_iter': 45341}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:31,695] Trial 57 finished with value: 0.9275223238836778 and parameters: {'solver': 'saga', 'C': 0.01755404182745113, 'max_iter': 75929}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:31,955] Trial 58 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.06460313183809621, 'max_iter': 99965}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:32,680] Trial 59 finished with value: 0.9295578195621423 and parameters: {'solver': 'saga', 'C': 0.16931959496082075, 'max_iter': 72839}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:33,077] Trial 60 finished with value: 0.9301231106870718 and parameters: {'solver': 'liblinear', 'C': 0.09741762203244701, 'max_iter': 78433}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:33,372] Trial 61 finished with value: 0.9296708777871283 and parameters: {'solver': 'liblinear', 'C': 0.0994508040064304, 'max_iter': 79964}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:33,646] Trial 62 finished with value: 0.9280876150086073 and parameters: {'solver': 'liblinear', 'C': 0.02674513079312995, 'max_iter': 83592}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:33,990] Trial 63 finished with value: 0.9289923365963336 and parameters: {'solver': 'liblinear', 'C': 0.31760885316766163, 'max_iter': 71110}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:34,296] Trial 64 finished with value: 0.9282008650744726 and parameters: {'solver': 'liblinear', 'C': 0.05103776173002755, 'max_iter': 79010}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:34,738] Trial 65 finished with value: 0.9298969942371 and parameters: {'solver': 'saga', 'C': 0.12235060328578168, 'max_iter': 63991}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:34,960] Trial 66 finished with value: 0.9297838081181945 and parameters: {'solver': 'lbfgs', 'C': 0.0729215630437442, 'max_iter': 74135}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:35,296] Trial 67 finished with value: 0.9296708138401684 and parameters: {'solver': 'liblinear', 'C': 0.1900732041104582, 'max_iter': 66829}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:35,571] Trial 68 finished with value: 0.9291053948213195 and parameters: {'solver': 'newton-cg', 'C': 0.49783697167440416, 'max_iter': 85942}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:36,013] Trial 69 finished with value: 0.9243560541144753 and parameters: {'solver': 'saga', 'C': 0.00840951604868801, 'max_iter': 76378}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:36,408] Trial 70 finished with value: 0.9295577556151825 and parameters: {'solver': 'sag', 'C': 0.037408328240937865, 'max_iter': 92294}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:36,847] Trial 71 finished with value: 0.930122982793152 and parameters: {'solver': 'saga', 'C': 0.08698402638442047, 'max_iter': 9800}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:37,319] Trial 72 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.10567383290289613, 'max_iter': 14723}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:37,819] Trial 73 finished with value: 0.9287662201463618 and parameters: {'solver': 'saga', 'C': 0.27409149831754326, 'max_iter': 9112}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:38,074] Trial 74 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1316760967420272, 'max_iter': 8956}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:38,538] Trial 75 finished with value: 0.9291055227152392 and parameters: {'solver': 'saga', 'C': 0.044649376270607735, 'max_iter': 18362}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:38,839] Trial 76 finished with value: 0.9297839360121142 and parameters: {'solver': 'liblinear', 'C': 0.1020954367033885, 'max_iter': 87284}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:39,076] Trial 77 finished with value: 0.9289923365963336 and parameters: {'solver': 'newton-cg', 'C': 0.02680758161215387, 'max_iter': 21017}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:39,530] Trial 78 finished with value: 0.9295578195621423 and parameters: {'solver': 'saga', 'C': 0.17192679285488713, 'max_iter': 26431}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:40,044] Trial 79 finished with value: 0.9291054587682792 and parameters: {'solver': 'saga', 'C': 0.24578979092591943, 'max_iter': 71197}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:40,278] Trial 80 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06313925827485066, 'max_iter': 81508}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:40,746] Trial 81 finished with value: 0.9297839360121142 and parameters: {'solver': 'saga', 'C': 0.13738003160154186, 'max_iter': 14331}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:41,200] Trial 82 finished with value: 0.9297838081181945 and parameters: {'solver': 'saga', 'C': 0.07141167542355277, 'max_iter': 3813}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:41,685] Trial 83 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.09931673328812417, 'max_iter': 26014}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:42,132] Trial 84 finished with value: 0.9303491631900837 and parameters: {'solver': 'saga', 'C': 0.09451751613554703, 'max_iter': 27377}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:42,583] Trial 85 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.10536119878470025, 'max_iter': 27595}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:42,818] Trial 86 finished with value: 0.9287662201463618 and parameters: {'solver': 'lbfgs', 'C': 0.3558333829909824, 'max_iter': 34330}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:43,100] Trial 87 finished with value: 0.9285401036963901 and parameters: {'solver': 'liblinear', 'C': 0.047278753454918304, 'max_iter': 28289}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:43,412] Trial 88 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.21663991029508692, 'max_iter': 21236}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:44,989] Trial 89 finished with value: 0.9298969302901401 and parameters: {'solver': 'saga', 'C': 0.10686840427017925, 'max_iter': 39331}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:45,999] Trial 90 finished with value: 0.9297839360121142 and parameters: {'solver': 'sag', 'C': 0.15124663055580637, 'max_iter': 30403}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:46,763] Trial 91 finished with value: 0.9296708138401686 and parameters: {'solver': 'saga', 'C': 0.05955295788178982, 'max_iter': 27539}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:47,211] Trial 92 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.09827741889874171, 'max_iter': 41905}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:47,658] Trial 93 finished with value: 0.9295577556151825 and parameters: {'solver': 'saga', 'C': 0.03823809804243412, 'max_iter': 23913}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:48,128] Trial 94 finished with value: 0.9300100524620859 and parameters: {'solver': 'saga', 'C': 0.11118191451718892, 'max_iter': 42113}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:48,580] Trial 95 finished with value: 0.9284269175774845 and parameters: {'solver': 'saga', 'C': 0.0218909173521775, 'max_iter': 32672}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:49,044] Trial 96 finished with value: 0.9296708777871283 and parameters: {'solver': 'saga', 'C': 0.16211129085401843, 'max_iter': 34467}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:49,347] Trial 97 finished with value: 0.9301231106870718 and parameters: {'solver': 'liblinear', 'C': 0.09609906307510391, 'max_iter': 48127}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:49,700] Trial 98 finished with value: 0.9289923365963336 and parameters: {'solver': 'liblinear', 'C': 0.40914035588160813, 'max_iter': 57081}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:50,009] Trial 99 finished with value: 0.9286530979744161 and parameters: {'solver': 'liblinear', 'C': 0.05902981485291267, 'max_iter': 48721}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:50,289] Trial 100 finished with value: 0.928766156199402 and parameters: {'solver': 'liblinear', 'C': 0.028941182922140554, 'max_iter': 47622}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:50,592] Trial 101 finished with value: 0.9296708777871283 and parameters: {'solver': 'liblinear', 'C': 0.09894004827911723, 'max_iter': 51316}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:50,862] Trial 102 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.21758202207115931, 'max_iter': 40119}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:51,199] Trial 103 finished with value: 0.9298969302901401 and parameters: {'solver': 'liblinear', 'C': 0.13945085406782076, 'max_iter': 77419}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:51,637] Trial 104 finished with value: 0.9062647557609816 and parameters: {'solver': 'saga', 'C': 0.00029144328946565545, 'max_iter': 20355}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:52,116] Trial 105 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.09167878193417593, 'max_iter': 54066}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:52,558] Trial 106 finished with value: 0.9292186448871848 and parameters: {'solver': 'saga', 'C': 0.045315790591864406, 'max_iter': 45282}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:53,002] Trial 107 finished with value: 0.9298968663431804 and parameters: {'solver': 'saga', 'C': 0.07310606795463966, 'max_iter': 42897}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:53,442] Trial 108 finished with value: 0.9300099245681661 and parameters: {'solver': 'saga', 'C': 0.08766051398223673, 'max_iter': 54205}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:53,888] Trial 109 finished with value: 0.9298969942371 and parameters: {'solver': 'saga', 'C': 0.12168338419169493, 'max_iter': 30213}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:54,232] Trial 110 finished with value: 0.9295577556151826 and parameters: {'solver': 'liblinear', 'C': 0.2078696319981065, 'max_iter': 36375}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:54,741] Trial 111 finished with value: 0.9286531619213759 and parameters: {'solver': 'saga', 'C': 0.2852610985575936, 'max_iter': 25072}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:54,994] Trial 112 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.08920308092527734, 'max_iter': 78916}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:55,248] Trial 113 finished with value: 0.9296708777871283 and parameters: {'solver': 'lbfgs', 'C': 0.17099551394663975, 'max_iter': 12382}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:55,699] Trial 114 finished with value: 0.9294446973901968 and parameters: {'solver': 'saga', 'C': 0.056439138327251635, 'max_iter': 73737}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:56,132] Trial 115 finished with value: 0.9298969942371 and parameters: {'solver': 'liblinear', 'C': 0.11840145429808269, 'max_iter': 84545}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:56,770] Trial 116 finished with value: 0.9295577556151825 and parameters: {'solver': 'sag', 'C': 0.0393934270533239, 'max_iter': 82045}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:57,467] Trial 117 finished with value: 0.9297838720651542 and parameters: {'solver': 'saga', 'C': 0.0642262961627418, 'max_iter': 53218}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:57,796] Trial 118 finished with value: 0.9292185809402248 and parameters: {'solver': 'newton-cg', 'C': 0.03207076644589472, 'max_iter': 59064}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:58,265] Trial 119 finished with value: 0.9302361049650978 and parameters: {'solver': 'saga', 'C': 0.098784116650299, 'max_iter': 69313}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:58,724] Trial 120 finished with value: 0.930122982793152 and parameters: {'solver': 'saga', 'C': 0.08401262577240405, 'max_iter': 61599}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:59,189] Trial 121 finished with value: 0.9298969942371 and parameters: {'solver': 'saga', 'C': 0.13033016070576614, 'max_iter': 62961}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:56:59,671] Trial 122 finished with value: 0.9301230467401119 and parameters: {'solver': 'saga', 'C': 0.10013563114128987, 'max_iter': 70808}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:00,143] Trial 123 finished with value: 0.9297838720651542 and parameters: {'solver': 'saga', 'C': 0.06833120184963262, 'max_iter': 76674}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:00,613] Trial 124 finished with value: 0.9291055227152392 and parameters: {'solver': 'saga', 'C': 0.0502625258695333, 'max_iter': 48425}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:00,943] Trial 125 finished with value: 0.9296708138401684 and parameters: {'solver': 'liblinear', 'C': 0.1852534054600106, 'max_iter': 74878}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:01,429] Trial 126 finished with value: 0.9297839360121142 and parameters: {'solver': 'saga', 'C': 0.15319351694070385, 'max_iter': 69904}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:01,667] Trial 127 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.10404331319118612, 'max_iter': 65840}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:02,177] Trial 128 finished with value: 0.9286531619213759 and parameters: {'solver': 'saga', 'C': 0.2838727843702069, 'max_iter': 65720}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:02,417] Trial 129 finished with value: 0.9300099245681661 and parameters: {'solver': 'newton-cg', 'C': 0.08008615380300242, 'max_iter': 17214}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:02,715] Trial 130 finished with value: 0.9297839360121142 and parameters: {'solver': 'liblinear', 'C': 0.10987007659961306, 'max_iter': 80852}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:02,980] Trial 131 finished with value: 0.9297839360121142 and parameters: {'solver': 'newton-cg', 'C': 0.1395731094366521, 'max_iter': 72363}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:03,219] Trial 132 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.1009387590279972, 'max_iter': 78055}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:03,462] Trial 133 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06694555648885968, 'max_iter': 69025}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:03,705] Trial 134 finished with value: 0.929218580940225 and parameters: {'solver': 'newton-cg', 'C': 0.04262485558592214, 'max_iter': 66496}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:04,178] Trial 135 finished with value: 0.9293316391652109 and parameters: {'solver': 'saga', 'C': 0.1930071160057794, 'max_iter': 46772}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:04,402] Trial 136 finished with value: 0.9295577556151826 and parameters: {'solver': 'lbfgs', 'C': 0.05465884578172497, 'max_iter': 56857}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:04,870] Trial 137 finished with value: 0.9300099245681661 and parameters: {'solver': 'saga', 'C': 0.07898611151074421, 'max_iter': 74105}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:05,112] Trial 138 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.12359941584486703, 'max_iter': 39533}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:05,412] Trial 139 finished with value: 0.9300100524620859 and parameters: {'solver': 'liblinear', 'C': 0.0928782106331282, 'max_iter': 27844}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:05,931] Trial 140 finished with value: 0.9288793423183075 and parameters: {'solver': 'saga', 'C': 0.250153013510061, 'max_iter': 23321}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:06,175] Trial 141 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.09192080554509703, 'max_iter': 79820}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:06,427] Trial 142 finished with value: 0.9297839360121142 and parameters: {'solver': 'newton-cg', 'C': 0.15371987658768743, 'max_iter': 83148}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:06,687] Trial 143 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06891661030006052, 'max_iter': 50819}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:06,936] Trial 144 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.1030720825646143, 'max_iter': 78787}. Best is trial 42 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-10-3816748024.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:57:07,180] Trial 145 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.11343456434913353, 'max_iter': 78240}. Best is trial 42 with value: 0.9303491631900837.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'solver': 'saga', 'C': 0.09535960119460092, 'max_iter': 77629}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習によって、データの見方でよりよくなるか：ハイパーパラメータチューニング\n",
        "機械学習モデルの外側から調整するため、ハイパーと呼ばれる"
      ],
      "metadata": {
        "id": "tM3Rs1PLaJgG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AAJGkE35Kcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1c9490-e37c-4263-a829-32b32162a23e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression(\n",
        "    # ハイパーパラメータ探索で特定した値を設定\n",
        "    solver = study.best_params['solver'],\n",
        "    C = study.best_params['C'],\n",
        "    max_iter = study.best_params['max_iter']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "# 正解率の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred)))\n",
        "# 混同行列の出力\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.40163 %\n",
            "[[ 875   96]\n",
            " [  72 1168]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKZRlpGSDFh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecb841c-b16b-4c52-e104-5d778e663bf2"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# 適合率の確認\n",
        "print(\"Precision: {:.5f} %\".format(100 * precision_score(y_test, pred)))\n",
        "# 再現率の確認\n",
        "print(\"Recall: {:.5f} %\".format(100 * recall_score(y_test, pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 92.40506 %\n",
            "Recall: 94.19355 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwVXagaQxnDn"
      },
      "source": [
        "##決定木を使用したフィッシング検出器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KyBu4q8xDwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4aa79b3-ef83-4d8e-a122-e52bd4d8d226"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "class Objective_DTC:\n",
        "    def __init__(self, X, y):\n",
        "        # 変数X,yの初期化\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # ターゲットのハイパーパラメータの設定\n",
        "        params = {\n",
        "            'criterion':\\\n",
        "            trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "            'splitter':\\\n",
        "            trial.suggest_categorical('splitter', ['best', 'random']),\n",
        "            'max_features':\\\n",
        "            trial.suggest_categorical('max_features', [ 'sqrt', 'log2']),\n",
        "            'min_samples_split':\\\n",
        "            trial.suggest_int('min_samples_split', 2, 64),\n",
        "            'max_depth':\\\n",
        "            trial.suggest_int('max_depth', 2, 64)\n",
        "            }\n",
        "\n",
        "        model = DecisionTreeClassifier(**params)\n",
        "\n",
        "        # 評価指標として正解率の最大化を目指す\n",
        "        scores = cross_validate(model,\n",
        "                                X=self.X, y=self.y,\n",
        "                                scoring='accuracy',\n",
        "                                n_jobs=-1)\n",
        "        return scores['test_score'].mean()\n",
        "\n",
        "objective = Objective_DTC(X_train, y_train)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# timeoutに60を指定し、最大で1分間探索させる\n",
        "study.optimize(objective, timeout=60)\n",
        "print('params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-15 09:57:54,296] A new study created in memory with name: no-name-cf252c37-c955-446e-b94e-41a7e351621e\n",
            "[I 2025-07-15 09:57:54,521] Trial 0 finished with value: 0.9322716006435622 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 19, 'max_depth': 43}. Best is trial 0 with value: 0.9322716006435622.\n",
            "[I 2025-07-15 09:57:54,712] Trial 1 finished with value: 0.9511541147310775 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 30}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:54,857] Trial 2 finished with value: 0.9077361113597938 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 41, 'max_depth': 9}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,021] Trial 3 finished with value: 0.9229990356798459 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 22, 'max_depth': 20}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,182] Trial 4 finished with value: 0.9114661375268897 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 29, 'max_depth': 17}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,334] Trial 5 finished with value: 0.9184766427334511 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 34, 'max_depth': 34}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,478] Trial 6 finished with value: 0.893939171093928 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 43, 'max_depth': 27}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,618] Trial 7 finished with value: 0.8995950239033735 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 57, 'max_depth': 41}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,759] Trial 8 finished with value: 0.9239049722598087 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 34, 'max_depth': 14}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:55,907] Trial 9 finished with value: 0.923452163837227 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 18, 'max_depth': 31}. Best is trial 1 with value: 0.9511541147310775.\n",
            "[I 2025-07-15 09:57:56,065] Trial 10 finished with value: 0.9525110692187473 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,226] Trial 11 finished with value: 0.9433526495783336 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 63}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,385] Trial 12 finished with value: 0.9510409925591319 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,537] Trial 13 finished with value: 0.9297840639060337 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 49}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,688] Trial 14 finished with value: 0.9314776351902678 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 12, 'max_depth': 51}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,835] Trial 15 finished with value: 0.6932303829911318 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 64, 'max_depth': 2}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:56,986] Trial 16 finished with value: 0.92785977199072 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 12, 'max_depth': 26}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,147] Trial 17 finished with value: 0.9458403142097819 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 38}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,298] Trial 18 finished with value: 0.9374720232050728 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 25, 'max_depth': 54}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,453] Trial 19 finished with value: 0.929443802132759 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 14, 'max_depth': 46}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,607] Trial 20 finished with value: 0.9158743851499812 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 49, 'max_depth': 63}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,759] Trial 21 finished with value: 0.9494586889850082 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 10 with value: 0.9525110692187473.\n",
            "[I 2025-07-15 09:57:57,908] Trial 22 finished with value: 0.9531893546217025 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 22 with value: 0.9531893546217025.\n",
            "[I 2025-07-15 09:57:58,071] Trial 23 finished with value: 0.9315928036649282 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 55}. Best is trial 22 with value: 0.9531893546217025.\n",
            "[I 2025-07-15 09:57:58,221] Trial 24 finished with value: 0.9298975697597385 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 16, 'max_depth': 36}. Best is trial 22 with value: 0.9531893546217025.\n",
            "[I 2025-07-15 09:57:58,373] Trial 25 finished with value: 0.9324960544725783 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 27}. Best is trial 22 with value: 0.9531893546217025.\n",
            "[I 2025-07-15 09:57:58,535] Trial 26 finished with value: 0.9564684907750115 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:58,695] Trial 27 finished with value: 0.9402998856628357 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 56}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:58,866] Trial 28 finished with value: 0.9298971860779794 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 26, 'max_depth': 50}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,017] Trial 29 finished with value: 0.9270713059759712 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 18, 'max_depth': 46}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,167] Trial 30 finished with value: 0.9424479919375672 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 42}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,320] Trial 31 finished with value: 0.9546598789100369 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,472] Trial 32 finished with value: 0.9561292521530941 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,624] Trial 33 finished with value: 0.9374721510989925 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 11, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,784] Trial 34 finished with value: 0.9431266610222817 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 58}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:57:59,935] Trial 35 finished with value: 0.9343072881629061 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 14, 'max_depth': 53}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,086] Trial 36 finished with value: 0.9279753241471393 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 22, 'max_depth': 59}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,244] Trial 37 finished with value: 0.9421080498990918 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 47}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,405] Trial 38 finished with value: 0.9540940762094289 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,557] Trial 39 finished with value: 0.9209637318422608 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 21, 'max_depth': 63}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,706] Trial 40 finished with value: 0.9163286643526394 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 37, 'max_depth': 53}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:00,868] Trial 41 finished with value: 0.9433525216844141 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,029] Trial 42 finished with value: 0.9559030717561626 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,182] Trial 43 finished with value: 0.9347600326385284 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 10, 'max_depth': 61}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,339] Trial 44 finished with value: 0.9392822337440434 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 5, 'max_depth': 61}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,501] Trial 45 finished with value: 0.9166668798231994 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 45, 'max_depth': 63}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,653] Trial 46 finished with value: 0.9215294705959091 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 14, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,814] Trial 47 finished with value: 0.942222514957194 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 5, 'max_depth': 51}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:01,980] Trial 48 finished with value: 0.9543190416141236 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 39}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,131] Trial 49 finished with value: 0.9207371038166103 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 30, 'max_depth': 32}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,283] Trial 50 finished with value: 0.9277491437502079 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 11, 'max_depth': 39}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,447] Trial 51 finished with value: 0.951605900002302 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 35}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,608] Trial 52 finished with value: 0.9434664751668377 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 7, 'max_depth': 44}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,766] Trial 53 finished with value: 0.944143225842757 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,927] Trial 54 finished with value: 0.9521717666498699 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 39}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:02,993] Trial 55 finished with value: 0.9426748118040973 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 6, 'max_depth': 23}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,145] Trial 56 finished with value: 0.9327250485357425 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 9, 'max_depth': 55}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,295] Trial 57 finished with value: 0.9056998483178113 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 52, 'max_depth': 48}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,449] Trial 58 finished with value: 0.9228854658791812 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 10}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,601] Trial 59 finished with value: 0.9329483513194816 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 13, 'max_depth': 29}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,753] Trial 60 finished with value: 0.9350989515256465 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 16, 'max_depth': 60}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:03,918] Trial 61 finished with value: 0.9551108968177436 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,075] Trial 62 finished with value: 0.9495712995812754 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,231] Trial 63 finished with value: 0.9525117086883454 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,388] Trial 64 finished with value: 0.9407516709340605 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 62}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,549] Trial 65 finished with value: 0.9416552414765098 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 64}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,708] Trial 66 finished with value: 0.9548860593069683 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:04,863] Trial 67 finished with value: 0.9068290876815135 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 62, 'max_depth': 44}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,031] Trial 68 finished with value: 0.9407515430401409 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 55}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,194] Trial 69 finished with value: 0.9456121514570954 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 59}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,350] Trial 70 finished with value: 0.9381512038654657 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 11, 'max_depth': 49}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,536] Trial 71 finished with value: 0.9562420545902407 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,711] Trial 72 finished with value: 0.9443706212319254 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 57}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:05,900] Trial 73 finished with value: 0.9536420990973247 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:06,105] Trial 74 finished with value: 0.9423340384551437 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 59}. Best is trial 26 with value: 0.9564684907750115.\n",
            "[I 2025-07-15 09:58:06,193] Trial 75 finished with value: 0.9565814850530376 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:06,376] Trial 76 finished with value: 0.9424481837784467 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:06,549] Trial 77 finished with value: 0.943579277603984 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 62}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:06,732] Trial 78 finished with value: 0.95296349395957 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:06,912] Trial 79 finished with value: 0.9481009031868608 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 59}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,100] Trial 80 finished with value: 0.9364552025967582 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 10, 'max_depth': 62}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,290] Trial 81 finished with value: 0.9543209600229184 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,452] Trial 82 finished with value: 0.9443700457092868 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,603] Trial 83 finished with value: 0.9395077746713765 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 60}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,760] Trial 84 finished with value: 0.9436920160941709 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 53}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:07,931] Trial 85 finished with value: 0.948779955953334 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 64}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,096] Trial 86 finished with value: 0.9538679597594572 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,254] Trial 87 finished with value: 0.9234512685797892 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 37, 'max_depth': 62}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,418] Trial 88 finished with value: 0.942222067328475 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 56}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,581] Trial 89 finished with value: 0.9362281269423889 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 51}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,743] Trial 90 finished with value: 0.9322714727496425 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 10, 'max_depth': 60}. Best is trial 75 with value: 0.9565814850530376.\n",
            "[I 2025-07-15 09:58:08,908] Trial 91 finished with value: 0.9583904805997714 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,071] Trial 92 finished with value: 0.9499106660971124 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,228] Trial 93 finished with value: 0.9561296358348532 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,389] Trial 94 finished with value: 0.9416568401505054 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,538] Trial 95 finished with value: 0.8202074311483084 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 2}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,700] Trial 96 finished with value: 0.9430120680702597 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:09,855] Trial 97 finished with value: 0.9407520546158195 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,020] Trial 98 finished with value: 0.9483274033185914 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 64}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,187] Trial 99 finished with value: 0.9405264497415263 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,340] Trial 100 finished with value: 0.9540934367398306 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,496] Trial 101 finished with value: 0.9555642168160041 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,659] Trial 102 finished with value: 0.946292291321886 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,822] Trial 103 finished with value: 0.9509276145993466 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:10,986] Trial 104 finished with value: 0.9401855484986532 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,150] Trial 105 finished with value: 0.945274831243973 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,313] Trial 106 finished with value: 0.9539812737722823 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,468] Trial 107 finished with value: 0.9442567956434214 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,621] Trial 108 finished with value: 0.934306201064589 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 12, 'max_depth': 64}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,775] Trial 109 finished with value: 0.944143993206275 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 18}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:11,927] Trial 110 finished with value: 0.9334003923785457 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 26, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,092] Trial 111 finished with value: 0.9575995846005488 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,259] Trial 112 finished with value: 0.9499106021501525 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,419] Trial 113 finished with value: 0.9569208515688749 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,583] Trial 114 finished with value: 0.9456134303962921 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,747] Trial 115 finished with value: 0.9568077933438888 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:12,915] Trial 116 finished with value: 0.9469704488309217 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,078] Trial 117 finished with value: 0.9412033283113654 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,243] Trial 118 finished with value: 0.9508141087456421 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,409] Trial 119 finished with value: 0.9404130078347814 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,575] Trial 120 finished with value: 0.9518324640809925 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,734] Trial 121 finished with value: 0.9569202120992764 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:13,894] Trial 122 finished with value: 0.945727255984796 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,058] Trial 123 finished with value: 0.9565819966287163 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,214] Trial 124 finished with value: 0.9376990349124823 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,371] Trial 125 finished with value: 0.9438037314330001 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,536] Trial 126 finished with value: 0.9512680682135011 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 48}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,705] Trial 127 finished with value: 0.9408642815303276 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:14,870] Trial 128 finished with value: 0.9560166415568272 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,025] Trial 129 finished with value: 0.9465184717188174 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,190] Trial 130 finished with value: 0.9572592588803144 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,370] Trial 131 finished with value: 0.9500237243220981 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,537] Trial 132 finished with value: 0.9476492458095557 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,702] Trial 133 finished with value: 0.9464054134938318 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 49}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:15,866] Trial 134 finished with value: 0.9547722337184646 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,033] Trial 135 finished with value: 0.9482147927223243 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,186] Trial 136 finished with value: 0.9406389324438738 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 6, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,342] Trial 137 finished with value: 0.9276356378965032 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 32, 'max_depth': 44}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,496] Trial 138 finished with value: 0.9253746652376652 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 52, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,661] Trial 139 finished with value: 0.9478756180473666 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,824] Trial 140 finished with value: 0.9548856756252094 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:16,993] Trial 141 finished with value: 0.9533028604754072 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:17,160] Trial 142 finished with value: 0.9500234685342589 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:17,332] Trial 143 finished with value: 0.9456138140780512 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:17,521] Trial 144 finished with value: 0.9570342934756196 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:17,715] Trial 145 finished with value: 0.9488926944435209 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:17,911] Trial 146 finished with value: 0.9220961046069949 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 43, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:18,116] Trial 147 finished with value: 0.9332886770397162 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 7, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:18,310] Trial 148 finished with value: 0.9473110303389957 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:18,511] Trial 149 finished with value: 0.9551110886586229 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:18,720] Trial 150 finished with value: 0.9466307625802853 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:18,924] Trial 151 finished with value: 0.9554503272805404 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,135] Trial 152 finished with value: 0.9531896743565017 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,294] Trial 153 finished with value: 0.957486462428603 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,471] Trial 154 finished with value: 0.944143929259315 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,636] Trial 155 finished with value: 0.9482144729875251 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,803] Trial 156 finished with value: 0.9568069620334111 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:19,975] Trial 157 finished with value: 0.9465178322492193 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,140] Trial 158 finished with value: 0.9531899301443412 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,309] Trial 159 finished with value: 0.9491191306282916 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,465] Trial 160 finished with value: 0.9382656049766082 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,630] Trial 161 finished with value: 0.9574858229590049 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,795] Trial 162 finished with value: 0.9513806148628081 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:20,952] Trial 163 finished with value: 0.9542064949648165 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,118] Trial 164 finished with value: 0.9490046016232296 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,288] Trial 165 finished with value: 0.952397755205922 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 64}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,445] Trial 166 finished with value: 0.9235638152290964 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 22, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,610] Trial 167 finished with value: 0.9570341655817 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,775] Trial 168 finished with value: 0.9468579661285743 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:21,942] Trial 169 finished with value: 0.9539812737722823 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,097] Trial 170 finished with value: 0.9334004563255054 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,266] Trial 171 finished with value: 0.9572595786151135 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,432] Trial 172 finished with value: 0.9577124509846552 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,602] Trial 173 finished with value: 0.9531887790990641 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,770] Trial 174 finished with value: 0.9471969489626524 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:22,938] Trial 175 finished with value: 0.9478749146308086 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,092] Trial 176 finished with value: 0.9389435706447644 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 20, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,262] Trial 177 finished with value: 0.9503634105727345 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,429] Trial 178 finished with value: 0.9477619203527826 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,613] Trial 179 finished with value: 0.9450487147940013 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,779] Trial 180 finished with value: 0.9552244026714481 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 37}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:23,941] Trial 181 finished with value: 0.9502497128781504 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,106] Trial 182 finished with value: 0.9559028799152831 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,275] Trial 183 finished with value: 0.945274831243973 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,441] Trial 184 finished with value: 0.9505890154470276 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,606] Trial 185 finished with value: 0.9455005000652259 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 64}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,773] Trial 186 finished with value: 0.9487795722715751 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:24,944] Trial 187 finished with value: 0.9424470966801296 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,110] Trial 188 finished with value: 0.9583904805997714 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 41}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,273] Trial 189 finished with value: 0.9538677039716179 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,438] Trial 190 finished with value: 0.9486663861526695 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 40}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,595] Trial 191 finished with value: 0.9536417793625256 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 32}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,755] Trial 192 finished with value: 0.9534155350186341 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 43}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:25,922] Trial 193 finished with value: 0.9534160465943128 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 24}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,089] Trial 194 finished with value: 0.9555638970812049 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,258] Trial 195 finished with value: 0.9535290408723387 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 41}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,424] Trial 196 finished with value: 0.945726488621278 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,590] Trial 197 finished with value: 0.9557902053720561 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,750] Trial 198 finished with value: 0.9439181325441426 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:26,919] Trial 199 finished with value: 0.9494582413562895 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,087] Trial 200 finished with value: 0.9478745309490495 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,258] Trial 201 finished with value: 0.9542071344344147 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,427] Trial 202 finished with value: 0.9525111971126667 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,596] Trial 203 finished with value: 0.9442564119616625 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 35}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,752] Trial 204 finished with value: 0.9552245945123277 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:27,927] Trial 205 finished with value: 0.9474237688291824 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,087] Trial 206 finished with value: 0.9180266479771019 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 38, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,251] Trial 207 finished with value: 0.9424470966801296 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,417] Trial 208 finished with value: 0.955451670166697 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,578] Trial 209 finished with value: 0.9525108134309079 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,764] Trial 210 finished with value: 0.9479880368027542 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:28,924] Trial 211 finished with value: 0.9190432127975772 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 24, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,093] Trial 212 finished with value: 0.9543202566063604 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,288] Trial 213 finished with value: 0.9467446521157491 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 62}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,485] Trial 214 finished with value: 0.9543210879168382 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,685] Trial 215 finished with value: 0.9504764048507607 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 64}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,781] Trial 216 finished with value: 0.9487810430516512 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 49}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:29,992] Trial 217 finished with value: 0.9555642807629641 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,090] Trial 218 finished with value: 0.9495716193160744 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,191] Trial 219 finished with value: 0.9580516256596129 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,299] Trial 220 finished with value: 0.9482140253588064 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,508] Trial 221 finished with value: 0.9536419072564453 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,708] Trial 222 finished with value: 0.9396216642068402 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 16, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:30,905] Trial 223 finished with value: 0.9531892906747427 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,093] Trial 224 finished with value: 0.920399783603488 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 58, 'max_depth': 47}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,263] Trial 225 finished with value: 0.9457262967803984 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 59}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,427] Trial 226 finished with value: 0.9511541147310775 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,632] Trial 227 finished with value: 0.9427871666125249 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 60}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,807] Trial 228 finished with value: 0.953189226727783 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:31,974] Trial 229 finished with value: 0.9478749785777685 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,143] Trial 230 finished with value: 0.9575990730248701 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,311] Trial 231 finished with value: 0.9539815295601215 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,484] Trial 232 finished with value: 0.9514940567695531 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,651] Trial 233 finished with value: 0.9574862705877237 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,822] Trial 234 finished with value: 0.9528514588859416 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:32,991] Trial 235 finished with value: 0.9449359123568548 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:33,159] Trial 236 finished with value: 0.9535288490314594 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:33,330] Trial 237 finished with value: 0.9502494570903111 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:33,503] Trial 238 finished with value: 0.943126085499643 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 29}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:33,673] Trial 239 finished with value: 0.9513811264384868 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:33,842] Trial 240 finished with value: 0.9553373969494743 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 91 with value: 0.9583904805997714.\n",
            "[I 2025-07-15 09:58:34,010] Trial 241 finished with value: 0.9600868016032781 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:34,182] Trial 242 finished with value: 0.9571466482840473 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:34,342] Trial 243 finished with value: 0.949910857937992 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 63}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:34,504] Trial 244 finished with value: 0.9538673842368185 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:34,674] Trial 245 finished with value: 0.9512675566378224 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 64}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:34,832] Trial 246 finished with value: 0.9485544150260008 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,020] Trial 247 finished with value: 0.9553381003660324 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,194] Trial 248 finished with value: 0.9468580940224939 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,354] Trial 249 finished with value: 0.949344223926906 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 55}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,528] Trial 250 finished with value: 0.9539805703557243 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 63}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,695] Trial 251 finished with value: 0.9565823803104753 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:35,857] Trial 252 finished with value: 0.9483280427881897 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,030] Trial 253 finished with value: 0.954998797797155 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,203] Trial 254 finished with value: 0.9517202371664846 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,370] Trial 255 finished with value: 0.9500228930116205 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,531] Trial 256 finished with value: 0.9572601541377519 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,691] Trial 257 finished with value: 0.9493456307600223 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:36,859] Trial 258 finished with value: 0.9570341655816998 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,019] Trial 259 finished with value: 0.9412045433036023 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 55}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,192] Trial 260 finished with value: 0.9543201287124408 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,362] Trial 261 finished with value: 0.9507015620963347 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,535] Trial 262 finished with value: 0.9466312102090042 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,704] Trial 263 finished with value: 0.952284760927896 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:37,862] Trial 264 finished with value: 0.9231117102230726 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 30, 'max_depth': 54}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,032] Trial 265 finished with value: 0.9500234045872992 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,205] Trial 266 finished with value: 0.947762112193662 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,376] Trial 267 finished with value: 0.9572598344029528 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,545] Trial 268 finished with value: 0.9575988172370309 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,720] Trial 269 finished with value: 0.9197199634734966 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 48, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:38,897] Trial 270 finished with value: 0.9560163218220279 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,068] Trial 271 finished with value: 0.9457264886212778 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,241] Trial 272 finished with value: 0.9488930141783198 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 55}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,402] Trial 273 finished with value: 0.920626923204817 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 10}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,572] Trial 274 finished with value: 0.950815259790919 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,741] Trial 275 finished with value: 0.9488926304965609 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:39,910] Trial 276 finished with value: 0.9535284653497003 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,081] Trial 277 finished with value: 0.9438057777357148 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,254] Trial 278 finished with value: 0.9516068592066995 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,425] Trial 279 finished with value: 0.9477619842997423 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 55}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,599] Trial 280 finished with value: 0.95352852929666 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,770] Trial 281 finished with value: 0.9509276785463066 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:40,941] Trial 282 finished with value: 0.957938567434627 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:41,109] Trial 283 finished with value: 0.951154306571957 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:41,303] Trial 284 finished with value: 0.9527366101460804 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:41,502] Trial 285 finished with value: 0.9467438847522311 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:41,859] Trial 286 finished with value: 0.9464052216529522 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:42,251] Trial 287 finished with value: 0.954659431281318 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:42,599] Trial 288 finished with value: 0.9509285098567843 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:42,963] Trial 289 finished with value: 0.9528504357345844 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:43,294] Trial 290 finished with value: 0.9552250421410464 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:43,597] Trial 291 finished with value: 0.9471977163261703 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:43,914] Trial 292 finished with value: 0.9544329311495872 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:44,129] Trial 293 finished with value: 0.9443683191413715 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:44,447] Trial 294 finished with value: 0.957372764734019 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:44,716] Trial 295 finished with value: 0.9513811264384868 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 52}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:44,936] Trial 296 finished with value: 0.9551110247116631 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:45,150] Trial 297 finished with value: 0.9447092203842444 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 53}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:45,409] Trial 298 finished with value: 0.9416560088400278 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 52}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:45,688] Trial 299 finished with value: 0.9538677679185776 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:45,987] Trial 300 finished with value: 0.9519454583590188 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:46,291] Trial 301 finished with value: 0.9456140698658905 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 51}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:46,571] Trial 302 finished with value: 0.9525110052717872 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:46,827] Trial 303 finished with value: 0.9586171086254216 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:47,129] Trial 304 finished with value: 0.9361155163461218 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:47,407] Trial 305 finished with value: 0.9560157462993895 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:47,695] Trial 306 finished with value: 0.920738382755807 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 35, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:48,008] Trial 307 finished with value: 0.9448220867683508 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:48,249] Trial 308 finished with value: 0.9548852919434504 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:48,521] Trial 309 finished with value: 0.9502495210372708 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 34}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:48,738] Trial 310 finished with value: 0.9445971213636561 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:48,895] Trial 311 finished with value: 0.9449351449933368 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:49,001] Trial 312 finished with value: 0.9486665140465892 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:49,279] Trial 313 finished with value: 0.8715468641689836 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 4}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:49,629] Trial 314 finished with value: 0.9460657272431954 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:49,900] Trial 315 finished with value: 0.9570337818999409 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:50,147] Trial 316 finished with value: 0.9543189137202038 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:50,396] Trial 317 finished with value: 0.947988164696674 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 21}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:50,574] Trial 318 finished with value: 0.9519451386242196 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:50,741] Trial 319 finished with value: 0.9588427774466746 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:50,913] Trial 320 finished with value: 0.948440525490537 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,088] Trial 321 finished with value: 0.942673341024021 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 62}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,254] Trial 322 finished with value: 0.9436900976853758 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,426] Trial 323 finished with value: 0.9488928862844002 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,597] Trial 324 finished with value: 0.9509281901219853 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,772] Trial 325 finished with value: 0.9488925665496011 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:51,945] Trial 326 finished with value: 0.9486667058874687 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 42}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,107] Trial 327 finished with value: 0.9346455675804262 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 7, 'max_depth': 38}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,273] Trial 328 finished with value: 0.9181370843767345 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 62, 'max_depth': 63}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,445] Trial 329 finished with value: 0.9580519453944121 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,622] Trial 330 finished with value: 0.9552246584592876 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,793] Trial 331 finished with value: 0.9479882925905937 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:52,961] Trial 332 finished with value: 0.9421090091034892 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 60}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:53,123] Trial 333 finished with value: 0.9187032068121418 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 40, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:53,286] Trial 334 finished with value: 0.9417698983754914 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 13}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:53,460] Trial 335 finished with value: 0.9530758487679979 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:53,627] Trial 336 finished with value: 0.9490051771458681 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:53,794] Trial 337 finished with value: 0.9562425661659194 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:54,001] Trial 338 finished with value: 0.9492320609593579 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 61}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:54,196] Trial 339 finished with value: 0.9503630908379354 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 241 with value: 0.9600868016032781.\n",
            "[I 2025-07-15 09:58:54,407] Trial 340 finished with value: 0.9559030078092027 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 241 with value: 0.9600868016032781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 62}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0YTQ22b9YxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871510bb-84be-4348-81b6-a4649e8eb81b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "model = DecisionTreeClassifier(\n",
        "    # ハイパーパラメータ探索で特定した値を設定\n",
        "    criterion = study.best_params['criterion'],\n",
        "    splitter = study.best_params['splitter'],\n",
        "    max_features = study.best_params['max_features'],\n",
        "    min_samples_split = study.best_params['min_samples_split'],\n",
        "    max_depth = study.best_params['max_depth']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# 正解率の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred)))\n",
        "# 適合率の出力\n",
        "print(\"Precision: {:.5f} %\".format(100 * precision_score(y_test, pred,)))\n",
        "# 再現率の出力\n",
        "print(\"Recall: {:.5f} %\".format(100 * recall_score(y_test, pred)))\n",
        "# 混同行列の出力\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.61284 %\n",
            "Precision: 96.27530 %\n",
            "Recall: 95.88710 %\n",
            "[[ 925   46]\n",
            " [  51 1189]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2025年７月１５日ここまで\n",
        "\n",
        "データをある程度の法則を決めて分析するものだという事が分かった。むずかしい"
      ],
      "metadata": {
        "id": "TLXarFfxiEoP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwDgHRK6yq1w"
      },
      "source": [
        "### tf-idfを使った迷惑メール検出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwvnhoHKJIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3744d060-82a2-44b5-e04a-7b5830610ac8"
      },
      "source": [
        "!wget https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/enron1.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-22 09:26:23--  https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/enron1.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/enron1.zip [following]\n",
            "--2025-07-22 09:26:24--  https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/enron1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3597958 (3.4M) [application/zip]\n",
            "Saving to: ‘enron1.zip.3’\n",
            "\n",
            "enron1.zip.3        100%[===================>]   3.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-07-22 09:26:24 (65.2 MB/s) - ‘enron1.zip.3’ saved [3597958/3597958]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "字句解析→構文解析→意味解析→談話統合→語用論的解析"
      ],
      "metadata": {
        "id": "19p9JyDpc9x6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF5r5b1qLQNd"
      },
      "source": [
        "!unzip -q enron1.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ntXsNTLmPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce80b0f-b407-424d-d8b3-72b55990be39"
      },
      "source": [
        "!ls ./enron1/ham"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0001.1999-12-10.farmer.ham.txt\t2561.2000-10-17.farmer.ham.txt\n",
            "0002.1999-12-13.farmer.ham.txt\t2563.2000-10-17.farmer.ham.txt\n",
            "0003.1999-12-14.farmer.ham.txt\t2564.2000-10-17.farmer.ham.txt\n",
            "0004.1999-12-14.farmer.ham.txt\t2565.2000-10-18.farmer.ham.txt\n",
            "0005.1999-12-14.farmer.ham.txt\t2567.2000-10-18.farmer.ham.txt\n",
            "0007.1999-12-14.farmer.ham.txt\t2569.2000-10-18.farmer.ham.txt\n",
            "0009.1999-12-14.farmer.ham.txt\t2571.2000-10-18.farmer.ham.txt\n",
            "0010.1999-12-14.farmer.ham.txt\t2572.2000-10-18.farmer.ham.txt\n",
            "0011.1999-12-14.farmer.ham.txt\t2573.2000-10-18.farmer.ham.txt\n",
            "0012.1999-12-14.farmer.ham.txt\t2574.2000-10-18.farmer.ham.txt\n",
            "0013.1999-12-14.farmer.ham.txt\t2576.2000-10-18.farmer.ham.txt\n",
            "0014.1999-12-15.farmer.ham.txt\t2577.2000-10-18.farmer.ham.txt\n",
            "0015.1999-12-15.farmer.ham.txt\t2578.2000-10-18.farmer.ham.txt\n",
            "0016.1999-12-15.farmer.ham.txt\t2579.2000-10-18.farmer.ham.txt\n",
            "0019.1999-12-15.farmer.ham.txt\t2582.2000-10-18.farmer.ham.txt\n",
            "0020.1999-12-15.farmer.ham.txt\t2584.2000-10-18.farmer.ham.txt\n",
            "0021.1999-12-15.farmer.ham.txt\t2586.2000-10-18.farmer.ham.txt\n",
            "0022.1999-12-16.farmer.ham.txt\t2587.2000-10-18.farmer.ham.txt\n",
            "0023.1999-12-16.farmer.ham.txt\t2588.2000-10-18.farmer.ham.txt\n",
            "0024.1999-12-16.farmer.ham.txt\t2589.2000-10-19.farmer.ham.txt\n",
            "0025.1999-12-16.farmer.ham.txt\t2591.2000-10-19.farmer.ham.txt\n",
            "0027.1999-12-17.farmer.ham.txt\t2592.2000-10-19.farmer.ham.txt\n",
            "0028.1999-12-17.farmer.ham.txt\t2593.2000-10-19.farmer.ham.txt\n",
            "0029.1999-12-17.farmer.ham.txt\t2594.2000-10-19.farmer.ham.txt\n",
            "0030.1999-12-20.farmer.ham.txt\t2595.2000-10-19.farmer.ham.txt\n",
            "0031.1999-12-20.farmer.ham.txt\t2596.2000-10-19.farmer.ham.txt\n",
            "0033.1999-12-20.farmer.ham.txt\t2597.2000-10-19.farmer.ham.txt\n",
            "0034.1999-12-20.farmer.ham.txt\t2598.2000-10-19.farmer.ham.txt\n",
            "0035.1999-12-20.farmer.ham.txt\t2599.2000-10-20.farmer.ham.txt\n",
            "0036.1999-12-20.farmer.ham.txt\t2600.2000-10-20.farmer.ham.txt\n",
            "0037.1999-12-20.farmer.ham.txt\t2601.2000-10-20.farmer.ham.txt\n",
            "0038.1999-12-20.farmer.ham.txt\t2602.2000-10-20.farmer.ham.txt\n",
            "0039.1999-12-21.farmer.ham.txt\t2604.2000-10-20.farmer.ham.txt\n",
            "0042.1999-12-21.farmer.ham.txt\t2605.2000-10-20.farmer.ham.txt\n",
            "0043.1999-12-21.farmer.ham.txt\t2606.2000-10-20.farmer.ham.txt\n",
            "0044.1999-12-21.farmer.ham.txt\t2607.2000-10-20.farmer.ham.txt\n",
            "0045.1999-12-21.farmer.ham.txt\t2608.2000-10-20.farmer.ham.txt\n",
            "0047.1999-12-21.farmer.ham.txt\t2609.2000-10-20.farmer.ham.txt\n",
            "0048.1999-12-21.farmer.ham.txt\t2610.2000-10-20.farmer.ham.txt\n",
            "0049.1999-12-21.farmer.ham.txt\t2611.2000-10-20.farmer.ham.txt\n",
            "0050.1999-12-22.farmer.ham.txt\t2612.2000-10-22.farmer.ham.txt\n",
            "0051.1999-12-22.farmer.ham.txt\t2613.2000-10-23.farmer.ham.txt\n",
            "0053.1999-12-22.farmer.ham.txt\t2614.2000-10-23.farmer.ham.txt\n",
            "0055.1999-12-22.farmer.ham.txt\t2616.2000-10-23.farmer.ham.txt\n",
            "0056.1999-12-23.farmer.ham.txt\t2617.2000-10-23.farmer.ham.txt\n",
            "0057.1999-12-23.farmer.ham.txt\t2618.2000-10-23.farmer.ham.txt\n",
            "0059.1999-12-23.farmer.ham.txt\t2619.2000-10-23.farmer.ham.txt\n",
            "0060.1999-12-23.farmer.ham.txt\t2620.2000-10-23.farmer.ham.txt\n",
            "0063.1999-12-23.farmer.ham.txt\t2623.2000-10-23.farmer.ham.txt\n",
            "0064.1999-12-23.farmer.ham.txt\t2624.2000-10-23.farmer.ham.txt\n",
            "0066.1999-12-27.farmer.ham.txt\t2625.2000-10-23.farmer.ham.txt\n",
            "0067.1999-12-27.farmer.ham.txt\t2628.2000-10-24.farmer.ham.txt\n",
            "0068.1999-12-27.farmer.ham.txt\t2630.2000-10-24.farmer.ham.txt\n",
            "0070.1999-12-27.farmer.ham.txt\t2632.2000-10-24.farmer.ham.txt\n",
            "0071.1999-12-27.farmer.ham.txt\t2633.2000-10-24.farmer.ham.txt\n",
            "0074.1999-12-28.farmer.ham.txt\t2634.2000-10-24.farmer.ham.txt\n",
            "0076.1999-12-28.farmer.ham.txt\t2635.2000-10-24.farmer.ham.txt\n",
            "0077.1999-12-28.farmer.ham.txt\t2636.2000-10-24.farmer.ham.txt\n",
            "0078.1999-12-28.farmer.ham.txt\t2637.2000-10-24.farmer.ham.txt\n",
            "0079.1999-12-28.farmer.ham.txt\t2639.2000-10-24.farmer.ham.txt\n",
            "0081.1999-12-28.farmer.ham.txt\t2640.2000-10-24.farmer.ham.txt\n",
            "0083.1999-12-28.farmer.ham.txt\t2641.2000-10-24.farmer.ham.txt\n",
            "0085.1999-12-28.farmer.ham.txt\t2643.2000-10-24.farmer.ham.txt\n",
            "0086.1999-12-29.farmer.ham.txt\t2644.2000-10-24.farmer.ham.txt\n",
            "0087.1999-12-29.farmer.ham.txt\t2646.2000-10-24.farmer.ham.txt\n",
            "0089.1999-12-29.farmer.ham.txt\t2648.2000-10-24.farmer.ham.txt\n",
            "0090.1999-12-29.farmer.ham.txt\t2650.2000-10-24.farmer.ham.txt\n",
            "0091.1999-12-29.farmer.ham.txt\t2651.2000-10-25.farmer.ham.txt\n",
            "0092.1999-12-29.farmer.ham.txt\t2653.2000-10-25.farmer.ham.txt\n",
            "0095.1999-12-29.farmer.ham.txt\t2654.2000-10-25.farmer.ham.txt\n",
            "0096.1999-12-29.farmer.ham.txt\t2655.2000-10-25.farmer.ham.txt\n",
            "0097.1999-12-29.farmer.ham.txt\t2656.2000-10-25.farmer.ham.txt\n",
            "0098.1999-12-29.farmer.ham.txt\t2657.2000-10-25.farmer.ham.txt\n",
            "0099.1999-12-30.farmer.ham.txt\t2659.2000-10-25.farmer.ham.txt\n",
            "0101.1999-12-30.farmer.ham.txt\t2661.2000-10-25.farmer.ham.txt\n",
            "0106.1999-12-30.farmer.ham.txt\t2663.2000-10-25.farmer.ham.txt\n",
            "0107.1999-12-30.farmer.ham.txt\t2664.2000-10-25.farmer.ham.txt\n",
            "0109.1999-12-30.farmer.ham.txt\t2665.2000-10-25.farmer.ham.txt\n",
            "0111.1999-12-31.farmer.ham.txt\t2666.2000-10-25.farmer.ham.txt\n",
            "0112.1999-12-31.farmer.ham.txt\t2667.2000-10-26.farmer.ham.txt\n",
            "0113.2000-01-04.farmer.ham.txt\t2669.2000-10-26.farmer.ham.txt\n",
            "0114.2000-01-04.farmer.ham.txt\t2671.2000-10-26.farmer.ham.txt\n",
            "0115.2000-01-04.farmer.ham.txt\t2672.2000-10-26.farmer.ham.txt\n",
            "0117.2000-01-04.farmer.ham.txt\t2674.2000-10-26.farmer.ham.txt\n",
            "0118.2000-01-04.farmer.ham.txt\t2675.2000-10-26.farmer.ham.txt\n",
            "0119.2000-01-04.farmer.ham.txt\t2676.2000-10-26.farmer.ham.txt\n",
            "0120.2000-01-04.farmer.ham.txt\t2678.2000-10-27.farmer.ham.txt\n",
            "0121.2000-01-05.farmer.ham.txt\t2679.2000-10-27.farmer.ham.txt\n",
            "0123.2000-01-05.farmer.ham.txt\t2683.2000-10-27.farmer.ham.txt\n",
            "0124.2000-01-05.farmer.ham.txt\t2684.2000-10-27.farmer.ham.txt\n",
            "0125.2000-01-05.farmer.ham.txt\t2685.2000-10-27.farmer.ham.txt\n",
            "0126.2000-01-05.farmer.ham.txt\t2687.2000-10-27.farmer.ham.txt\n",
            "0127.2000-01-05.farmer.ham.txt\t2688.2000-10-27.farmer.ham.txt\n",
            "0128.2000-01-05.farmer.ham.txt\t2689.2000-10-27.farmer.ham.txt\n",
            "0129.2000-01-05.farmer.ham.txt\t2690.2000-10-27.farmer.ham.txt\n",
            "0132.2000-01-05.farmer.ham.txt\t2691.2000-10-27.farmer.ham.txt\n",
            "0133.2000-01-06.farmer.ham.txt\t2693.2000-10-30.farmer.ham.txt\n",
            "0136.2000-01-06.farmer.ham.txt\t2694.2000-10-30.farmer.ham.txt\n",
            "0137.2000-01-06.farmer.ham.txt\t2695.2000-10-30.farmer.ham.txt\n",
            "0138.2000-01-06.farmer.ham.txt\t2696.2000-10-30.farmer.ham.txt\n",
            "0139.2000-01-06.farmer.ham.txt\t2699.2000-10-30.farmer.ham.txt\n",
            "0140.2000-01-06.farmer.ham.txt\t2700.2000-10-30.farmer.ham.txt\n",
            "0141.2000-01-06.farmer.ham.txt\t2701.2000-10-30.farmer.ham.txt\n",
            "0142.2000-01-06.farmer.ham.txt\t2703.2000-10-30.farmer.ham.txt\n",
            "0143.2000-01-07.farmer.ham.txt\t2704.2000-10-30.farmer.ham.txt\n",
            "0144.2000-01-07.farmer.ham.txt\t2706.2000-10-30.farmer.ham.txt\n",
            "0145.2000-01-07.farmer.ham.txt\t2708.2000-10-30.farmer.ham.txt\n",
            "0146.2000-01-07.farmer.ham.txt\t2710.2000-10-30.farmer.ham.txt\n",
            "0148.2000-01-07.farmer.ham.txt\t2712.2000-10-31.farmer.ham.txt\n",
            "0151.2000-01-07.farmer.ham.txt\t2714.2000-10-31.farmer.ham.txt\n",
            "0152.2000-01-10.farmer.ham.txt\t2717.2000-10-31.farmer.ham.txt\n",
            "0154.2000-01-10.farmer.ham.txt\t2718.2000-10-31.farmer.ham.txt\n",
            "0155.2000-01-10.farmer.ham.txt\t2719.2000-10-31.farmer.ham.txt\n",
            "0156.2000-01-10.farmer.ham.txt\t2721.2000-10-31.farmer.ham.txt\n",
            "0157.2000-01-10.farmer.ham.txt\t2723.2000-10-31.farmer.ham.txt\n",
            "0158.2000-01-10.farmer.ham.txt\t2725.2000-10-31.farmer.ham.txt\n",
            "0161.2000-01-10.farmer.ham.txt\t2727.2000-10-31.farmer.ham.txt\n",
            "0162.2000-01-10.farmer.ham.txt\t2728.2000-10-31.farmer.ham.txt\n",
            "0163.2000-01-10.farmer.ham.txt\t2729.2000-10-31.farmer.ham.txt\n",
            "0164.2000-01-11.farmer.ham.txt\t2730.2000-10-31.farmer.ham.txt\n",
            "0165.2000-01-11.farmer.ham.txt\t2732.2000-11-01.farmer.ham.txt\n",
            "0166.2000-01-11.farmer.ham.txt\t2734.2000-11-01.farmer.ham.txt\n",
            "0169.2000-01-11.farmer.ham.txt\t2736.2000-11-01.farmer.ham.txt\n",
            "0171.2000-01-11.farmer.ham.txt\t2737.2000-11-01.farmer.ham.txt\n",
            "0172.2000-01-11.farmer.ham.txt\t2738.2000-11-01.farmer.ham.txt\n",
            "0175.2000-01-11.farmer.ham.txt\t2740.2000-11-01.farmer.ham.txt\n",
            "0177.2000-01-11.farmer.ham.txt\t2742.2000-11-01.farmer.ham.txt\n",
            "0178.2000-01-11.farmer.ham.txt\t2743.2000-11-01.farmer.ham.txt\n",
            "0179.2000-01-11.farmer.ham.txt\t2745.2000-11-01.farmer.ham.txt\n",
            "0180.2000-01-11.farmer.ham.txt\t2748.2000-11-01.farmer.ham.txt\n",
            "0181.2000-01-12.farmer.ham.txt\t2749.2000-11-02.farmer.ham.txt\n",
            "0182.2000-01-12.farmer.ham.txt\t2750.2000-11-02.farmer.ham.txt\n",
            "0183.2000-01-12.farmer.ham.txt\t2753.2000-11-02.farmer.ham.txt\n",
            "0185.2000-01-12.farmer.ham.txt\t2754.2000-11-02.farmer.ham.txt\n",
            "0186.2000-01-12.farmer.ham.txt\t2757.2000-11-02.farmer.ham.txt\n",
            "0187.2000-01-12.farmer.ham.txt\t2758.2000-11-02.farmer.ham.txt\n",
            "0188.2000-01-12.farmer.ham.txt\t2759.2000-11-02.farmer.ham.txt\n",
            "0190.2000-01-12.farmer.ham.txt\t2760.2000-11-02.farmer.ham.txt\n",
            "0193.2000-01-12.farmer.ham.txt\t2761.2000-11-02.farmer.ham.txt\n",
            "0194.2000-01-13.farmer.ham.txt\t2762.2000-11-02.farmer.ham.txt\n",
            "0196.2000-01-13.farmer.ham.txt\t2765.2000-11-03.farmer.ham.txt\n",
            "0198.2000-01-14.farmer.ham.txt\t2766.2000-11-03.farmer.ham.txt\n",
            "0200.2000-01-14.farmer.ham.txt\t2767.2000-11-05.farmer.ham.txt\n",
            "0201.2000-01-14.farmer.ham.txt\t2768.2000-11-06.farmer.ham.txt\n",
            "0203.2000-01-16.farmer.ham.txt\t2769.2000-11-06.farmer.ham.txt\n",
            "0205.2000-01-17.farmer.ham.txt\t2771.2000-11-06.farmer.ham.txt\n",
            "0206.2000-01-17.farmer.ham.txt\t2772.2000-11-06.farmer.ham.txt\n",
            "0207.2000-01-17.farmer.ham.txt\t2773.2000-11-06.farmer.ham.txt\n",
            "0208.2000-01-17.farmer.ham.txt\t2774.2000-11-06.farmer.ham.txt\n",
            "0210.2000-01-17.farmer.ham.txt\t2776.2000-11-07.farmer.ham.txt\n",
            "0211.2000-01-17.farmer.ham.txt\t2777.2000-11-07.farmer.ham.txt\n",
            "0212.2000-01-18.farmer.ham.txt\t2778.2000-11-07.farmer.ham.txt\n",
            "0213.2000-01-18.farmer.ham.txt\t2779.2000-11-07.farmer.ham.txt\n",
            "0215.2000-01-18.farmer.ham.txt\t2780.2000-11-07.farmer.ham.txt\n",
            "0217.2000-01-18.farmer.ham.txt\t2782.2000-11-07.farmer.ham.txt\n",
            "0218.2000-01-19.farmer.ham.txt\t2786.2000-11-07.farmer.ham.txt\n",
            "0219.2000-01-19.farmer.ham.txt\t2788.2000-11-07.farmer.ham.txt\n",
            "0220.2000-01-19.farmer.ham.txt\t2789.2000-11-07.farmer.ham.txt\n",
            "0221.2000-01-19.farmer.ham.txt\t2790.2000-11-07.farmer.ham.txt\n",
            "0222.2000-01-19.farmer.ham.txt\t2791.2000-11-07.farmer.ham.txt\n",
            "0223.2000-01-19.farmer.ham.txt\t2792.2000-11-07.farmer.ham.txt\n",
            "0224.2000-01-19.farmer.ham.txt\t2793.2000-11-08.farmer.ham.txt\n",
            "0225.2000-01-19.farmer.ham.txt\t2795.2000-11-08.farmer.ham.txt\n",
            "0226.2000-01-20.farmer.ham.txt\t2796.2000-11-08.farmer.ham.txt\n",
            "0227.2000-01-20.farmer.ham.txt\t2797.2000-11-08.farmer.ham.txt\n",
            "0229.2000-01-20.farmer.ham.txt\t2799.2000-11-08.farmer.ham.txt\n",
            "0230.2000-01-20.farmer.ham.txt\t2800.2000-11-08.farmer.ham.txt\n",
            "0231.2000-01-21.farmer.ham.txt\t2801.2000-11-09.farmer.ham.txt\n",
            "0232.2000-01-21.farmer.ham.txt\t2802.2000-11-09.farmer.ham.txt\n",
            "0234.2000-01-21.farmer.ham.txt\t2804.2000-11-09.farmer.ham.txt\n",
            "0235.2000-01-21.farmer.ham.txt\t2805.2000-11-09.farmer.ham.txt\n",
            "0237.2000-01-21.farmer.ham.txt\t2806.2000-11-09.farmer.ham.txt\n",
            "0239.2000-01-21.farmer.ham.txt\t2808.2000-11-09.farmer.ham.txt\n",
            "0240.2000-01-21.farmer.ham.txt\t2809.2000-11-09.farmer.ham.txt\n",
            "0241.2000-01-21.farmer.ham.txt\t2811.2000-11-09.farmer.ham.txt\n",
            "0242.2000-01-21.farmer.ham.txt\t2814.2000-11-09.farmer.ham.txt\n",
            "0243.2000-01-24.farmer.ham.txt\t2815.2000-11-09.farmer.ham.txt\n",
            "0244.2000-01-24.farmer.ham.txt\t2816.2000-11-10.farmer.ham.txt\n",
            "0245.2000-01-24.farmer.ham.txt\t2817.2000-11-10.farmer.ham.txt\n",
            "0246.2000-01-24.farmer.ham.txt\t2818.2000-11-10.farmer.ham.txt\n",
            "0247.2000-01-24.farmer.ham.txt\t2819.2000-11-12.farmer.ham.txt\n",
            "0249.2000-01-24.farmer.ham.txt\t2820.2000-11-13.farmer.ham.txt\n",
            "0251.2000-01-24.farmer.ham.txt\t2821.2000-11-13.farmer.ham.txt\n",
            "0252.2000-01-25.farmer.ham.txt\t2823.2000-11-13.farmer.ham.txt\n",
            "0253.2000-01-25.farmer.ham.txt\t2824.2000-11-13.farmer.ham.txt\n",
            "0254.2000-01-25.farmer.ham.txt\t2825.2000-11-13.farmer.ham.txt\n",
            "0255.2000-01-25.farmer.ham.txt\t2828.2000-11-13.farmer.ham.txt\n",
            "0257.2000-01-25.farmer.ham.txt\t2830.2000-11-13.farmer.ham.txt\n",
            "0258.2000-01-25.farmer.ham.txt\t2831.2000-11-13.farmer.ham.txt\n",
            "0259.2000-01-25.farmer.ham.txt\t2834.2000-11-13.farmer.ham.txt\n",
            "0261.2000-01-25.farmer.ham.txt\t2835.2000-11-13.farmer.ham.txt\n",
            "0262.2000-01-26.farmer.ham.txt\t2836.2000-11-13.farmer.ham.txt\n",
            "0263.2000-01-26.farmer.ham.txt\t2838.2000-11-13.farmer.ham.txt\n",
            "0265.2000-01-26.farmer.ham.txt\t2839.2000-11-14.farmer.ham.txt\n",
            "0267.2000-01-26.farmer.ham.txt\t2841.2000-11-14.farmer.ham.txt\n",
            "0268.2000-01-26.farmer.ham.txt\t2842.2000-11-14.farmer.ham.txt\n",
            "0269.2000-01-27.farmer.ham.txt\t2843.2000-11-14.farmer.ham.txt\n",
            "0270.2000-01-27.farmer.ham.txt\t2844.2000-11-14.farmer.ham.txt\n",
            "0271.2000-01-27.farmer.ham.txt\t2845.2000-11-14.farmer.ham.txt\n",
            "0272.2000-01-28.farmer.ham.txt\t2846.2000-11-14.farmer.ham.txt\n",
            "0273.2000-01-28.farmer.ham.txt\t2847.2000-11-14.farmer.ham.txt\n",
            "0274.2000-01-28.farmer.ham.txt\t2848.2000-11-14.farmer.ham.txt\n",
            "0275.2000-01-28.farmer.ham.txt\t2849.2000-11-14.farmer.ham.txt\n",
            "0276.2000-01-28.farmer.ham.txt\t2850.2000-11-15.farmer.ham.txt\n",
            "0278.2000-01-28.farmer.ham.txt\t2851.2000-11-15.farmer.ham.txt\n",
            "0279.2000-01-31.farmer.ham.txt\t2853.2000-11-15.farmer.ham.txt\n",
            "0280.2000-01-31.farmer.ham.txt\t2854.2000-11-15.farmer.ham.txt\n",
            "0281.2000-01-31.farmer.ham.txt\t2855.2000-11-15.farmer.ham.txt\n",
            "0283.2000-01-31.farmer.ham.txt\t2856.2000-11-15.farmer.ham.txt\n",
            "0284.2000-01-31.farmer.ham.txt\t2857.2000-11-15.farmer.ham.txt\n",
            "0285.2000-01-31.farmer.ham.txt\t2858.2000-11-15.farmer.ham.txt\n",
            "0286.2000-01-31.farmer.ham.txt\t2860.2000-11-15.farmer.ham.txt\n",
            "0287.2000-01-31.farmer.ham.txt\t2861.2000-11-15.farmer.ham.txt\n",
            "0288.2000-01-31.farmer.ham.txt\t2862.2000-11-15.farmer.ham.txt\n",
            "0291.2000-01-31.farmer.ham.txt\t2863.2000-11-16.farmer.ham.txt\n",
            "0292.2000-01-31.farmer.ham.txt\t2864.2000-11-16.farmer.ham.txt\n",
            "0293.2000-01-31.farmer.ham.txt\t2865.2000-11-16.farmer.ham.txt\n",
            "0294.2000-02-01.farmer.ham.txt\t2866.2000-11-16.farmer.ham.txt\n",
            "0295.2000-02-01.farmer.ham.txt\t2868.2000-11-16.farmer.ham.txt\n",
            "0296.2000-02-01.farmer.ham.txt\t2870.2000-11-16.farmer.ham.txt\n",
            "0297.2000-02-01.farmer.ham.txt\t2871.2000-11-16.farmer.ham.txt\n",
            "0299.2000-02-01.farmer.ham.txt\t2872.2000-11-16.farmer.ham.txt\n",
            "0300.2000-02-01.farmer.ham.txt\t2873.2000-11-17.farmer.ham.txt\n",
            "0301.2000-02-02.farmer.ham.txt\t2875.2000-11-17.farmer.ham.txt\n",
            "0302.2000-02-02.farmer.ham.txt\t2876.2000-11-17.farmer.ham.txt\n",
            "0304.2000-02-02.farmer.ham.txt\t2877.2000-11-17.farmer.ham.txt\n",
            "0305.2000-02-02.farmer.ham.txt\t2878.2000-11-17.farmer.ham.txt\n",
            "0306.2000-02-02.farmer.ham.txt\t2879.2000-11-17.farmer.ham.txt\n",
            "0309.2000-02-02.farmer.ham.txt\t2880.2000-11-17.farmer.ham.txt\n",
            "0310.2000-02-02.farmer.ham.txt\t2881.2000-11-17.farmer.ham.txt\n",
            "0311.2000-02-02.farmer.ham.txt\t2882.2000-11-17.farmer.ham.txt\n",
            "0313.2000-02-02.farmer.ham.txt\t2884.2000-11-17.farmer.ham.txt\n",
            "0314.2000-02-02.farmer.ham.txt\t2885.2000-11-19.farmer.ham.txt\n",
            "0315.2000-02-03.farmer.ham.txt\t2887.2000-11-20.farmer.ham.txt\n",
            "0316.2000-02-03.farmer.ham.txt\t2891.2000-11-20.farmer.ham.txt\n",
            "0317.2000-02-03.farmer.ham.txt\t2892.2000-11-20.farmer.ham.txt\n",
            "0318.2000-02-03.farmer.ham.txt\t2893.2000-11-20.farmer.ham.txt\n",
            "0319.2000-02-03.farmer.ham.txt\t2894.2000-11-20.farmer.ham.txt\n",
            "0320.2000-02-03.farmer.ham.txt\t2895.2000-11-20.farmer.ham.txt\n",
            "0321.2000-02-03.farmer.ham.txt\t2896.2000-11-21.farmer.ham.txt\n",
            "0322.2000-02-03.farmer.ham.txt\t2897.2000-11-21.farmer.ham.txt\n",
            "0326.2000-02-03.farmer.ham.txt\t2898.2000-11-21.farmer.ham.txt\n",
            "0329.2000-02-04.farmer.ham.txt\t2901.2000-11-21.farmer.ham.txt\n",
            "0330.2000-02-04.farmer.ham.txt\t2902.2000-11-21.farmer.ham.txt\n",
            "0331.2000-02-04.farmer.ham.txt\t2903.2000-11-21.farmer.ham.txt\n",
            "0333.2000-02-04.farmer.ham.txt\t2904.2000-11-21.farmer.ham.txt\n",
            "0335.2000-02-04.farmer.ham.txt\t2906.2000-11-21.farmer.ham.txt\n",
            "0336.2000-02-04.farmer.ham.txt\t2907.2000-11-21.farmer.ham.txt\n",
            "0338.2000-02-04.farmer.ham.txt\t2908.2000-11-21.farmer.ham.txt\n",
            "0340.2000-02-04.farmer.ham.txt\t2909.2000-11-21.farmer.ham.txt\n",
            "0341.2000-02-04.farmer.ham.txt\t2910.2000-11-21.farmer.ham.txt\n",
            "0343.2000-02-04.farmer.ham.txt\t2911.2000-11-21.farmer.ham.txt\n",
            "0344.2000-02-04.farmer.ham.txt\t2913.2000-11-21.farmer.ham.txt\n",
            "0345.2000-02-04.farmer.ham.txt\t2914.2000-11-21.farmer.ham.txt\n",
            "0346.2000-02-04.farmer.ham.txt\t2915.2000-11-21.farmer.ham.txt\n",
            "0348.2000-02-04.farmer.ham.txt\t2916.2000-11-21.farmer.ham.txt\n",
            "0349.2000-02-04.farmer.ham.txt\t2917.2000-11-22.farmer.ham.txt\n",
            "0350.2000-02-05.farmer.ham.txt\t2918.2000-11-22.farmer.ham.txt\n",
            "0351.2000-02-06.farmer.ham.txt\t2919.2000-11-22.farmer.ham.txt\n",
            "0353.2000-02-07.farmer.ham.txt\t2920.2000-11-22.farmer.ham.txt\n",
            "0354.2000-02-07.farmer.ham.txt\t2921.2000-11-22.farmer.ham.txt\n",
            "0355.2000-02-07.farmer.ham.txt\t2922.2000-11-22.farmer.ham.txt\n",
            "0356.2000-02-07.farmer.ham.txt\t2924.2000-11-22.farmer.ham.txt\n",
            "0358.2000-02-07.farmer.ham.txt\t2925.2000-11-22.farmer.ham.txt\n",
            "0360.2000-02-07.farmer.ham.txt\t2927.2000-11-22.farmer.ham.txt\n",
            "0361.2000-02-07.farmer.ham.txt\t2928.2000-11-24.farmer.ham.txt\n",
            "0362.2000-02-07.farmer.ham.txt\t2930.2000-11-27.farmer.ham.txt\n",
            "0363.2000-02-07.farmer.ham.txt\t2931.2000-11-27.farmer.ham.txt\n",
            "0365.2000-02-07.farmer.ham.txt\t2934.2000-11-27.farmer.ham.txt\n",
            "0366.2000-02-07.farmer.ham.txt\t2935.2000-11-27.farmer.ham.txt\n",
            "0368.2000-02-08.farmer.ham.txt\t2936.2000-11-27.farmer.ham.txt\n",
            "0369.2000-02-08.farmer.ham.txt\t2937.2000-11-27.farmer.ham.txt\n",
            "0370.2000-02-08.farmer.ham.txt\t2938.2000-11-27.farmer.ham.txt\n",
            "0371.2000-02-08.farmer.ham.txt\t2940.2000-11-27.farmer.ham.txt\n",
            "0372.2000-02-08.farmer.ham.txt\t2941.2000-11-27.farmer.ham.txt\n",
            "0374.2000-02-08.farmer.ham.txt\t2943.2000-11-27.farmer.ham.txt\n",
            "0375.2000-02-08.farmer.ham.txt\t2945.2000-11-27.farmer.ham.txt\n",
            "0376.2000-02-09.farmer.ham.txt\t2946.2000-11-27.farmer.ham.txt\n",
            "0379.2000-02-09.farmer.ham.txt\t2947.2000-11-27.farmer.ham.txt\n",
            "0380.2000-02-09.farmer.ham.txt\t2949.2000-11-27.farmer.ham.txt\n",
            "0382.2000-02-09.farmer.ham.txt\t2950.2000-11-27.farmer.ham.txt\n",
            "0383.2000-02-09.farmer.ham.txt\t2951.2000-11-27.farmer.ham.txt\n",
            "0384.2000-02-09.farmer.ham.txt\t2952.2000-11-27.farmer.ham.txt\n",
            "0386.2000-02-09.farmer.ham.txt\t2954.2000-11-27.farmer.ham.txt\n",
            "0388.2000-02-09.farmer.ham.txt\t2958.2000-11-27.farmer.ham.txt\n",
            "0390.2000-02-09.farmer.ham.txt\t2959.2000-11-28.farmer.ham.txt\n",
            "0393.2000-02-09.farmer.ham.txt\t2961.2000-11-28.farmer.ham.txt\n",
            "0394.2000-02-10.farmer.ham.txt\t2962.2000-11-28.farmer.ham.txt\n",
            "0395.2000-02-10.farmer.ham.txt\t2963.2000-11-28.farmer.ham.txt\n",
            "0397.2000-02-10.farmer.ham.txt\t2964.2000-11-28.farmer.ham.txt\n",
            "0399.2000-02-10.farmer.ham.txt\t2965.2000-11-29.farmer.ham.txt\n",
            "0400.2000-02-10.farmer.ham.txt\t2966.2000-11-29.farmer.ham.txt\n",
            "0402.2000-02-11.farmer.ham.txt\t2968.2000-11-29.farmer.ham.txt\n",
            "0403.2000-02-11.farmer.ham.txt\t2969.2000-11-29.farmer.ham.txt\n",
            "0404.2000-02-14.farmer.ham.txt\t2970.2000-11-29.farmer.ham.txt\n",
            "0405.2000-02-14.farmer.ham.txt\t2972.2000-11-29.farmer.ham.txt\n",
            "0406.2000-02-14.farmer.ham.txt\t2973.2000-11-29.farmer.ham.txt\n",
            "0408.2000-02-14.farmer.ham.txt\t2974.2000-11-29.farmer.ham.txt\n",
            "0409.2000-02-14.farmer.ham.txt\t2975.2000-11-29.farmer.ham.txt\n",
            "0410.2000-02-14.farmer.ham.txt\t2976.2000-11-30.farmer.ham.txt\n",
            "0411.2000-02-14.farmer.ham.txt\t2977.2000-11-30.farmer.ham.txt\n",
            "0412.2000-02-14.farmer.ham.txt\t2979.2000-11-30.farmer.ham.txt\n",
            "0413.2000-02-14.farmer.ham.txt\t2980.2000-11-30.farmer.ham.txt\n",
            "0414.2000-02-14.farmer.ham.txt\t2982.2000-11-30.farmer.ham.txt\n",
            "0415.2000-02-15.farmer.ham.txt\t2983.2000-11-30.farmer.ham.txt\n",
            "0416.2000-02-15.farmer.ham.txt\t2985.2000-11-30.farmer.ham.txt\n",
            "0418.2000-02-15.farmer.ham.txt\t2986.2000-11-30.farmer.ham.txt\n",
            "0419.2000-02-15.farmer.ham.txt\t2989.2000-12-01.farmer.ham.txt\n",
            "0420.2000-02-15.farmer.ham.txt\t2990.2000-12-01.farmer.ham.txt\n",
            "0421.2000-02-16.farmer.ham.txt\t2991.2000-12-01.farmer.ham.txt\n",
            "0422.2000-02-16.farmer.ham.txt\t2992.2000-12-01.farmer.ham.txt\n",
            "0423.2000-02-16.farmer.ham.txt\t2993.2000-12-01.farmer.ham.txt\n",
            "0425.2000-02-16.farmer.ham.txt\t2994.2000-12-01.farmer.ham.txt\n",
            "0426.2000-02-16.farmer.ham.txt\t2996.2000-12-03.farmer.ham.txt\n",
            "0427.2000-02-16.farmer.ham.txt\t2997.2000-12-04.farmer.ham.txt\n",
            "0428.2000-02-16.farmer.ham.txt\t2998.2000-12-04.farmer.ham.txt\n",
            "0429.2000-02-17.farmer.ham.txt\t2999.2000-12-04.farmer.ham.txt\n",
            "0430.2000-02-17.farmer.ham.txt\t3000.2000-12-04.farmer.ham.txt\n",
            "0433.2000-02-17.farmer.ham.txt\t3002.2000-12-04.farmer.ham.txt\n",
            "0435.2000-02-17.farmer.ham.txt\t3003.2000-12-04.farmer.ham.txt\n",
            "0436.2000-02-17.farmer.ham.txt\t3004.2000-12-04.farmer.ham.txt\n",
            "0437.2000-02-17.farmer.ham.txt\t3006.2000-12-04.farmer.ham.txt\n",
            "0440.2000-02-17.farmer.ham.txt\t3007.2000-12-04.farmer.ham.txt\n",
            "0441.2000-02-18.farmer.ham.txt\t3008.2000-12-05.farmer.ham.txt\n",
            "0442.2000-02-18.farmer.ham.txt\t3011.2000-12-05.farmer.ham.txt\n",
            "0443.2000-02-18.farmer.ham.txt\t3014.2000-12-05.farmer.ham.txt\n",
            "0444.2000-02-18.farmer.ham.txt\t3015.2000-12-05.farmer.ham.txt\n",
            "0446.2000-02-18.farmer.ham.txt\t3016.2000-12-05.farmer.ham.txt\n",
            "0447.2000-02-21.farmer.ham.txt\t3017.2000-12-05.farmer.ham.txt\n",
            "0448.2000-02-22.farmer.ham.txt\t3019.2000-12-05.farmer.ham.txt\n",
            "0450.2000-02-22.farmer.ham.txt\t3021.2000-12-05.farmer.ham.txt\n",
            "0452.2000-02-22.farmer.ham.txt\t3022.2000-12-05.farmer.ham.txt\n",
            "0453.2000-02-22.farmer.ham.txt\t3024.2000-12-05.farmer.ham.txt\n",
            "0456.2000-02-22.farmer.ham.txt\t3025.2000-12-05.farmer.ham.txt\n",
            "0457.2000-02-22.farmer.ham.txt\t3027.2000-12-05.farmer.ham.txt\n",
            "0458.2000-02-22.farmer.ham.txt\t3028.2000-12-05.farmer.ham.txt\n",
            "0459.2000-02-22.farmer.ham.txt\t3030.2000-12-05.farmer.ham.txt\n",
            "0460.2000-02-22.farmer.ham.txt\t3032.2000-12-06.farmer.ham.txt\n",
            "0461.2000-02-22.farmer.ham.txt\t3034.2000-12-06.farmer.ham.txt\n",
            "0464.2000-02-22.farmer.ham.txt\t3036.2000-12-06.farmer.ham.txt\n",
            "0465.2000-02-22.farmer.ham.txt\t3037.2000-12-06.farmer.ham.txt\n",
            "0466.2000-02-23.farmer.ham.txt\t3038.2000-12-06.farmer.ham.txt\n",
            "0467.2000-02-23.farmer.ham.txt\t3039.2000-12-07.farmer.ham.txt\n",
            "0468.2000-02-23.farmer.ham.txt\t3041.2000-12-07.farmer.ham.txt\n",
            "0469.2000-02-23.farmer.ham.txt\t3043.2000-12-07.farmer.ham.txt\n",
            "0470.2000-02-23.farmer.ham.txt\t3044.2000-12-07.farmer.ham.txt\n",
            "0471.2000-02-23.farmer.ham.txt\t3045.2000-12-07.farmer.ham.txt\n",
            "0472.2000-02-23.farmer.ham.txt\t3046.2000-12-07.farmer.ham.txt\n",
            "0474.2000-02-23.farmer.ham.txt\t3047.2000-12-07.farmer.ham.txt\n",
            "0475.2000-02-24.farmer.ham.txt\t3048.2000-12-07.farmer.ham.txt\n",
            "0476.2000-02-24.farmer.ham.txt\t3050.2000-12-08.farmer.ham.txt\n",
            "0478.2000-02-24.farmer.ham.txt\t3051.2000-12-08.farmer.ham.txt\n",
            "0479.2000-02-24.farmer.ham.txt\t3052.2000-12-08.farmer.ham.txt\n",
            "0481.2000-02-24.farmer.ham.txt\t3053.2000-12-08.farmer.ham.txt\n",
            "0482.2000-02-24.farmer.ham.txt\t3054.2000-12-11.farmer.ham.txt\n",
            "0483.2000-02-24.farmer.ham.txt\t3056.2000-12-11.farmer.ham.txt\n",
            "0486.2000-02-24.farmer.ham.txt\t3057.2000-12-11.farmer.ham.txt\n",
            "0487.2000-02-24.farmer.ham.txt\t3058.2000-12-11.farmer.ham.txt\n",
            "0488.2000-02-24.farmer.ham.txt\t3059.2000-12-11.farmer.ham.txt\n",
            "0489.2000-02-24.farmer.ham.txt\t3061.2000-12-11.farmer.ham.txt\n",
            "0490.2000-02-25.farmer.ham.txt\t3062.2000-12-11.farmer.ham.txt\n",
            "0491.2000-02-25.farmer.ham.txt\t3063.2000-12-11.farmer.ham.txt\n",
            "0493.2000-02-25.farmer.ham.txt\t3064.2000-12-11.farmer.ham.txt\n",
            "0494.2000-02-25.farmer.ham.txt\t3066.2000-12-11.farmer.ham.txt\n",
            "0495.2000-02-25.farmer.ham.txt\t3067.2000-12-12.farmer.ham.txt\n",
            "0497.2000-02-25.farmer.ham.txt\t3068.2000-12-12.farmer.ham.txt\n",
            "0498.2000-02-25.farmer.ham.txt\t3070.2000-12-12.farmer.ham.txt\n",
            "0499.2000-02-25.farmer.ham.txt\t3071.2000-12-12.farmer.ham.txt\n",
            "0500.2000-02-28.farmer.ham.txt\t3073.2000-12-12.farmer.ham.txt\n",
            "0502.2000-02-28.farmer.ham.txt\t3075.2000-12-12.farmer.ham.txt\n",
            "0503.2000-02-28.farmer.ham.txt\t3076.2000-12-12.farmer.ham.txt\n",
            "0504.2000-02-28.farmer.ham.txt\t3077.2000-12-12.farmer.ham.txt\n",
            "0506.2000-02-28.farmer.ham.txt\t3078.2000-12-12.farmer.ham.txt\n",
            "0507.2000-02-28.farmer.ham.txt\t3080.2000-12-12.farmer.ham.txt\n",
            "0508.2000-02-28.farmer.ham.txt\t3081.2000-12-12.farmer.ham.txt\n",
            "0509.2000-02-29.farmer.ham.txt\t3082.2000-12-12.farmer.ham.txt\n",
            "0510.2000-02-29.farmer.ham.txt\t3084.2000-12-13.farmer.ham.txt\n",
            "0513.2000-02-29.farmer.ham.txt\t3085.2000-12-13.farmer.ham.txt\n",
            "0514.2000-02-29.farmer.ham.txt\t3086.2000-12-13.farmer.ham.txt\n",
            "0515.2000-02-29.farmer.ham.txt\t3088.2000-12-13.farmer.ham.txt\n",
            "0516.2000-02-29.farmer.ham.txt\t3089.2000-12-13.farmer.ham.txt\n",
            "0517.2000-02-29.farmer.ham.txt\t3091.2000-12-13.farmer.ham.txt\n",
            "0518.2000-02-29.farmer.ham.txt\t3092.2000-12-13.farmer.ham.txt\n",
            "0519.2000-02-29.farmer.ham.txt\t3093.2000-12-13.farmer.ham.txt\n",
            "0521.2000-03-01.farmer.ham.txt\t3094.2000-12-13.farmer.ham.txt\n",
            "0522.2000-03-01.farmer.ham.txt\t3095.2000-12-13.farmer.ham.txt\n",
            "0523.2000-03-01.farmer.ham.txt\t3096.2000-12-14.farmer.ham.txt\n",
            "0524.2000-03-01.farmer.ham.txt\t3097.2000-12-14.farmer.ham.txt\n",
            "0525.2000-03-01.farmer.ham.txt\t3098.2000-12-14.farmer.ham.txt\n",
            "0526.2000-03-01.farmer.ham.txt\t3099.2000-12-14.farmer.ham.txt\n",
            "0527.2000-03-01.farmer.ham.txt\t3100.2000-12-14.farmer.ham.txt\n",
            "0530.2000-03-02.farmer.ham.txt\t3101.2000-12-14.farmer.ham.txt\n",
            "0531.2000-03-02.farmer.ham.txt\t3102.2000-12-14.farmer.ham.txt\n",
            "0532.2000-03-02.farmer.ham.txt\t3104.2000-12-14.farmer.ham.txt\n",
            "0534.2000-03-02.farmer.ham.txt\t3106.2000-12-14.farmer.ham.txt\n",
            "0535.2000-03-02.farmer.ham.txt\t3108.2000-12-15.farmer.ham.txt\n",
            "0536.2000-03-03.farmer.ham.txt\t3109.2000-12-15.farmer.ham.txt\n",
            "0537.2000-03-03.farmer.ham.txt\t3111.2000-12-15.farmer.ham.txt\n",
            "0539.2000-03-03.farmer.ham.txt\t3114.2000-12-15.farmer.ham.txt\n",
            "0540.2000-03-03.farmer.ham.txt\t3115.2000-12-15.farmer.ham.txt\n",
            "0541.2000-03-03.farmer.ham.txt\t3117.2000-12-15.farmer.ham.txt\n",
            "0543.2000-03-03.farmer.ham.txt\t3118.2000-12-15.farmer.ham.txt\n",
            "0545.2000-03-03.farmer.ham.txt\t3119.2000-12-18.farmer.ham.txt\n",
            "0546.2000-03-03.farmer.ham.txt\t3120.2000-12-18.farmer.ham.txt\n",
            "0548.2000-03-03.farmer.ham.txt\t3121.2000-12-18.farmer.ham.txt\n",
            "0549.2000-03-03.farmer.ham.txt\t3122.2000-12-18.farmer.ham.txt\n",
            "0550.2000-03-03.farmer.ham.txt\t3125.2000-12-19.farmer.ham.txt\n",
            "0551.2000-03-03.farmer.ham.txt\t3126.2000-12-19.farmer.ham.txt\n",
            "0552.2000-03-06.farmer.ham.txt\t3127.2000-12-19.farmer.ham.txt\n",
            "0553.2000-03-06.farmer.ham.txt\t3128.2000-12-19.farmer.ham.txt\n",
            "0554.2000-03-06.farmer.ham.txt\t3129.2000-12-19.farmer.ham.txt\n",
            "0556.2000-03-06.farmer.ham.txt\t3132.2000-12-19.farmer.ham.txt\n",
            "0558.2000-03-06.farmer.ham.txt\t3133.2000-12-19.farmer.ham.txt\n",
            "0560.2000-03-06.farmer.ham.txt\t3134.2000-12-19.farmer.ham.txt\n",
            "0562.2000-03-06.farmer.ham.txt\t3135.2000-12-19.farmer.ham.txt\n",
            "0563.2000-03-06.farmer.ham.txt\t3136.2000-12-19.farmer.ham.txt\n",
            "0564.2000-03-07.farmer.ham.txt\t3137.2000-12-19.farmer.ham.txt\n",
            "0565.2000-03-07.farmer.ham.txt\t3138.2000-12-19.farmer.ham.txt\n",
            "0566.2000-03-07.farmer.ham.txt\t3139.2000-12-19.farmer.ham.txt\n",
            "0568.2000-03-07.farmer.ham.txt\t3140.2000-12-19.farmer.ham.txt\n",
            "0570.2000-03-07.farmer.ham.txt\t3141.2000-12-19.farmer.ham.txt\n",
            "0572.2000-03-07.farmer.ham.txt\t3142.2000-12-20.farmer.ham.txt\n",
            "0573.2000-03-07.farmer.ham.txt\t3143.2000-12-20.farmer.ham.txt\n",
            "0576.2000-03-07.farmer.ham.txt\t3145.2000-12-20.farmer.ham.txt\n",
            "0579.2000-03-08.farmer.ham.txt\t3146.2000-12-20.farmer.ham.txt\n",
            "0581.2000-03-08.farmer.ham.txt\t3147.2000-12-20.farmer.ham.txt\n",
            "0583.2000-03-08.farmer.ham.txt\t3148.2000-12-20.farmer.ham.txt\n",
            "0584.2000-03-08.farmer.ham.txt\t3149.2000-12-20.farmer.ham.txt\n",
            "0586.2000-03-08.farmer.ham.txt\t3150.2000-12-20.farmer.ham.txt\n",
            "0587.2000-03-10.farmer.ham.txt\t3151.2000-12-20.farmer.ham.txt\n",
            "0590.2000-03-10.farmer.ham.txt\t3152.2000-12-20.farmer.ham.txt\n",
            "0591.2000-03-10.farmer.ham.txt\t3154.2000-12-20.farmer.ham.txt\n",
            "0592.2000-03-10.farmer.ham.txt\t3155.2000-12-20.farmer.ham.txt\n",
            "0593.2000-03-10.farmer.ham.txt\t3156.2000-12-20.farmer.ham.txt\n",
            "0594.2000-03-11.farmer.ham.txt\t3157.2000-12-20.farmer.ham.txt\n",
            "0597.2000-03-11.farmer.ham.txt\t3158.2000-12-21.farmer.ham.txt\n",
            "0599.2000-03-11.farmer.ham.txt\t3160.2000-12-21.farmer.ham.txt\n",
            "0600.2000-03-13.farmer.ham.txt\t3162.2000-12-21.farmer.ham.txt\n",
            "0601.2000-03-13.farmer.ham.txt\t3163.2000-12-21.farmer.ham.txt\n",
            "0602.2000-03-13.farmer.ham.txt\t3168.2000-12-21.farmer.ham.txt\n",
            "0603.2000-03-13.farmer.ham.txt\t3169.2000-12-21.farmer.ham.txt\n",
            "0604.2000-03-13.farmer.ham.txt\t3171.2000-12-21.farmer.ham.txt\n",
            "0605.2000-03-13.farmer.ham.txt\t3174.2000-12-21.farmer.ham.txt\n",
            "0606.2000-03-13.farmer.ham.txt\t3177.2000-12-21.farmer.ham.txt\n",
            "0607.2000-03-13.farmer.ham.txt\t3179.2000-12-22.farmer.ham.txt\n",
            "0608.2000-03-13.farmer.ham.txt\t3182.2000-12-22.farmer.ham.txt\n",
            "0609.2000-03-14.farmer.ham.txt\t3185.2000-12-22.farmer.ham.txt\n",
            "0610.2000-03-14.farmer.ham.txt\t3186.2000-12-26.farmer.ham.txt\n",
            "0611.2000-03-14.farmer.ham.txt\t3187.2000-12-26.farmer.ham.txt\n",
            "0613.2000-03-14.farmer.ham.txt\t3188.2000-12-26.farmer.ham.txt\n",
            "0614.2000-03-15.farmer.ham.txt\t3189.2000-12-26.farmer.ham.txt\n",
            "0616.2000-03-15.farmer.ham.txt\t3191.2000-12-26.farmer.ham.txt\n",
            "0617.2000-03-15.farmer.ham.txt\t3192.2000-12-26.farmer.ham.txt\n",
            "0618.2000-03-15.farmer.ham.txt\t3194.2000-12-27.farmer.ham.txt\n",
            "0619.2000-03-17.farmer.ham.txt\t3196.2000-12-27.farmer.ham.txt\n",
            "0620.2000-03-17.farmer.ham.txt\t3197.2000-12-27.farmer.ham.txt\n",
            "0623.2000-03-18.farmer.ham.txt\t3198.2000-12-27.farmer.ham.txt\n",
            "0624.2000-03-19.farmer.ham.txt\t3199.2000-12-27.farmer.ham.txt\n",
            "0627.2000-03-20.farmer.ham.txt\t3200.2000-12-27.farmer.ham.txt\n",
            "0628.2000-03-20.farmer.ham.txt\t3202.2000-12-27.farmer.ham.txt\n",
            "0629.2000-03-20.farmer.ham.txt\t3203.2000-12-27.farmer.ham.txt\n",
            "0631.2000-03-20.farmer.ham.txt\t3204.2000-12-28.farmer.ham.txt\n",
            "0632.2000-03-20.farmer.ham.txt\t3205.2000-12-28.farmer.ham.txt\n",
            "0633.2000-03-20.farmer.ham.txt\t3206.2000-12-28.farmer.ham.txt\n",
            "0635.2000-03-20.farmer.ham.txt\t3208.2000-12-28.farmer.ham.txt\n",
            "0636.2000-03-20.farmer.ham.txt\t3209.2000-12-28.farmer.ham.txt\n",
            "0637.2000-03-20.farmer.ham.txt\t3210.2000-12-28.farmer.ham.txt\n",
            "0638.2000-03-20.farmer.ham.txt\t3211.2000-12-28.farmer.ham.txt\n",
            "0639.2000-03-20.farmer.ham.txt\t3212.2000-12-28.farmer.ham.txt\n",
            "0641.2000-03-20.farmer.ham.txt\t3213.2000-12-28.farmer.ham.txt\n",
            "0642.2000-03-20.farmer.ham.txt\t3215.2000-12-28.farmer.ham.txt\n",
            "0643.2000-03-20.farmer.ham.txt\t3216.2000-12-28.farmer.ham.txt\n",
            "0645.2000-03-20.farmer.ham.txt\t3219.2000-12-28.farmer.ham.txt\n",
            "0646.2000-03-21.farmer.ham.txt\t3220.2000-12-28.farmer.ham.txt\n",
            "0648.2000-03-21.farmer.ham.txt\t3223.2000-12-29.farmer.ham.txt\n",
            "0649.2000-03-21.farmer.ham.txt\t3224.2000-12-29.farmer.ham.txt\n",
            "0650.2000-03-21.farmer.ham.txt\t3225.2000-12-29.farmer.ham.txt\n",
            "0652.2000-03-21.farmer.ham.txt\t3226.2001-01-01.farmer.ham.txt\n",
            "0653.2000-03-21.farmer.ham.txt\t3227.2001-01-01.farmer.ham.txt\n",
            "0654.2000-03-21.farmer.ham.txt\t3228.2001-01-01.farmer.ham.txt\n",
            "0655.2000-03-21.farmer.ham.txt\t3229.2001-01-02.farmer.ham.txt\n",
            "0656.2000-03-21.farmer.ham.txt\t3231.2001-01-02.farmer.ham.txt\n",
            "0659.2000-03-21.farmer.ham.txt\t3232.2001-01-02.farmer.ham.txt\n",
            "0662.2000-03-21.farmer.ham.txt\t3233.2001-01-02.farmer.ham.txt\n",
            "0664.2000-03-21.farmer.ham.txt\t3234.2001-01-02.farmer.ham.txt\n",
            "0665.2000-03-21.farmer.ham.txt\t3236.2001-01-02.farmer.ham.txt\n",
            "0666.2000-03-21.farmer.ham.txt\t3237.2001-01-02.farmer.ham.txt\n",
            "0669.2000-03-21.farmer.ham.txt\t3240.2001-01-02.farmer.ham.txt\n",
            "0672.2000-03-21.farmer.ham.txt\t3242.2001-01-02.farmer.ham.txt\n",
            "0675.2000-03-21.farmer.ham.txt\t3243.2001-01-03.farmer.ham.txt\n",
            "0676.2000-03-22.farmer.ham.txt\t3244.2001-01-03.farmer.ham.txt\n",
            "0677.2000-03-22.farmer.ham.txt\t3246.2001-01-03.farmer.ham.txt\n",
            "0678.2000-03-22.farmer.ham.txt\t3249.2001-01-03.farmer.ham.txt\n",
            "0679.2000-03-22.farmer.ham.txt\t3250.2001-01-03.farmer.ham.txt\n",
            "0680.2000-03-22.farmer.ham.txt\t3251.2001-01-03.farmer.ham.txt\n",
            "0681.2000-03-22.farmer.ham.txt\t3252.2001-01-03.farmer.ham.txt\n",
            "0683.2000-03-22.farmer.ham.txt\t3253.2001-01-04.farmer.ham.txt\n",
            "0684.2000-03-22.farmer.ham.txt\t3254.2001-01-04.farmer.ham.txt\n",
            "0685.2000-03-22.farmer.ham.txt\t3256.2001-01-04.farmer.ham.txt\n",
            "0688.2000-03-22.farmer.ham.txt\t3258.2001-01-04.farmer.ham.txt\n",
            "0689.2000-03-22.farmer.ham.txt\t3259.2001-01-05.farmer.ham.txt\n",
            "0690.2000-03-22.farmer.ham.txt\t3260.2001-01-05.farmer.ham.txt\n",
            "0691.2000-03-22.farmer.ham.txt\t3261.2001-01-05.farmer.ham.txt\n",
            "0694.2000-03-22.farmer.ham.txt\t3263.2001-01-05.farmer.ham.txt\n",
            "0696.2000-03-22.farmer.ham.txt\t3264.2001-01-05.farmer.ham.txt\n",
            "0698.2000-03-22.farmer.ham.txt\t3267.2001-01-05.farmer.ham.txt\n",
            "0700.2000-03-23.farmer.ham.txt\t3269.2001-01-05.farmer.ham.txt\n",
            "0701.2000-03-23.farmer.ham.txt\t3270.2001-01-05.farmer.ham.txt\n",
            "0702.2000-03-23.farmer.ham.txt\t3271.2001-01-06.farmer.ham.txt\n",
            "0703.2000-03-23.farmer.ham.txt\t3272.2001-01-08.farmer.ham.txt\n",
            "0704.2000-03-23.farmer.ham.txt\t3273.2001-01-08.farmer.ham.txt\n",
            "0706.2000-03-23.farmer.ham.txt\t3274.2001-01-08.farmer.ham.txt\n",
            "0708.2000-03-23.farmer.ham.txt\t3276.2001-01-08.farmer.ham.txt\n",
            "0711.2000-03-23.farmer.ham.txt\t3277.2001-01-08.farmer.ham.txt\n",
            "0713.2000-03-23.farmer.ham.txt\t3279.2001-01-08.farmer.ham.txt\n",
            "0714.2000-03-24.farmer.ham.txt\t3280.2001-01-08.farmer.ham.txt\n",
            "0715.2000-03-24.farmer.ham.txt\t3282.2001-01-08.farmer.ham.txt\n",
            "0716.2000-03-24.farmer.ham.txt\t3283.2001-01-09.farmer.ham.txt\n",
            "0719.2000-03-24.farmer.ham.txt\t3284.2001-01-09.farmer.ham.txt\n",
            "0720.2000-03-24.farmer.ham.txt\t3285.2001-01-09.farmer.ham.txt\n",
            "0722.2000-03-24.farmer.ham.txt\t3286.2001-01-09.farmer.ham.txt\n",
            "0724.2000-03-24.farmer.ham.txt\t3287.2001-01-09.farmer.ham.txt\n",
            "0725.2000-03-24.farmer.ham.txt\t3289.2001-01-09.farmer.ham.txt\n",
            "0727.2000-03-24.farmer.ham.txt\t3290.2001-01-09.farmer.ham.txt\n",
            "0728.2000-03-25.farmer.ham.txt\t3292.2001-01-09.farmer.ham.txt\n",
            "0729.2000-03-26.farmer.ham.txt\t3293.2001-01-10.farmer.ham.txt\n",
            "0730.2000-03-27.farmer.ham.txt\t3294.2001-01-10.farmer.ham.txt\n",
            "0731.2000-03-27.farmer.ham.txt\t3295.2001-01-10.farmer.ham.txt\n",
            "0732.2000-03-27.farmer.ham.txt\t3296.2001-01-10.farmer.ham.txt\n",
            "0735.2000-03-27.farmer.ham.txt\t3297.2001-01-10.farmer.ham.txt\n",
            "0736.2000-03-27.farmer.ham.txt\t3298.2001-01-10.farmer.ham.txt\n",
            "0738.2000-03-27.farmer.ham.txt\t3300.2001-01-10.farmer.ham.txt\n",
            "0739.2000-03-27.farmer.ham.txt\t3301.2001-01-10.farmer.ham.txt\n",
            "0740.2000-03-27.farmer.ham.txt\t3303.2001-01-10.farmer.ham.txt\n",
            "0741.2000-03-27.farmer.ham.txt\t3305.2001-01-10.farmer.ham.txt\n",
            "0742.2000-03-27.farmer.ham.txt\t3306.2001-01-10.farmer.ham.txt\n",
            "0743.2000-03-27.farmer.ham.txt\t3307.2001-01-10.farmer.ham.txt\n",
            "0744.2000-03-27.farmer.ham.txt\t3308.2001-01-10.farmer.ham.txt\n",
            "0745.2000-03-27.farmer.ham.txt\t3309.2001-01-10.farmer.ham.txt\n",
            "0748.2000-03-27.farmer.ham.txt\t3310.2001-01-10.farmer.ham.txt\n",
            "0749.2000-03-28.farmer.ham.txt\t3311.2001-01-10.farmer.ham.txt\n",
            "0752.2000-03-28.farmer.ham.txt\t3314.2001-01-10.farmer.ham.txt\n",
            "0753.2000-03-28.farmer.ham.txt\t3316.2001-01-11.farmer.ham.txt\n",
            "0755.2000-03-28.farmer.ham.txt\t3317.2001-01-11.farmer.ham.txt\n",
            "0756.2000-03-28.farmer.ham.txt\t3318.2001-01-11.farmer.ham.txt\n",
            "0757.2000-03-28.farmer.ham.txt\t3320.2001-01-11.farmer.ham.txt\n",
            "0759.2000-03-28.farmer.ham.txt\t3323.2001-01-11.farmer.ham.txt\n",
            "0761.2000-03-28.farmer.ham.txt\t3324.2001-01-11.farmer.ham.txt\n",
            "0765.2000-03-28.farmer.ham.txt\t3325.2001-01-11.farmer.ham.txt\n",
            "0766.2000-03-28.farmer.ham.txt\t3326.2001-01-11.farmer.ham.txt\n",
            "0768.2000-03-28.farmer.ham.txt\t3327.2001-01-11.farmer.ham.txt\n",
            "0769.2000-03-28.farmer.ham.txt\t3329.2001-01-12.farmer.ham.txt\n",
            "0770.2000-03-28.farmer.ham.txt\t3331.2001-01-12.farmer.ham.txt\n",
            "0771.2000-03-28.farmer.ham.txt\t3333.2001-01-12.farmer.ham.txt\n",
            "0772.2000-03-28.farmer.ham.txt\t3334.2001-01-12.farmer.ham.txt\n",
            "0773.2000-03-28.farmer.ham.txt\t3335.2001-01-12.farmer.ham.txt\n",
            "0774.2000-03-28.farmer.ham.txt\t3336.2001-01-12.farmer.ham.txt\n",
            "0776.2000-03-28.farmer.ham.txt\t3337.2001-01-12.farmer.ham.txt\n",
            "0777.2000-03-28.farmer.ham.txt\t3339.2001-01-12.farmer.ham.txt\n",
            "0778.2000-03-28.farmer.ham.txt\t3340.2001-01-12.farmer.ham.txt\n",
            "0780.2000-03-28.farmer.ham.txt\t3341.2001-01-12.farmer.ham.txt\n",
            "0781.2000-03-29.farmer.ham.txt\t3342.2001-01-12.farmer.ham.txt\n",
            "0782.2000-03-29.farmer.ham.txt\t3344.2001-01-12.farmer.ham.txt\n",
            "0783.2000-03-29.farmer.ham.txt\t3345.2001-01-13.farmer.ham.txt\n",
            "0785.2000-03-29.farmer.ham.txt\t3347.2001-01-15.farmer.ham.txt\n",
            "0787.2000-03-29.farmer.ham.txt\t3348.2001-01-15.farmer.ham.txt\n",
            "0789.2000-03-29.farmer.ham.txt\t3349.2001-01-15.farmer.ham.txt\n",
            "0790.2000-03-29.farmer.ham.txt\t3350.2001-01-16.farmer.ham.txt\n",
            "0792.2000-03-29.farmer.ham.txt\t3351.2001-01-16.farmer.ham.txt\n",
            "0793.2000-03-29.farmer.ham.txt\t3354.2001-01-16.farmer.ham.txt\n",
            "0795.2000-03-30.farmer.ham.txt\t3355.2001-01-16.farmer.ham.txt\n",
            "0796.2000-03-30.farmer.ham.txt\t3356.2001-01-16.farmer.ham.txt\n",
            "0798.2000-03-31.farmer.ham.txt\t3359.2001-01-17.farmer.ham.txt\n",
            "0800.2000-03-31.farmer.ham.txt\t3360.2001-01-17.farmer.ham.txt\n",
            "0801.2000-03-31.farmer.ham.txt\t3362.2001-01-17.farmer.ham.txt\n",
            "0802.2000-03-31.farmer.ham.txt\t3363.2001-01-17.farmer.ham.txt\n",
            "0804.2000-03-31.farmer.ham.txt\t3365.2001-01-17.farmer.ham.txt\n",
            "0806.2000-03-31.farmer.ham.txt\t3366.2001-01-17.farmer.ham.txt\n",
            "0807.2000-03-31.farmer.ham.txt\t3368.2001-01-18.farmer.ham.txt\n",
            "0808.2000-03-31.farmer.ham.txt\t3369.2001-01-18.farmer.ham.txt\n",
            "0809.2000-03-31.farmer.ham.txt\t3370.2001-01-18.farmer.ham.txt\n",
            "0812.2000-04-03.farmer.ham.txt\t3372.2001-01-18.farmer.ham.txt\n",
            "0813.2000-04-03.farmer.ham.txt\t3373.2001-01-18.farmer.ham.txt\n",
            "0815.2000-04-03.farmer.ham.txt\t3374.2001-01-18.farmer.ham.txt\n",
            "0816.2000-04-03.farmer.ham.txt\t3375.2001-01-19.farmer.ham.txt\n",
            "0817.2000-04-03.farmer.ham.txt\t3376.2001-01-19.farmer.ham.txt\n",
            "0818.2000-04-03.farmer.ham.txt\t3378.2001-01-19.farmer.ham.txt\n",
            "0819.2000-04-03.farmer.ham.txt\t3379.2001-01-19.farmer.ham.txt\n",
            "0821.2000-04-03.farmer.ham.txt\t3380.2001-01-19.farmer.ham.txt\n",
            "0822.2000-04-03.farmer.ham.txt\t3381.2001-01-19.farmer.ham.txt\n",
            "0823.2000-04-03.farmer.ham.txt\t3382.2001-01-20.farmer.ham.txt\n",
            "0824.2000-04-03.farmer.ham.txt\t3385.2001-01-21.farmer.ham.txt\n",
            "0825.2000-04-03.farmer.ham.txt\t3386.2001-01-22.farmer.ham.txt\n",
            "0826.2000-04-03.farmer.ham.txt\t3387.2001-01-22.farmer.ham.txt\n",
            "0827.2000-04-04.farmer.ham.txt\t3389.2001-01-22.farmer.ham.txt\n",
            "0828.2000-04-04.farmer.ham.txt\t3390.2001-01-22.farmer.ham.txt\n",
            "0829.2000-04-04.farmer.ham.txt\t3391.2001-01-22.farmer.ham.txt\n",
            "0831.2000-04-04.farmer.ham.txt\t3392.2001-01-22.farmer.ham.txt\n",
            "0832.2000-04-04.farmer.ham.txt\t3393.2001-01-22.farmer.ham.txt\n",
            "0833.2000-04-04.farmer.ham.txt\t3394.2001-01-22.farmer.ham.txt\n",
            "0834.2000-04-04.farmer.ham.txt\t3396.2001-01-22.farmer.ham.txt\n",
            "0837.2000-04-04.farmer.ham.txt\t3399.2001-01-23.farmer.ham.txt\n",
            "0839.2000-04-04.farmer.ham.txt\t3401.2001-01-23.farmer.ham.txt\n",
            "0841.2000-04-04.farmer.ham.txt\t3402.2001-01-23.farmer.ham.txt\n",
            "0843.2000-04-04.farmer.ham.txt\t3403.2001-01-23.farmer.ham.txt\n",
            "0845.2000-04-04.farmer.ham.txt\t3404.2001-01-23.farmer.ham.txt\n",
            "0846.2000-04-04.farmer.ham.txt\t3405.2001-01-23.farmer.ham.txt\n",
            "0848.2000-04-05.farmer.ham.txt\t3407.2001-01-23.farmer.ham.txt\n",
            "0850.2000-04-05.farmer.ham.txt\t3409.2001-01-23.farmer.ham.txt\n",
            "0851.2000-04-05.farmer.ham.txt\t3410.2001-01-24.farmer.ham.txt\n",
            "0852.2000-04-05.farmer.ham.txt\t3411.2001-01-24.farmer.ham.txt\n",
            "0853.2000-04-05.farmer.ham.txt\t3412.2001-01-24.farmer.ham.txt\n",
            "0855.2000-04-05.farmer.ham.txt\t3413.2001-01-24.farmer.ham.txt\n",
            "0856.2000-04-05.farmer.ham.txt\t3414.2001-01-24.farmer.ham.txt\n",
            "0857.2000-04-05.farmer.ham.txt\t3415.2001-01-24.farmer.ham.txt\n",
            "0859.2000-04-05.farmer.ham.txt\t3416.2001-01-24.farmer.ham.txt\n",
            "0860.2000-04-05.farmer.ham.txt\t3417.2001-01-24.farmer.ham.txt\n",
            "0863.2000-04-05.farmer.ham.txt\t3418.2001-01-25.farmer.ham.txt\n",
            "0864.2000-04-05.farmer.ham.txt\t3420.2001-01-25.farmer.ham.txt\n",
            "0866.2000-04-05.farmer.ham.txt\t3423.2001-01-25.farmer.ham.txt\n",
            "0868.2000-04-06.farmer.ham.txt\t3424.2001-01-25.farmer.ham.txt\n",
            "0869.2000-04-06.farmer.ham.txt\t3425.2001-01-25.farmer.ham.txt\n",
            "0870.2000-04-06.farmer.ham.txt\t3426.2001-01-25.farmer.ham.txt\n",
            "0872.2000-04-06.farmer.ham.txt\t3427.2001-01-25.farmer.ham.txt\n",
            "0873.2000-04-06.farmer.ham.txt\t3429.2001-01-25.farmer.ham.txt\n",
            "0875.2000-04-06.farmer.ham.txt\t3430.2001-01-25.farmer.ham.txt\n",
            "0876.2000-04-06.farmer.ham.txt\t3431.2001-01-25.farmer.ham.txt\n",
            "0877.2000-04-06.farmer.ham.txt\t3432.2001-01-25.farmer.ham.txt\n",
            "0878.2000-04-06.farmer.ham.txt\t3434.2001-01-25.farmer.ham.txt\n",
            "0879.2000-04-06.farmer.ham.txt\t3435.2001-01-25.farmer.ham.txt\n",
            "0880.2000-04-06.farmer.ham.txt\t3436.2001-01-25.farmer.ham.txt\n",
            "0882.2000-04-06.farmer.ham.txt\t3437.2001-01-25.farmer.ham.txt\n",
            "0884.2000-04-06.farmer.ham.txt\t3438.2001-01-25.farmer.ham.txt\n",
            "0885.2000-04-07.farmer.ham.txt\t3439.2001-01-26.farmer.ham.txt\n",
            "0886.2000-04-07.farmer.ham.txt\t3440.2001-01-26.farmer.ham.txt\n",
            "0888.2000-04-07.farmer.ham.txt\t3444.2001-01-26.farmer.ham.txt\n",
            "0890.2000-04-07.farmer.ham.txt\t3445.2001-01-26.farmer.ham.txt\n",
            "0892.2000-04-07.farmer.ham.txt\t3446.2001-01-26.farmer.ham.txt\n",
            "0894.2000-04-10.farmer.ham.txt\t3447.2001-01-26.farmer.ham.txt\n",
            "0896.2000-04-10.farmer.ham.txt\t3450.2001-01-26.farmer.ham.txt\n",
            "0898.2000-04-10.farmer.ham.txt\t3451.2001-01-26.farmer.ham.txt\n",
            "0900.2000-04-10.farmer.ham.txt\t3454.2001-01-26.farmer.ham.txt\n",
            "0901.2000-04-10.farmer.ham.txt\t3456.2001-01-26.farmer.ham.txt\n",
            "0902.2000-04-10.farmer.ham.txt\t3457.2001-01-28.farmer.ham.txt\n",
            "0904.2000-04-11.farmer.ham.txt\t3458.2001-01-29.farmer.ham.txt\n",
            "0906.2000-04-11.farmer.ham.txt\t3459.2001-01-29.farmer.ham.txt\n",
            "0907.2000-04-11.farmer.ham.txt\t3461.2001-01-29.farmer.ham.txt\n",
            "0908.2000-04-11.farmer.ham.txt\t3462.2001-01-29.farmer.ham.txt\n",
            "0909.2000-04-11.farmer.ham.txt\t3463.2001-01-29.farmer.ham.txt\n",
            "0911.2000-04-11.farmer.ham.txt\t3464.2001-01-29.farmer.ham.txt\n",
            "0912.2000-04-11.farmer.ham.txt\t3466.2001-01-29.farmer.ham.txt\n",
            "0915.2000-04-11.farmer.ham.txt\t3467.2001-01-29.farmer.ham.txt\n",
            "0916.2000-04-12.farmer.ham.txt\t3469.2001-01-29.farmer.ham.txt\n",
            "0917.2000-04-12.farmer.ham.txt\t3470.2001-01-29.farmer.ham.txt\n",
            "0918.2000-04-12.farmer.ham.txt\t3472.2001-01-29.farmer.ham.txt\n",
            "0919.2000-04-12.farmer.ham.txt\t3473.2001-01-30.farmer.ham.txt\n",
            "0921.2000-04-12.farmer.ham.txt\t3474.2001-01-30.farmer.ham.txt\n",
            "0922.2000-04-12.farmer.ham.txt\t3477.2001-01-30.farmer.ham.txt\n",
            "0923.2000-04-13.farmer.ham.txt\t3478.2001-01-30.farmer.ham.txt\n",
            "0925.2000-04-13.farmer.ham.txt\t3479.2001-01-30.farmer.ham.txt\n",
            "0926.2000-04-13.farmer.ham.txt\t3480.2001-01-30.farmer.ham.txt\n",
            "0927.2000-04-13.farmer.ham.txt\t3481.2001-01-30.farmer.ham.txt\n",
            "0929.2000-04-13.farmer.ham.txt\t3482.2001-01-30.farmer.ham.txt\n",
            "0930.2000-04-13.farmer.ham.txt\t3484.2001-01-31.farmer.ham.txt\n",
            "0932.2000-04-13.farmer.ham.txt\t3485.2001-01-31.farmer.ham.txt\n",
            "0933.2000-04-13.farmer.ham.txt\t3487.2001-01-31.farmer.ham.txt\n",
            "0935.2000-04-14.farmer.ham.txt\t3488.2001-01-31.farmer.ham.txt\n",
            "0936.2000-04-14.farmer.ham.txt\t3489.2001-01-31.farmer.ham.txt\n",
            "0937.2000-04-14.farmer.ham.txt\t3490.2001-01-31.farmer.ham.txt\n",
            "0939.2000-04-14.farmer.ham.txt\t3491.2001-01-31.farmer.ham.txt\n",
            "0940.2000-04-14.farmer.ham.txt\t3492.2001-01-31.farmer.ham.txt\n",
            "0942.2000-04-14.farmer.ham.txt\t3493.2001-02-01.farmer.ham.txt\n",
            "0943.2000-04-14.farmer.ham.txt\t3494.2001-02-01.farmer.ham.txt\n",
            "0944.2000-04-14.farmer.ham.txt\t3495.2001-02-01.farmer.ham.txt\n",
            "0945.2000-04-17.farmer.ham.txt\t3496.2001-02-01.farmer.ham.txt\n",
            "0946.2000-04-17.farmer.ham.txt\t3498.2001-02-01.farmer.ham.txt\n",
            "0947.2000-04-17.farmer.ham.txt\t3500.2001-02-01.farmer.ham.txt\n",
            "0948.2000-04-17.farmer.ham.txt\t3501.2001-02-01.farmer.ham.txt\n",
            "0949.2000-04-17.farmer.ham.txt\t3503.2001-02-01.farmer.ham.txt\n",
            "0951.2000-04-17.farmer.ham.txt\t3506.2001-02-01.farmer.ham.txt\n",
            "0955.2000-04-18.farmer.ham.txt\t3507.2001-02-01.farmer.ham.txt\n",
            "0956.2000-04-19.farmer.ham.txt\t3508.2001-02-01.farmer.ham.txt\n",
            "0958.2000-04-19.farmer.ham.txt\t3509.2001-02-01.farmer.ham.txt\n",
            "0959.2000-04-19.farmer.ham.txt\t3510.2001-02-01.farmer.ham.txt\n",
            "0960.2000-04-19.farmer.ham.txt\t3511.2001-02-01.farmer.ham.txt\n",
            "0961.2000-04-19.farmer.ham.txt\t3514.2001-02-02.farmer.ham.txt\n",
            "0964.2000-04-19.farmer.ham.txt\t3516.2001-02-02.farmer.ham.txt\n",
            "0965.2000-04-19.farmer.ham.txt\t3518.2001-02-02.farmer.ham.txt\n",
            "0966.2000-04-19.farmer.ham.txt\t3519.2001-02-02.farmer.ham.txt\n",
            "0968.2000-04-19.farmer.ham.txt\t3520.2001-02-05.farmer.ham.txt\n",
            "0970.2000-04-19.farmer.ham.txt\t3521.2001-02-05.farmer.ham.txt\n",
            "0972.2000-04-19.farmer.ham.txt\t3522.2001-02-05.farmer.ham.txt\n",
            "0973.2000-04-20.farmer.ham.txt\t3524.2001-02-05.farmer.ham.txt\n",
            "0974.2000-04-20.farmer.ham.txt\t3525.2001-02-05.farmer.ham.txt\n",
            "0975.2000-04-20.farmer.ham.txt\t3527.2001-02-05.farmer.ham.txt\n",
            "0976.2000-04-20.farmer.ham.txt\t3528.2001-02-05.farmer.ham.txt\n",
            "0978.2000-04-20.farmer.ham.txt\t3529.2001-02-05.farmer.ham.txt\n",
            "0979.2000-04-24.farmer.ham.txt\t3532.2001-02-06.farmer.ham.txt\n",
            "0980.2000-04-24.farmer.ham.txt\t3534.2001-02-06.farmer.ham.txt\n",
            "0981.2000-04-24.farmer.ham.txt\t3535.2001-02-06.farmer.ham.txt\n",
            "0982.2000-04-24.farmer.ham.txt\t3537.2001-02-06.farmer.ham.txt\n",
            "0983.2000-04-24.farmer.ham.txt\t3538.2001-02-06.farmer.ham.txt\n",
            "0985.2000-04-24.farmer.ham.txt\t3539.2001-02-06.farmer.ham.txt\n",
            "0986.2000-04-24.farmer.ham.txt\t3541.2001-02-06.farmer.ham.txt\n",
            "0987.2000-04-24.farmer.ham.txt\t3543.2001-02-06.farmer.ham.txt\n",
            "0988.2000-04-24.farmer.ham.txt\t3544.2001-02-07.farmer.ham.txt\n",
            "0989.2000-04-24.farmer.ham.txt\t3545.2001-02-07.farmer.ham.txt\n",
            "0990.2000-04-25.farmer.ham.txt\t3546.2001-02-07.farmer.ham.txt\n",
            "0991.2000-04-25.farmer.ham.txt\t3548.2001-02-07.farmer.ham.txt\n",
            "0993.2000-04-25.farmer.ham.txt\t3549.2001-02-07.farmer.ham.txt\n",
            "0994.2000-04-25.farmer.ham.txt\t3550.2001-02-07.farmer.ham.txt\n",
            "0996.2000-04-25.farmer.ham.txt\t3551.2001-02-08.farmer.ham.txt\n",
            "0998.2000-04-25.farmer.ham.txt\t3552.2001-02-08.farmer.ham.txt\n",
            "0999.2000-04-25.farmer.ham.txt\t3553.2001-02-08.farmer.ham.txt\n",
            "1000.2000-04-26.farmer.ham.txt\t3557.2001-02-09.farmer.ham.txt\n",
            "1001.2000-04-26.farmer.ham.txt\t3558.2001-02-09.farmer.ham.txt\n",
            "1002.2000-04-26.farmer.ham.txt\t3559.2001-02-09.farmer.ham.txt\n",
            "1003.2000-04-26.farmer.ham.txt\t3560.2001-02-09.farmer.ham.txt\n",
            "1004.2000-04-26.farmer.ham.txt\t3561.2001-02-09.farmer.ham.txt\n",
            "1006.2000-04-27.farmer.ham.txt\t3563.2001-02-10.farmer.ham.txt\n",
            "1007.2000-04-27.farmer.ham.txt\t3565.2001-02-12.farmer.ham.txt\n",
            "1009.2000-04-27.farmer.ham.txt\t3566.2001-02-12.farmer.ham.txt\n",
            "1010.2000-04-28.farmer.ham.txt\t3567.2001-02-12.farmer.ham.txt\n",
            "1012.2000-04-28.farmer.ham.txt\t3569.2001-02-12.farmer.ham.txt\n",
            "1013.2000-04-28.farmer.ham.txt\t3571.2001-02-12.farmer.ham.txt\n",
            "1015.2000-05-01.farmer.ham.txt\t3572.2001-02-12.farmer.ham.txt\n",
            "1016.2000-05-01.farmer.ham.txt\t3575.2001-02-13.farmer.ham.txt\n",
            "1017.2000-05-01.farmer.ham.txt\t3576.2001-02-13.farmer.ham.txt\n",
            "1020.2000-05-01.farmer.ham.txt\t3577.2001-02-13.farmer.ham.txt\n",
            "1021.2000-05-01.farmer.ham.txt\t3578.2001-02-14.farmer.ham.txt\n",
            "1022.2000-05-01.farmer.ham.txt\t3580.2001-02-14.farmer.ham.txt\n",
            "1024.2000-05-01.farmer.ham.txt\t3581.2001-02-14.farmer.ham.txt\n",
            "1025.2000-05-01.farmer.ham.txt\t3583.2001-02-15.farmer.ham.txt\n",
            "1026.2000-05-02.farmer.ham.txt\t3585.2001-02-15.farmer.ham.txt\n",
            "1028.2000-05-02.farmer.ham.txt\t3586.2001-02-15.farmer.ham.txt\n",
            "1029.2000-05-02.farmer.ham.txt\t3587.2001-02-15.farmer.ham.txt\n",
            "1030.2000-05-02.farmer.ham.txt\t3588.2001-02-16.farmer.ham.txt\n",
            "1031.2000-05-03.farmer.ham.txt\t3589.2001-02-16.farmer.ham.txt\n",
            "1032.2000-05-03.farmer.ham.txt\t3592.2001-02-16.farmer.ham.txt\n",
            "1034.2000-05-03.farmer.ham.txt\t3593.2001-02-16.farmer.ham.txt\n",
            "1035.2000-05-03.farmer.ham.txt\t3594.2001-02-16.farmer.ham.txt\n",
            "1036.2000-05-04.farmer.ham.txt\t3595.2001-02-16.farmer.ham.txt\n",
            "1039.2000-05-04.farmer.ham.txt\t3596.2001-02-16.farmer.ham.txt\n",
            "1041.2000-05-04.farmer.ham.txt\t3599.2001-02-16.farmer.ham.txt\n",
            "1042.2000-05-05.farmer.ham.txt\t3600.2001-02-18.farmer.ham.txt\n",
            "1043.2000-05-05.farmer.ham.txt\t3601.2001-02-18.farmer.ham.txt\n",
            "1045.2000-05-05.farmer.ham.txt\t3602.2001-02-19.farmer.ham.txt\n",
            "1047.2000-05-08.farmer.ham.txt\t3603.2001-02-20.farmer.ham.txt\n",
            "1049.2000-05-08.farmer.ham.txt\t3605.2001-02-20.farmer.ham.txt\n",
            "1050.2000-05-08.farmer.ham.txt\t3606.2001-02-20.farmer.ham.txt\n",
            "1051.2000-05-08.farmer.ham.txt\t3608.2001-02-20.farmer.ham.txt\n",
            "1052.2000-05-08.farmer.ham.txt\t3609.2001-02-20.farmer.ham.txt\n",
            "1054.2000-05-08.farmer.ham.txt\t3611.2001-02-20.farmer.ham.txt\n",
            "1055.2000-05-09.farmer.ham.txt\t3612.2001-02-21.farmer.ham.txt\n",
            "1056.2000-05-09.farmer.ham.txt\t3613.2001-02-21.farmer.ham.txt\n",
            "1058.2000-05-09.farmer.ham.txt\t3616.2001-02-21.farmer.ham.txt\n",
            "1059.2000-05-09.farmer.ham.txt\t3617.2001-02-21.farmer.ham.txt\n",
            "1060.2000-05-10.farmer.ham.txt\t3619.2001-02-21.farmer.ham.txt\n",
            "1061.2000-05-10.farmer.ham.txt\t3622.2001-02-21.farmer.ham.txt\n",
            "1062.2000-05-11.farmer.ham.txt\t3623.2001-02-21.farmer.ham.txt\n",
            "1063.2000-05-11.farmer.ham.txt\t3625.2001-02-21.farmer.ham.txt\n",
            "1064.2000-05-11.farmer.ham.txt\t3626.2001-02-21.farmer.ham.txt\n",
            "1065.2000-05-11.farmer.ham.txt\t3627.2001-02-21.farmer.ham.txt\n",
            "1067.2000-05-11.farmer.ham.txt\t3628.2001-02-21.farmer.ham.txt\n",
            "1068.2000-05-11.farmer.ham.txt\t3629.2001-02-21.farmer.ham.txt\n",
            "1069.2000-05-12.farmer.ham.txt\t3630.2001-02-21.farmer.ham.txt\n",
            "1070.2000-05-12.farmer.ham.txt\t3631.2001-02-22.farmer.ham.txt\n",
            "1071.2000-05-12.farmer.ham.txt\t3632.2001-02-22.farmer.ham.txt\n",
            "1072.2000-05-12.farmer.ham.txt\t3633.2001-02-22.farmer.ham.txt\n",
            "1073.2000-05-14.farmer.ham.txt\t3634.2001-02-22.farmer.ham.txt\n",
            "1074.2000-05-15.farmer.ham.txt\t3635.2001-02-22.farmer.ham.txt\n",
            "1075.2000-05-15.farmer.ham.txt\t3636.2001-02-22.farmer.ham.txt\n",
            "1077.2000-05-16.farmer.ham.txt\t3638.2001-02-22.farmer.ham.txt\n",
            "1079.2000-05-16.farmer.ham.txt\t3639.2001-02-22.farmer.ham.txt\n",
            "1080.2000-05-17.farmer.ham.txt\t3640.2001-02-22.farmer.ham.txt\n",
            "1081.2000-05-17.farmer.ham.txt\t3641.2001-02-22.farmer.ham.txt\n",
            "1083.2000-05-17.farmer.ham.txt\t3642.2001-02-22.farmer.ham.txt\n",
            "1084.2000-05-17.farmer.ham.txt\t3643.2001-02-22.farmer.ham.txt\n",
            "1086.2000-05-18.farmer.ham.txt\t3645.2001-02-23.farmer.ham.txt\n",
            "1087.2000-05-18.farmer.ham.txt\t3646.2001-02-23.farmer.ham.txt\n",
            "1088.2000-05-18.farmer.ham.txt\t3647.2001-02-23.farmer.ham.txt\n",
            "1089.2000-05-18.farmer.ham.txt\t3648.2001-02-23.farmer.ham.txt\n",
            "1090.2000-05-18.farmer.ham.txt\t3650.2001-02-23.farmer.ham.txt\n",
            "1091.2000-05-19.farmer.ham.txt\t3652.2001-02-23.farmer.ham.txt\n",
            "1094.2000-05-19.farmer.ham.txt\t3653.2001-02-23.farmer.ham.txt\n",
            "1097.2000-05-19.farmer.ham.txt\t3654.2001-02-23.farmer.ham.txt\n",
            "1098.2000-05-19.farmer.ham.txt\t3655.2001-02-23.farmer.ham.txt\n",
            "1100.2000-05-19.farmer.ham.txt\t3657.2001-02-23.farmer.ham.txt\n",
            "1101.2000-05-19.farmer.ham.txt\t3658.2001-02-23.farmer.ham.txt\n",
            "1102.2000-05-19.farmer.ham.txt\t3659.2001-02-23.farmer.ham.txt\n",
            "1103.2000-05-22.farmer.ham.txt\t3662.2001-02-23.farmer.ham.txt\n",
            "1105.2000-05-22.farmer.ham.txt\t3663.2001-02-23.farmer.ham.txt\n",
            "1106.2000-05-22.farmer.ham.txt\t3664.2001-02-23.farmer.ham.txt\n",
            "1108.2000-05-22.farmer.ham.txt\t3665.2001-02-25.farmer.ham.txt\n",
            "1109.2000-05-22.farmer.ham.txt\t3667.2001-02-26.farmer.ham.txt\n",
            "1110.2000-05-22.farmer.ham.txt\t3669.2001-02-26.farmer.ham.txt\n",
            "1111.2000-05-22.farmer.ham.txt\t3670.2001-02-26.farmer.ham.txt\n",
            "1113.2000-05-22.farmer.ham.txt\t3671.2001-02-26.farmer.ham.txt\n",
            "1114.2000-05-23.farmer.ham.txt\t3673.2001-02-26.farmer.ham.txt\n",
            "1116.2000-05-23.farmer.ham.txt\t3675.2001-02-26.farmer.ham.txt\n",
            "1117.2000-05-23.farmer.ham.txt\t3676.2001-02-26.farmer.ham.txt\n",
            "1118.2000-05-23.farmer.ham.txt\t3678.2001-02-26.farmer.ham.txt\n",
            "1120.2000-05-23.farmer.ham.txt\t3679.2001-02-27.farmer.ham.txt\n",
            "1121.2000-05-23.farmer.ham.txt\t3680.2001-02-27.farmer.ham.txt\n",
            "1122.2000-05-23.farmer.ham.txt\t3682.2001-02-27.farmer.ham.txt\n",
            "1124.2000-05-23.farmer.ham.txt\t3683.2001-02-27.farmer.ham.txt\n",
            "1125.2000-05-23.farmer.ham.txt\t3684.2001-02-27.farmer.ham.txt\n",
            "1126.2000-05-24.farmer.ham.txt\t3685.2001-02-27.farmer.ham.txt\n",
            "1127.2000-05-24.farmer.ham.txt\t3686.2001-02-27.farmer.ham.txt\n",
            "1128.2000-05-24.farmer.ham.txt\t3689.2001-02-27.farmer.ham.txt\n",
            "1129.2000-05-24.farmer.ham.txt\t3690.2001-02-28.farmer.ham.txt\n",
            "1131.2000-05-24.farmer.ham.txt\t3691.2001-02-28.farmer.ham.txt\n",
            "1132.2000-05-24.farmer.ham.txt\t3692.2001-03-01.farmer.ham.txt\n",
            "1133.2000-05-24.farmer.ham.txt\t3693.2001-03-01.farmer.ham.txt\n",
            "1134.2000-05-24.farmer.ham.txt\t3694.2001-03-01.farmer.ham.txt\n",
            "1135.2000-05-24.farmer.ham.txt\t3696.2001-03-01.farmer.ham.txt\n",
            "1136.2000-05-24.farmer.ham.txt\t3697.2001-03-02.farmer.ham.txt\n",
            "1137.2000-05-24.farmer.ham.txt\t3698.2001-03-02.farmer.ham.txt\n",
            "1138.2000-05-24.farmer.ham.txt\t3699.2001-03-02.farmer.ham.txt\n",
            "1139.2000-05-25.farmer.ham.txt\t3700.2001-03-02.farmer.ham.txt\n",
            "1140.2000-05-25.farmer.ham.txt\t3701.2001-03-02.farmer.ham.txt\n",
            "1143.2000-05-25.farmer.ham.txt\t3702.2001-03-02.farmer.ham.txt\n",
            "1144.2000-05-25.farmer.ham.txt\t3703.2001-03-04.farmer.ham.txt\n",
            "1145.2000-05-25.farmer.ham.txt\t3704.2001-03-05.farmer.ham.txt\n",
            "1146.2000-05-25.farmer.ham.txt\t3705.2001-03-05.farmer.ham.txt\n",
            "1147.2000-05-25.farmer.ham.txt\t3706.2001-03-05.farmer.ham.txt\n",
            "1150.2000-05-26.farmer.ham.txt\t3707.2001-03-05.farmer.ham.txt\n",
            "1151.2000-05-26.farmer.ham.txt\t3710.2001-03-05.farmer.ham.txt\n",
            "1152.2000-05-26.farmer.ham.txt\t3712.2001-03-06.farmer.ham.txt\n",
            "1153.2000-05-26.farmer.ham.txt\t3713.2001-03-06.farmer.ham.txt\n",
            "1155.2000-05-26.farmer.ham.txt\t3715.2001-03-06.farmer.ham.txt\n",
            "1157.2000-05-26.farmer.ham.txt\t3716.2001-03-06.farmer.ham.txt\n",
            "1158.2000-05-26.farmer.ham.txt\t3718.2001-03-06.farmer.ham.txt\n",
            "1159.2000-05-30.farmer.ham.txt\t3719.2001-03-06.farmer.ham.txt\n",
            "1160.2000-05-30.farmer.ham.txt\t3720.2001-03-06.farmer.ham.txt\n",
            "1161.2000-05-30.farmer.ham.txt\t3721.2001-03-06.farmer.ham.txt\n",
            "1162.2000-05-30.farmer.ham.txt\t3722.2001-03-06.farmer.ham.txt\n",
            "1163.2000-05-30.farmer.ham.txt\t3724.2001-03-07.farmer.ham.txt\n",
            "1164.2000-05-30.farmer.ham.txt\t3725.2001-03-07.farmer.ham.txt\n",
            "1167.2000-05-30.farmer.ham.txt\t3727.2001-03-07.farmer.ham.txt\n",
            "1168.2000-05-30.farmer.ham.txt\t3729.2001-03-07.farmer.ham.txt\n",
            "1169.2000-05-30.farmer.ham.txt\t3730.2001-03-07.farmer.ham.txt\n",
            "1170.2000-05-30.farmer.ham.txt\t3731.2001-03-07.farmer.ham.txt\n",
            "1171.2000-05-30.farmer.ham.txt\t3733.2001-03-08.farmer.ham.txt\n",
            "1172.2000-05-30.farmer.ham.txt\t3734.2001-03-08.farmer.ham.txt\n",
            "1173.2000-05-31.farmer.ham.txt\t3736.2001-03-08.farmer.ham.txt\n",
            "1174.2000-05-31.farmer.ham.txt\t3738.2001-03-08.farmer.ham.txt\n",
            "1175.2000-05-31.farmer.ham.txt\t3739.2001-03-08.farmer.ham.txt\n",
            "1176.2000-05-31.farmer.ham.txt\t3740.2001-03-08.farmer.ham.txt\n",
            "1178.2000-05-31.farmer.ham.txt\t3741.2001-03-08.farmer.ham.txt\n",
            "1179.2000-05-31.farmer.ham.txt\t3742.2001-03-09.farmer.ham.txt\n",
            "1181.2000-05-31.farmer.ham.txt\t3743.2001-03-09.farmer.ham.txt\n",
            "1184.2000-05-31.farmer.ham.txt\t3744.2001-03-09.farmer.ham.txt\n",
            "1186.2000-05-31.farmer.ham.txt\t3745.2001-03-09.farmer.ham.txt\n",
            "1187.2000-05-31.farmer.ham.txt\t3747.2001-03-09.farmer.ham.txt\n",
            "1188.2000-05-31.farmer.ham.txt\t3749.2001-03-09.farmer.ham.txt\n",
            "1189.2000-05-31.farmer.ham.txt\t3750.2001-03-09.farmer.ham.txt\n",
            "1191.2000-05-31.farmer.ham.txt\t3751.2001-03-12.farmer.ham.txt\n",
            "1193.2000-06-01.farmer.ham.txt\t3752.2001-03-12.farmer.ham.txt\n",
            "1194.2000-06-01.farmer.ham.txt\t3753.2001-03-12.farmer.ham.txt\n",
            "1197.2000-06-01.farmer.ham.txt\t3754.2001-03-12.farmer.ham.txt\n",
            "1198.2000-06-01.farmer.ham.txt\t3755.2001-03-12.farmer.ham.txt\n",
            "1201.2000-06-01.farmer.ham.txt\t3757.2001-03-12.farmer.ham.txt\n",
            "1202.2000-06-01.farmer.ham.txt\t3758.2001-03-12.farmer.ham.txt\n",
            "1203.2000-06-01.farmer.ham.txt\t3759.2001-03-12.farmer.ham.txt\n",
            "1206.2000-06-01.farmer.ham.txt\t3760.2001-03-12.farmer.ham.txt\n",
            "1207.2000-06-01.farmer.ham.txt\t3761.2001-03-12.farmer.ham.txt\n",
            "1209.2000-06-01.farmer.ham.txt\t3762.2001-03-12.farmer.ham.txt\n",
            "1210.2000-06-01.farmer.ham.txt\t3763.2001-03-12.farmer.ham.txt\n",
            "1211.2000-06-01.farmer.ham.txt\t3764.2001-03-12.farmer.ham.txt\n",
            "1213.2000-06-02.farmer.ham.txt\t3765.2001-03-13.farmer.ham.txt\n",
            "1214.2000-06-02.farmer.ham.txt\t3767.2001-03-13.farmer.ham.txt\n",
            "1215.2000-06-02.farmer.ham.txt\t3769.2001-03-13.farmer.ham.txt\n",
            "1217.2000-06-02.farmer.ham.txt\t3771.2001-03-13.farmer.ham.txt\n",
            "1220.2000-06-02.farmer.ham.txt\t3772.2001-03-13.farmer.ham.txt\n",
            "1221.2000-06-02.farmer.ham.txt\t3775.2001-03-13.farmer.ham.txt\n",
            "1222.2000-06-02.farmer.ham.txt\t3776.2001-03-13.farmer.ham.txt\n",
            "1223.2000-06-02.farmer.ham.txt\t3777.2001-03-13.farmer.ham.txt\n",
            "1225.2000-06-03.farmer.ham.txt\t3778.2001-03-13.farmer.ham.txt\n",
            "1226.2000-06-04.farmer.ham.txt\t3780.2001-03-14.farmer.ham.txt\n",
            "1227.2000-06-04.farmer.ham.txt\t3782.2001-03-14.farmer.ham.txt\n",
            "1229.2000-06-05.farmer.ham.txt\t3784.2001-03-14.farmer.ham.txt\n",
            "1232.2000-06-05.farmer.ham.txt\t3785.2001-03-14.farmer.ham.txt\n",
            "1233.2000-06-05.farmer.ham.txt\t3786.2001-03-14.farmer.ham.txt\n",
            "1234.2000-06-05.farmer.ham.txt\t3788.2001-03-14.farmer.ham.txt\n",
            "1235.2000-06-05.farmer.ham.txt\t3790.2001-03-14.farmer.ham.txt\n",
            "1237.2000-06-05.farmer.ham.txt\t3791.2001-03-14.farmer.ham.txt\n",
            "1238.2000-06-05.farmer.ham.txt\t3793.2001-03-14.farmer.ham.txt\n",
            "1239.2000-06-05.farmer.ham.txt\t3794.2001-03-14.farmer.ham.txt\n",
            "1240.2000-06-05.farmer.ham.txt\t3795.2001-03-14.farmer.ham.txt\n",
            "1242.2000-06-05.farmer.ham.txt\t3796.2001-03-14.farmer.ham.txt\n",
            "1244.2000-06-05.farmer.ham.txt\t3798.2001-03-14.farmer.ham.txt\n",
            "1245.2000-06-05.farmer.ham.txt\t3800.2001-03-15.farmer.ham.txt\n",
            "1246.2000-06-05.farmer.ham.txt\t3801.2001-03-15.farmer.ham.txt\n",
            "1248.2000-06-05.farmer.ham.txt\t3804.2001-03-15.farmer.ham.txt\n",
            "1249.2000-06-06.farmer.ham.txt\t3805.2001-03-15.farmer.ham.txt\n",
            "1250.2000-06-06.farmer.ham.txt\t3806.2001-03-15.farmer.ham.txt\n",
            "1251.2000-06-06.farmer.ham.txt\t3807.2001-03-15.farmer.ham.txt\n",
            "1252.2000-06-06.farmer.ham.txt\t3808.2001-03-15.farmer.ham.txt\n",
            "1253.2000-06-06.farmer.ham.txt\t3809.2001-03-15.farmer.ham.txt\n",
            "1254.2000-06-06.farmer.ham.txt\t3810.2001-03-15.farmer.ham.txt\n",
            "1255.2000-06-06.farmer.ham.txt\t3815.2001-03-15.farmer.ham.txt\n",
            "1256.2000-06-06.farmer.ham.txt\t3816.2001-03-15.farmer.ham.txt\n",
            "1257.2000-06-06.farmer.ham.txt\t3817.2001-03-15.farmer.ham.txt\n",
            "1259.2000-06-06.farmer.ham.txt\t3819.2001-03-15.farmer.ham.txt\n",
            "1261.2000-06-06.farmer.ham.txt\t3820.2001-03-15.farmer.ham.txt\n",
            "1262.2000-06-07.farmer.ham.txt\t3823.2001-03-16.farmer.ham.txt\n",
            "1263.2000-06-07.farmer.ham.txt\t3824.2001-03-16.farmer.ham.txt\n",
            "1264.2000-06-07.farmer.ham.txt\t3825.2001-03-16.farmer.ham.txt\n",
            "1265.2000-06-07.farmer.ham.txt\t3826.2001-03-16.farmer.ham.txt\n",
            "1266.2000-06-07.farmer.ham.txt\t3829.2001-03-16.farmer.ham.txt\n",
            "1267.2000-06-07.farmer.ham.txt\t3831.2001-03-16.farmer.ham.txt\n",
            "1269.2000-06-07.farmer.ham.txt\t3832.2001-03-16.farmer.ham.txt\n",
            "1270.2000-06-07.farmer.ham.txt\t3833.2001-03-16.farmer.ham.txt\n",
            "1271.2000-06-07.farmer.ham.txt\t3834.2001-03-16.farmer.ham.txt\n",
            "1272.2000-06-07.farmer.ham.txt\t3835.2001-03-16.farmer.ham.txt\n",
            "1273.2000-06-07.farmer.ham.txt\t3836.2001-03-16.farmer.ham.txt\n",
            "1274.2000-06-07.farmer.ham.txt\t3837.2001-03-16.farmer.ham.txt\n",
            "1275.2000-06-07.farmer.ham.txt\t3838.2001-03-16.farmer.ham.txt\n",
            "1276.2000-06-07.farmer.ham.txt\t3839.2001-03-16.farmer.ham.txt\n",
            "1277.2000-06-07.farmer.ham.txt\t3840.2001-03-19.farmer.ham.txt\n",
            "1279.2000-06-07.farmer.ham.txt\t3841.2001-03-19.farmer.ham.txt\n",
            "1281.2000-06-08.farmer.ham.txt\t3842.2001-03-19.farmer.ham.txt\n",
            "1283.2000-06-08.farmer.ham.txt\t3843.2001-03-19.farmer.ham.txt\n",
            "1285.2000-06-08.farmer.ham.txt\t3846.2001-03-19.farmer.ham.txt\n",
            "1286.2000-06-08.farmer.ham.txt\t3847.2001-03-19.farmer.ham.txt\n",
            "1287.2000-06-08.farmer.ham.txt\t3848.2001-03-20.farmer.ham.txt\n",
            "1288.2000-06-08.farmer.ham.txt\t3850.2001-03-20.farmer.ham.txt\n",
            "1289.2000-06-08.farmer.ham.txt\t3851.2001-03-20.farmer.ham.txt\n",
            "1290.2000-06-08.farmer.ham.txt\t3852.2001-03-20.farmer.ham.txt\n",
            "1291.2000-06-08.farmer.ham.txt\t3853.2001-03-20.farmer.ham.txt\n",
            "1292.2000-06-08.farmer.ham.txt\t3855.2001-03-20.farmer.ham.txt\n",
            "1294.2000-06-08.farmer.ham.txt\t3857.2001-03-20.farmer.ham.txt\n",
            "1296.2000-06-08.farmer.ham.txt\t3859.2001-03-20.farmer.ham.txt\n",
            "1297.2000-06-09.farmer.ham.txt\t3860.2001-03-20.farmer.ham.txt\n",
            "1298.2000-06-09.farmer.ham.txt\t3861.2001-03-20.farmer.ham.txt\n",
            "1299.2000-06-09.farmer.ham.txt\t3863.2001-03-20.farmer.ham.txt\n",
            "1302.2000-06-09.farmer.ham.txt\t3864.2001-03-20.farmer.ham.txt\n",
            "1303.2000-06-09.farmer.ham.txt\t3865.2001-03-20.farmer.ham.txt\n",
            "1304.2000-06-09.farmer.ham.txt\t3866.2001-03-20.farmer.ham.txt\n",
            "1305.2000-06-09.farmer.ham.txt\t3868.2001-03-20.farmer.ham.txt\n",
            "1310.2000-06-09.farmer.ham.txt\t3869.2001-03-20.farmer.ham.txt\n",
            "1311.2000-06-09.farmer.ham.txt\t3873.2001-03-20.farmer.ham.txt\n",
            "1312.2000-06-09.farmer.ham.txt\t3876.2001-03-20.farmer.ham.txt\n",
            "1314.2000-06-09.farmer.ham.txt\t3877.2001-03-20.farmer.ham.txt\n",
            "1315.2000-06-09.farmer.ham.txt\t3878.2001-03-20.farmer.ham.txt\n",
            "1316.2000-06-11.farmer.ham.txt\t3879.2001-03-20.farmer.ham.txt\n",
            "1318.2000-06-12.farmer.ham.txt\t3880.2001-03-20.farmer.ham.txt\n",
            "1320.2000-06-12.farmer.ham.txt\t3882.2001-03-21.farmer.ham.txt\n",
            "1321.2000-06-12.farmer.ham.txt\t3884.2001-03-21.farmer.ham.txt\n",
            "1323.2000-06-12.farmer.ham.txt\t3886.2001-03-21.farmer.ham.txt\n",
            "1324.2000-06-12.farmer.ham.txt\t3888.2001-03-21.farmer.ham.txt\n",
            "1325.2000-06-12.farmer.ham.txt\t3889.2001-03-21.farmer.ham.txt\n",
            "1326.2000-06-12.farmer.ham.txt\t3892.2001-03-21.farmer.ham.txt\n",
            "1327.2000-06-13.farmer.ham.txt\t3895.2001-03-21.farmer.ham.txt\n",
            "1328.2000-06-13.farmer.ham.txt\t3896.2001-03-21.farmer.ham.txt\n",
            "1329.2000-06-13.farmer.ham.txt\t3898.2001-03-21.farmer.ham.txt\n",
            "1330.2000-06-13.farmer.ham.txt\t3899.2001-03-21.farmer.ham.txt\n",
            "1331.2000-06-13.farmer.ham.txt\t3901.2001-03-21.farmer.ham.txt\n",
            "1332.2000-06-13.farmer.ham.txt\t3902.2001-03-21.farmer.ham.txt\n",
            "1333.2000-06-13.farmer.ham.txt\t3903.2001-03-21.farmer.ham.txt\n",
            "1334.2000-06-13.farmer.ham.txt\t3904.2001-03-21.farmer.ham.txt\n",
            "1335.2000-06-13.farmer.ham.txt\t3905.2001-03-21.farmer.ham.txt\n",
            "1337.2000-06-13.farmer.ham.txt\t3906.2001-03-21.farmer.ham.txt\n",
            "1339.2000-06-13.farmer.ham.txt\t3907.2001-03-21.farmer.ham.txt\n",
            "1341.2000-06-13.farmer.ham.txt\t3908.2001-03-21.farmer.ham.txt\n",
            "1342.2000-06-14.farmer.ham.txt\t3909.2001-03-21.farmer.ham.txt\n",
            "1344.2000-06-14.farmer.ham.txt\t3911.2001-03-21.farmer.ham.txt\n",
            "1345.2000-06-14.farmer.ham.txt\t3914.2001-03-21.farmer.ham.txt\n",
            "1348.2000-06-14.farmer.ham.txt\t3916.2001-03-21.farmer.ham.txt\n",
            "1349.2000-06-14.farmer.ham.txt\t3917.2001-03-21.farmer.ham.txt\n",
            "1350.2000-06-14.farmer.ham.txt\t3918.2001-03-21.farmer.ham.txt\n",
            "1351.2000-06-14.farmer.ham.txt\t3919.2001-03-21.farmer.ham.txt\n",
            "1353.2000-06-14.farmer.ham.txt\t3920.2001-03-21.farmer.ham.txt\n",
            "1354.2000-06-15.farmer.ham.txt\t3922.2001-03-21.farmer.ham.txt\n",
            "1355.2000-06-15.farmer.ham.txt\t3924.2001-03-21.farmer.ham.txt\n",
            "1357.2000-06-15.farmer.ham.txt\t3925.2001-03-22.farmer.ham.txt\n",
            "1358.2000-06-15.farmer.ham.txt\t3926.2001-03-22.farmer.ham.txt\n",
            "1359.2000-06-15.farmer.ham.txt\t3927.2001-03-22.farmer.ham.txt\n",
            "1360.2000-06-15.farmer.ham.txt\t3929.2001-03-22.farmer.ham.txt\n",
            "1361.2000-06-15.farmer.ham.txt\t3930.2001-03-22.farmer.ham.txt\n",
            "1362.2000-06-15.farmer.ham.txt\t3932.2001-03-22.farmer.ham.txt\n",
            "1363.2000-06-15.farmer.ham.txt\t3933.2001-03-22.farmer.ham.txt\n",
            "1364.2000-06-16.farmer.ham.txt\t3935.2001-03-22.farmer.ham.txt\n",
            "1365.2000-06-16.farmer.ham.txt\t3937.2001-03-22.farmer.ham.txt\n",
            "1366.2000-06-16.farmer.ham.txt\t3939.2001-03-22.farmer.ham.txt\n",
            "1368.2000-06-16.farmer.ham.txt\t3940.2001-03-22.farmer.ham.txt\n",
            "1370.2000-06-16.farmer.ham.txt\t3942.2001-03-22.farmer.ham.txt\n",
            "1373.2000-06-16.farmer.ham.txt\t3943.2001-03-22.farmer.ham.txt\n",
            "1374.2000-06-16.farmer.ham.txt\t3945.2001-03-22.farmer.ham.txt\n",
            "1375.2000-06-16.farmer.ham.txt\t3946.2001-03-22.farmer.ham.txt\n",
            "1376.2000-06-16.farmer.ham.txt\t3948.2001-03-22.farmer.ham.txt\n",
            "1377.2000-06-16.farmer.ham.txt\t3950.2001-03-23.farmer.ham.txt\n",
            "1379.2000-06-16.farmer.ham.txt\t3951.2001-03-23.farmer.ham.txt\n",
            "1380.2000-06-17.farmer.ham.txt\t3952.2001-03-23.farmer.ham.txt\n",
            "1381.2000-06-17.farmer.ham.txt\t3955.2001-03-23.farmer.ham.txt\n",
            "1382.2000-06-17.farmer.ham.txt\t3956.2001-03-23.farmer.ham.txt\n",
            "1383.2000-06-17.farmer.ham.txt\t3957.2001-03-23.farmer.ham.txt\n",
            "1385.2000-06-17.farmer.ham.txt\t3958.2001-03-23.farmer.ham.txt\n",
            "1386.2000-06-17.farmer.ham.txt\t3961.2001-03-23.farmer.ham.txt\n",
            "1387.2000-06-17.farmer.ham.txt\t3964.2001-03-23.farmer.ham.txt\n",
            "1389.2000-06-17.farmer.ham.txt\t3967.2001-03-23.farmer.ham.txt\n",
            "1390.2000-06-19.farmer.ham.txt\t3969.2001-03-23.farmer.ham.txt\n",
            "1392.2000-06-19.farmer.ham.txt\t3971.2001-03-23.farmer.ham.txt\n",
            "1394.2000-06-19.farmer.ham.txt\t3972.2001-03-23.farmer.ham.txt\n",
            "1395.2000-06-19.farmer.ham.txt\t3974.2001-03-23.farmer.ham.txt\n",
            "1396.2000-06-19.farmer.ham.txt\t3975.2001-03-23.farmer.ham.txt\n",
            "1397.2000-06-19.farmer.ham.txt\t3976.2001-03-23.farmer.ham.txt\n",
            "1398.2000-06-19.farmer.ham.txt\t3977.2001-03-23.farmer.ham.txt\n",
            "1399.2000-06-19.farmer.ham.txt\t3978.2001-03-23.farmer.ham.txt\n",
            "1401.2000-06-20.farmer.ham.txt\t3980.2001-03-23.farmer.ham.txt\n",
            "1403.2000-06-20.farmer.ham.txt\t3981.2001-03-23.farmer.ham.txt\n",
            "1406.2000-06-20.farmer.ham.txt\t3984.2001-03-23.farmer.ham.txt\n",
            "1407.2000-06-20.farmer.ham.txt\t3986.2001-03-23.farmer.ham.txt\n",
            "1408.2000-06-20.farmer.ham.txt\t3989.2001-03-23.farmer.ham.txt\n",
            "1410.2000-06-20.farmer.ham.txt\t3991.2001-03-26.farmer.ham.txt\n",
            "1411.2000-06-20.farmer.ham.txt\t3992.2001-03-26.farmer.ham.txt\n",
            "1412.2000-06-20.farmer.ham.txt\t3993.2001-03-26.farmer.ham.txt\n",
            "1415.2000-06-20.farmer.ham.txt\t3995.2001-03-26.farmer.ham.txt\n",
            "1418.2000-06-21.farmer.ham.txt\t3996.2001-03-26.farmer.ham.txt\n",
            "1419.2000-06-21.farmer.ham.txt\t3997.2001-03-26.farmer.ham.txt\n",
            "1422.2000-06-21.farmer.ham.txt\t3998.2001-03-26.farmer.ham.txt\n",
            "1424.2000-06-21.farmer.ham.txt\t3999.2001-03-26.farmer.ham.txt\n",
            "1425.2000-06-21.farmer.ham.txt\t4000.2001-03-26.farmer.ham.txt\n",
            "1426.2000-06-21.farmer.ham.txt\t4002.2001-03-26.farmer.ham.txt\n",
            "1427.2000-06-21.farmer.ham.txt\t4003.2001-03-26.farmer.ham.txt\n",
            "1429.2000-06-21.farmer.ham.txt\t4005.2001-03-26.farmer.ham.txt\n",
            "1431.2000-06-21.farmer.ham.txt\t4006.2001-03-26.farmer.ham.txt\n",
            "1432.2000-06-21.farmer.ham.txt\t4007.2001-03-26.farmer.ham.txt\n",
            "1434.2000-06-21.farmer.ham.txt\t4008.2001-03-26.farmer.ham.txt\n",
            "1436.2000-06-21.farmer.ham.txt\t4010.2001-03-26.farmer.ham.txt\n",
            "1438.2000-06-21.farmer.ham.txt\t4011.2001-03-26.farmer.ham.txt\n",
            "1439.2000-06-21.farmer.ham.txt\t4012.2001-03-26.farmer.ham.txt\n",
            "1440.2000-06-22.farmer.ham.txt\t4013.2001-03-26.farmer.ham.txt\n",
            "1441.2000-06-22.farmer.ham.txt\t4015.2001-03-26.farmer.ham.txt\n",
            "1443.2000-06-22.farmer.ham.txt\t4017.2001-03-26.farmer.ham.txt\n",
            "1444.2000-06-22.farmer.ham.txt\t4019.2001-03-27.farmer.ham.txt\n",
            "1445.2000-06-22.farmer.ham.txt\t4020.2001-03-27.farmer.ham.txt\n",
            "1446.2000-06-22.farmer.ham.txt\t4021.2001-03-27.farmer.ham.txt\n",
            "1447.2000-06-22.farmer.ham.txt\t4022.2001-03-27.farmer.ham.txt\n",
            "1448.2000-06-22.farmer.ham.txt\t4023.2001-03-27.farmer.ham.txt\n",
            "1449.2000-06-22.farmer.ham.txt\t4024.2001-03-27.farmer.ham.txt\n",
            "1451.2000-06-22.farmer.ham.txt\t4025.2001-03-27.farmer.ham.txt\n",
            "1455.2000-06-22.farmer.ham.txt\t4027.2001-03-27.farmer.ham.txt\n",
            "1456.2000-06-22.farmer.ham.txt\t4028.2001-03-27.farmer.ham.txt\n",
            "1457.2000-06-22.farmer.ham.txt\t4029.2001-03-27.farmer.ham.txt\n",
            "1458.2000-06-22.farmer.ham.txt\t4032.2001-03-27.farmer.ham.txt\n",
            "1460.2000-06-22.farmer.ham.txt\t4036.2001-03-27.farmer.ham.txt\n",
            "1461.2000-06-22.farmer.ham.txt\t4037.2001-03-27.farmer.ham.txt\n",
            "1462.2000-06-22.farmer.ham.txt\t4038.2001-03-27.farmer.ham.txt\n",
            "1463.2000-06-22.farmer.ham.txt\t4040.2001-03-27.farmer.ham.txt\n",
            "1464.2000-06-22.farmer.ham.txt\t4043.2001-03-27.farmer.ham.txt\n",
            "1465.2000-06-22.farmer.ham.txt\t4044.2001-03-28.farmer.ham.txt\n",
            "1466.2000-06-22.farmer.ham.txt\t4045.2001-03-28.farmer.ham.txt\n",
            "1468.2000-06-23.farmer.ham.txt\t4046.2001-03-28.farmer.ham.txt\n",
            "1470.2000-06-23.farmer.ham.txt\t4047.2001-03-28.farmer.ham.txt\n",
            "1472.2000-06-23.farmer.ham.txt\t4049.2001-03-28.farmer.ham.txt\n",
            "1475.2000-06-23.farmer.ham.txt\t4050.2001-03-28.farmer.ham.txt\n",
            "1476.2000-06-23.farmer.ham.txt\t4052.2001-03-28.farmer.ham.txt\n",
            "1477.2000-06-23.farmer.ham.txt\t4053.2001-03-28.farmer.ham.txt\n",
            "1478.2000-06-23.farmer.ham.txt\t4054.2001-03-28.farmer.ham.txt\n",
            "1479.2000-06-23.farmer.ham.txt\t4056.2001-03-28.farmer.ham.txt\n",
            "1480.2000-06-23.farmer.ham.txt\t4058.2001-03-28.farmer.ham.txt\n",
            "1481.2000-06-26.farmer.ham.txt\t4059.2001-03-28.farmer.ham.txt\n",
            "1482.2000-06-26.farmer.ham.txt\t4060.2001-03-28.farmer.ham.txt\n",
            "1483.2000-06-26.farmer.ham.txt\t4062.2001-03-28.farmer.ham.txt\n",
            "1484.2000-06-26.farmer.ham.txt\t4063.2001-03-28.farmer.ham.txt\n",
            "1485.2000-06-26.farmer.ham.txt\t4064.2001-03-28.farmer.ham.txt\n",
            "1486.2000-06-26.farmer.ham.txt\t4066.2001-03-28.farmer.ham.txt\n",
            "1488.2000-06-26.farmer.ham.txt\t4068.2001-03-28.farmer.ham.txt\n",
            "1490.2000-06-26.farmer.ham.txt\t4069.2001-03-28.farmer.ham.txt\n",
            "1491.2000-06-26.farmer.ham.txt\t4070.2001-03-28.farmer.ham.txt\n",
            "1492.2000-06-27.farmer.ham.txt\t4071.2001-03-28.farmer.ham.txt\n",
            "1493.2000-06-27.farmer.ham.txt\t4072.2001-03-28.farmer.ham.txt\n",
            "1494.2000-06-27.farmer.ham.txt\t4073.2001-03-28.farmer.ham.txt\n",
            "1496.2000-06-27.farmer.ham.txt\t4074.2001-03-28.farmer.ham.txt\n",
            "1497.2000-06-27.farmer.ham.txt\t4075.2001-03-28.farmer.ham.txt\n",
            "1498.2000-06-27.farmer.ham.txt\t4076.2001-03-28.farmer.ham.txt\n",
            "1501.2000-06-27.farmer.ham.txt\t4079.2001-03-28.farmer.ham.txt\n",
            "1502.2000-06-27.farmer.ham.txt\t4080.2001-03-29.farmer.ham.txt\n",
            "1504.2000-06-27.farmer.ham.txt\t4081.2001-03-29.farmer.ham.txt\n",
            "1506.2000-06-27.farmer.ham.txt\t4082.2001-03-29.farmer.ham.txt\n",
            "1507.2000-06-27.farmer.ham.txt\t4084.2001-03-29.farmer.ham.txt\n",
            "1509.2000-06-27.farmer.ham.txt\t4085.2001-03-29.farmer.ham.txt\n",
            "1510.2000-06-27.farmer.ham.txt\t4086.2001-03-29.farmer.ham.txt\n",
            "1512.2000-06-27.farmer.ham.txt\t4088.2001-03-29.farmer.ham.txt\n",
            "1514.2000-06-27.farmer.ham.txt\t4089.2001-03-29.farmer.ham.txt\n",
            "1515.2000-06-27.farmer.ham.txt\t4090.2001-03-29.farmer.ham.txt\n",
            "1516.2000-06-27.farmer.ham.txt\t4092.2001-03-29.farmer.ham.txt\n",
            "1517.2000-06-27.farmer.ham.txt\t4094.2001-03-29.farmer.ham.txt\n",
            "1518.2000-06-28.farmer.ham.txt\t4095.2001-03-29.farmer.ham.txt\n",
            "1519.2000-06-28.farmer.ham.txt\t4096.2001-03-29.farmer.ham.txt\n",
            "1520.2000-06-28.farmer.ham.txt\t4098.2001-03-29.farmer.ham.txt\n",
            "1521.2000-06-28.farmer.ham.txt\t4100.2001-03-29.farmer.ham.txt\n",
            "1522.2000-06-28.farmer.ham.txt\t4103.2001-03-29.farmer.ham.txt\n",
            "1523.2000-06-28.farmer.ham.txt\t4105.2001-03-29.farmer.ham.txt\n",
            "1524.2000-06-28.farmer.ham.txt\t4106.2001-03-29.farmer.ham.txt\n",
            "1525.2000-06-28.farmer.ham.txt\t4107.2001-03-29.farmer.ham.txt\n",
            "1526.2000-06-28.farmer.ham.txt\t4108.2001-03-29.farmer.ham.txt\n",
            "1527.2000-06-28.farmer.ham.txt\t4109.2001-03-30.farmer.ham.txt\n",
            "1528.2000-06-28.farmer.ham.txt\t4112.2001-03-30.farmer.ham.txt\n",
            "1529.2000-06-28.farmer.ham.txt\t4114.2001-03-30.farmer.ham.txt\n",
            "1530.2000-06-28.farmer.ham.txt\t4116.2001-03-30.farmer.ham.txt\n",
            "1531.2000-06-28.farmer.ham.txt\t4117.2001-03-30.farmer.ham.txt\n",
            "1532.2000-06-28.farmer.ham.txt\t4118.2001-03-30.farmer.ham.txt\n",
            "1534.2000-06-29.farmer.ham.txt\t4121.2001-03-30.farmer.ham.txt\n",
            "1537.2000-06-29.farmer.ham.txt\t4122.2001-03-30.farmer.ham.txt\n",
            "1538.2000-06-29.farmer.ham.txt\t4125.2001-03-30.farmer.ham.txt\n",
            "1539.2000-06-29.farmer.ham.txt\t4126.2001-03-30.farmer.ham.txt\n",
            "1541.2000-06-29.farmer.ham.txt\t4129.2001-03-30.farmer.ham.txt\n",
            "1542.2000-06-29.farmer.ham.txt\t4130.2001-03-30.farmer.ham.txt\n",
            "1543.2000-06-29.farmer.ham.txt\t4131.2001-03-30.farmer.ham.txt\n",
            "1546.2000-06-29.farmer.ham.txt\t4133.2001-03-30.farmer.ham.txt\n",
            "1547.2000-06-29.farmer.ham.txt\t4134.2001-03-30.farmer.ham.txt\n",
            "1548.2000-06-29.farmer.ham.txt\t4136.2001-03-30.farmer.ham.txt\n",
            "1550.2000-06-29.farmer.ham.txt\t4138.2001-03-30.farmer.ham.txt\n",
            "1551.2000-06-29.farmer.ham.txt\t4139.2001-03-30.farmer.ham.txt\n",
            "1552.2000-06-29.farmer.ham.txt\t4140.2001-03-30.farmer.ham.txt\n",
            "1553.2000-06-29.farmer.ham.txt\t4141.2001-03-30.farmer.ham.txt\n",
            "1554.2000-06-29.farmer.ham.txt\t4143.2001-03-31.farmer.ham.txt\n",
            "1555.2000-06-29.farmer.ham.txt\t4144.2001-04-02.farmer.ham.txt\n",
            "1556.2000-06-29.farmer.ham.txt\t4145.2001-04-02.farmer.ham.txt\n",
            "1558.2000-06-29.farmer.ham.txt\t4146.2001-04-02.farmer.ham.txt\n",
            "1560.2000-06-29.farmer.ham.txt\t4147.2001-04-02.farmer.ham.txt\n",
            "1561.2000-06-29.farmer.ham.txt\t4148.2001-04-02.farmer.ham.txt\n",
            "1562.2000-06-30.farmer.ham.txt\t4149.2001-04-02.farmer.ham.txt\n",
            "1563.2000-06-30.farmer.ham.txt\t4150.2001-04-02.farmer.ham.txt\n",
            "1564.2000-06-30.farmer.ham.txt\t4151.2001-04-02.farmer.ham.txt\n",
            "1565.2000-06-30.farmer.ham.txt\t4153.2001-04-02.farmer.ham.txt\n",
            "1566.2000-06-30.farmer.ham.txt\t4154.2001-04-02.farmer.ham.txt\n",
            "1567.2000-06-30.farmer.ham.txt\t4155.2001-04-02.farmer.ham.txt\n",
            "1568.2000-06-30.farmer.ham.txt\t4156.2001-04-02.farmer.ham.txt\n",
            "1570.2000-06-30.farmer.ham.txt\t4157.2001-04-02.farmer.ham.txt\n",
            "1571.2000-06-30.farmer.ham.txt\t4158.2001-04-02.farmer.ham.txt\n",
            "1572.2000-07-03.farmer.ham.txt\t4159.2001-04-02.farmer.ham.txt\n",
            "1573.2000-07-05.farmer.ham.txt\t4160.2001-04-02.farmer.ham.txt\n",
            "1574.2000-07-05.farmer.ham.txt\t4162.2001-04-02.farmer.ham.txt\n",
            "1576.2000-07-05.farmer.ham.txt\t4163.2001-04-03.farmer.ham.txt\n",
            "1577.2000-07-06.farmer.ham.txt\t4164.2001-04-03.farmer.ham.txt\n",
            "1578.2000-07-06.farmer.ham.txt\t4165.2001-04-03.farmer.ham.txt\n",
            "1579.2000-07-06.farmer.ham.txt\t4167.2001-04-03.farmer.ham.txt\n",
            "1580.2000-07-06.farmer.ham.txt\t4168.2001-04-03.farmer.ham.txt\n",
            "1582.2000-07-06.farmer.ham.txt\t4169.2001-04-03.farmer.ham.txt\n",
            "1583.2000-07-06.farmer.ham.txt\t4170.2001-04-03.farmer.ham.txt\n",
            "1584.2000-07-06.farmer.ham.txt\t4171.2001-04-03.farmer.ham.txt\n",
            "1585.2000-07-07.farmer.ham.txt\t4173.2001-04-04.farmer.ham.txt\n",
            "1586.2000-07-07.farmer.ham.txt\t4174.2001-04-04.farmer.ham.txt\n",
            "1587.2000-07-07.farmer.ham.txt\t4176.2001-04-04.farmer.ham.txt\n",
            "1589.2000-07-07.farmer.ham.txt\t4177.2001-04-04.farmer.ham.txt\n",
            "1590.2000-07-10.farmer.ham.txt\t4178.2001-04-04.farmer.ham.txt\n",
            "1591.2000-07-10.farmer.ham.txt\t4179.2001-04-04.farmer.ham.txt\n",
            "1592.2000-07-10.farmer.ham.txt\t4180.2001-04-04.farmer.ham.txt\n",
            "1593.2000-07-10.farmer.ham.txt\t4181.2001-04-04.farmer.ham.txt\n",
            "1594.2000-07-10.farmer.ham.txt\t4182.2001-04-04.farmer.ham.txt\n",
            "1595.2000-07-10.farmer.ham.txt\t4183.2001-04-04.farmer.ham.txt\n",
            "1596.2000-07-10.farmer.ham.txt\t4184.2001-04-04.farmer.ham.txt\n",
            "1597.2000-07-10.farmer.ham.txt\t4185.2001-04-04.farmer.ham.txt\n",
            "1598.2000-07-10.farmer.ham.txt\t4186.2001-04-04.farmer.ham.txt\n",
            "1599.2000-07-11.farmer.ham.txt\t4187.2001-04-05.farmer.ham.txt\n",
            "1600.2000-07-11.farmer.ham.txt\t4189.2001-04-05.farmer.ham.txt\n",
            "1601.2000-07-11.farmer.ham.txt\t4191.2001-04-05.farmer.ham.txt\n",
            "1603.2000-07-11.farmer.ham.txt\t4192.2001-04-05.farmer.ham.txt\n",
            "1604.2000-07-11.farmer.ham.txt\t4194.2001-04-05.farmer.ham.txt\n",
            "1605.2000-07-11.farmer.ham.txt\t4195.2001-04-05.farmer.ham.txt\n",
            "1606.2000-07-11.farmer.ham.txt\t4199.2001-04-05.farmer.ham.txt\n",
            "1608.2000-07-11.farmer.ham.txt\t4200.2001-04-05.farmer.ham.txt\n",
            "1609.2000-07-11.farmer.ham.txt\t4202.2001-04-05.farmer.ham.txt\n",
            "1610.2000-07-11.farmer.ham.txt\t4203.2001-04-05.farmer.ham.txt\n",
            "1611.2000-07-11.farmer.ham.txt\t4205.2001-04-05.farmer.ham.txt\n",
            "1613.2000-07-12.farmer.ham.txt\t4206.2001-04-05.farmer.ham.txt\n",
            "1614.2000-07-12.farmer.ham.txt\t4209.2001-04-05.farmer.ham.txt\n",
            "1616.2000-07-12.farmer.ham.txt\t4210.2001-04-05.farmer.ham.txt\n",
            "1617.2000-07-12.farmer.ham.txt\t4212.2001-04-05.farmer.ham.txt\n",
            "1618.2000-07-12.farmer.ham.txt\t4213.2001-04-05.farmer.ham.txt\n",
            "1620.2000-07-12.farmer.ham.txt\t4214.2001-04-06.farmer.ham.txt\n",
            "1621.2000-07-12.farmer.ham.txt\t4215.2001-04-06.farmer.ham.txt\n",
            "1622.2000-07-12.farmer.ham.txt\t4216.2001-04-06.farmer.ham.txt\n",
            "1623.2000-07-13.farmer.ham.txt\t4217.2001-04-06.farmer.ham.txt\n",
            "1624.2000-07-13.farmer.ham.txt\t4218.2001-04-06.farmer.ham.txt\n",
            "1625.2000-07-13.farmer.ham.txt\t4219.2001-04-06.farmer.ham.txt\n",
            "1627.2000-07-13.farmer.ham.txt\t4220.2001-04-06.farmer.ham.txt\n",
            "1629.2000-07-13.farmer.ham.txt\t4222.2001-04-06.farmer.ham.txt\n",
            "1630.2000-07-13.farmer.ham.txt\t4223.2001-04-06.farmer.ham.txt\n",
            "1631.2000-07-13.farmer.ham.txt\t4228.2001-04-06.farmer.ham.txt\n",
            "1634.2000-07-13.farmer.ham.txt\t4231.2001-04-06.farmer.ham.txt\n",
            "1636.2000-07-13.farmer.ham.txt\t4232.2001-04-09.farmer.ham.txt\n",
            "1637.2000-07-13.farmer.ham.txt\t4234.2001-04-09.farmer.ham.txt\n",
            "1638.2000-07-13.farmer.ham.txt\t4235.2001-04-09.farmer.ham.txt\n",
            "1639.2000-07-13.farmer.ham.txt\t4236.2001-04-09.farmer.ham.txt\n",
            "1641.2000-07-14.farmer.ham.txt\t4237.2001-04-09.farmer.ham.txt\n",
            "1643.2000-07-14.farmer.ham.txt\t4240.2001-04-09.farmer.ham.txt\n",
            "1644.2000-07-14.farmer.ham.txt\t4241.2001-04-09.farmer.ham.txt\n",
            "1645.2000-07-14.farmer.ham.txt\t4244.2001-04-09.farmer.ham.txt\n",
            "1646.2000-07-14.farmer.ham.txt\t4245.2001-04-09.farmer.ham.txt\n",
            "1647.2000-07-14.farmer.ham.txt\t4246.2001-04-09.farmer.ham.txt\n",
            "1648.2000-07-14.farmer.ham.txt\t4247.2001-04-09.farmer.ham.txt\n",
            "1650.2000-07-14.farmer.ham.txt\t4248.2001-04-09.farmer.ham.txt\n",
            "1651.2000-07-14.farmer.ham.txt\t4250.2001-04-09.farmer.ham.txt\n",
            "1652.2000-07-14.farmer.ham.txt\t4251.2001-04-09.farmer.ham.txt\n",
            "1653.2000-07-14.farmer.ham.txt\t4253.2001-04-09.farmer.ham.txt\n",
            "1655.2000-07-17.farmer.ham.txt\t4255.2001-04-10.farmer.ham.txt\n",
            "1657.2000-07-17.farmer.ham.txt\t4256.2001-04-10.farmer.ham.txt\n",
            "1658.2000-07-17.farmer.ham.txt\t4257.2001-04-10.farmer.ham.txt\n",
            "1659.2000-07-17.farmer.ham.txt\t4258.2001-04-10.farmer.ham.txt\n",
            "1662.2000-07-17.farmer.ham.txt\t4259.2001-04-10.farmer.ham.txt\n",
            "1664.2000-07-17.farmer.ham.txt\t4261.2001-04-10.farmer.ham.txt\n",
            "1665.2000-07-17.farmer.ham.txt\t4263.2001-04-10.farmer.ham.txt\n",
            "1667.2000-07-17.farmer.ham.txt\t4264.2001-04-11.farmer.ham.txt\n",
            "1668.2000-07-17.farmer.ham.txt\t4265.2001-04-11.farmer.ham.txt\n",
            "1673.2000-07-17.farmer.ham.txt\t4267.2001-04-11.farmer.ham.txt\n",
            "1674.2000-07-18.farmer.ham.txt\t4268.2001-04-11.farmer.ham.txt\n",
            "1675.2000-07-18.farmer.ham.txt\t4269.2001-04-11.farmer.ham.txt\n",
            "1676.2000-07-18.farmer.ham.txt\t4271.2001-04-11.farmer.ham.txt\n",
            "1677.2000-07-18.farmer.ham.txt\t4272.2001-04-11.farmer.ham.txt\n",
            "1680.2000-07-18.farmer.ham.txt\t4273.2001-04-12.farmer.ham.txt\n",
            "1681.2000-07-18.farmer.ham.txt\t4274.2001-04-12.farmer.ham.txt\n",
            "1682.2000-07-19.farmer.ham.txt\t4275.2001-04-12.farmer.ham.txt\n",
            "1683.2000-07-19.farmer.ham.txt\t4276.2001-04-12.farmer.ham.txt\n",
            "1684.2000-07-19.farmer.ham.txt\t4278.2001-04-12.farmer.ham.txt\n",
            "1685.2000-07-19.farmer.ham.txt\t4279.2001-04-12.farmer.ham.txt\n",
            "1687.2000-07-19.farmer.ham.txt\t4280.2001-04-15.farmer.ham.txt\n",
            "1688.2000-07-19.farmer.ham.txt\t4281.2001-04-15.farmer.ham.txt\n",
            "1689.2000-07-20.farmer.ham.txt\t4282.2001-04-16.farmer.ham.txt\n",
            "1691.2000-07-20.farmer.ham.txt\t4285.2001-04-16.farmer.ham.txt\n",
            "1692.2000-07-20.farmer.ham.txt\t4287.2001-04-16.farmer.ham.txt\n",
            "1693.2000-07-20.farmer.ham.txt\t4288.2001-04-16.farmer.ham.txt\n",
            "1695.2000-07-20.farmer.ham.txt\t4290.2001-04-16.farmer.ham.txt\n",
            "1696.2000-07-20.farmer.ham.txt\t4291.2001-04-16.farmer.ham.txt\n",
            "1697.2000-07-20.farmer.ham.txt\t4292.2001-04-16.farmer.ham.txt\n",
            "1698.2000-07-21.farmer.ham.txt\t4293.2001-04-16.farmer.ham.txt\n",
            "1699.2000-07-21.farmer.ham.txt\t4294.2001-04-17.farmer.ham.txt\n",
            "1700.2000-07-21.farmer.ham.txt\t4295.2001-04-17.farmer.ham.txt\n",
            "1702.2000-07-21.farmer.ham.txt\t4296.2001-04-17.farmer.ham.txt\n",
            "1703.2000-07-21.farmer.ham.txt\t4297.2001-04-17.farmer.ham.txt\n",
            "1704.2000-07-21.farmer.ham.txt\t4298.2001-04-17.farmer.ham.txt\n",
            "1706.2000-07-21.farmer.ham.txt\t4300.2001-04-17.farmer.ham.txt\n",
            "1707.2000-07-24.farmer.ham.txt\t4301.2001-04-17.farmer.ham.txt\n",
            "1709.2000-07-24.farmer.ham.txt\t4302.2001-04-17.farmer.ham.txt\n",
            "1712.2000-07-24.farmer.ham.txt\t4303.2001-04-17.farmer.ham.txt\n",
            "1713.2000-07-24.farmer.ham.txt\t4305.2001-04-17.farmer.ham.txt\n",
            "1714.2000-07-24.farmer.ham.txt\t4307.2001-04-18.farmer.ham.txt\n",
            "1716.2000-07-24.farmer.ham.txt\t4309.2001-04-18.farmer.ham.txt\n",
            "1718.2000-07-24.farmer.ham.txt\t4310.2001-04-18.farmer.ham.txt\n",
            "1719.2000-07-24.farmer.ham.txt\t4311.2001-04-18.farmer.ham.txt\n",
            "1721.2000-07-24.farmer.ham.txt\t4312.2001-04-18.farmer.ham.txt\n",
            "1722.2000-07-24.farmer.ham.txt\t4313.2001-04-18.farmer.ham.txt\n",
            "1724.2000-07-25.farmer.ham.txt\t4315.2001-04-19.farmer.ham.txt\n",
            "1725.2000-07-25.farmer.ham.txt\t4316.2001-04-19.farmer.ham.txt\n",
            "1726.2000-07-25.farmer.ham.txt\t4318.2001-04-19.farmer.ham.txt\n",
            "1729.2000-07-25.farmer.ham.txt\t4319.2001-04-19.farmer.ham.txt\n",
            "1731.2000-07-25.farmer.ham.txt\t4322.2001-04-19.farmer.ham.txt\n",
            "1734.2000-07-25.farmer.ham.txt\t4324.2001-04-19.farmer.ham.txt\n",
            "1737.2000-07-25.farmer.ham.txt\t4325.2001-04-19.farmer.ham.txt\n",
            "1738.2000-07-25.farmer.ham.txt\t4327.2001-04-19.farmer.ham.txt\n",
            "1741.2000-07-25.farmer.ham.txt\t4329.2001-04-19.farmer.ham.txt\n",
            "1743.2000-07-25.farmer.ham.txt\t4330.2001-04-19.farmer.ham.txt\n",
            "1744.2000-07-25.farmer.ham.txt\t4331.2001-04-19.farmer.ham.txt\n",
            "1746.2000-07-25.farmer.ham.txt\t4332.2001-04-19.farmer.ham.txt\n",
            "1747.2000-07-26.farmer.ham.txt\t4333.2001-04-19.farmer.ham.txt\n",
            "1749.2000-07-26.farmer.ham.txt\t4334.2001-04-20.farmer.ham.txt\n",
            "1751.2000-07-26.farmer.ham.txt\t4335.2001-04-20.farmer.ham.txt\n",
            "1754.2000-07-26.farmer.ham.txt\t4336.2001-04-20.farmer.ham.txt\n",
            "1755.2000-07-26.farmer.ham.txt\t4337.2001-04-20.farmer.ham.txt\n",
            "1759.2000-07-26.farmer.ham.txt\t4338.2001-04-20.farmer.ham.txt\n",
            "1761.2000-07-26.farmer.ham.txt\t4341.2001-04-20.farmer.ham.txt\n",
            "1762.2000-07-27.farmer.ham.txt\t4343.2001-04-20.farmer.ham.txt\n",
            "1764.2000-07-27.farmer.ham.txt\t4345.2001-04-20.farmer.ham.txt\n",
            "1765.2000-07-27.farmer.ham.txt\t4346.2001-04-23.farmer.ham.txt\n",
            "1767.2000-07-27.farmer.ham.txt\t4347.2001-04-23.farmer.ham.txt\n",
            "1768.2000-07-27.farmer.ham.txt\t4348.2001-04-23.farmer.ham.txt\n",
            "1769.2000-07-27.farmer.ham.txt\t4349.2001-04-23.farmer.ham.txt\n",
            "1770.2000-07-27.farmer.ham.txt\t4351.2001-04-23.farmer.ham.txt\n",
            "1771.2000-07-27.farmer.ham.txt\t4352.2001-04-24.farmer.ham.txt\n",
            "1772.2000-07-27.farmer.ham.txt\t4353.2001-04-24.farmer.ham.txt\n",
            "1774.2000-07-27.farmer.ham.txt\t4354.2001-04-24.farmer.ham.txt\n",
            "1776.2000-07-27.farmer.ham.txt\t4357.2001-04-24.farmer.ham.txt\n",
            "1777.2000-07-27.farmer.ham.txt\t4358.2001-04-24.farmer.ham.txt\n",
            "1779.2000-07-28.farmer.ham.txt\t4360.2001-04-24.farmer.ham.txt\n",
            "1780.2000-07-28.farmer.ham.txt\t4361.2001-04-24.farmer.ham.txt\n",
            "1781.2000-07-28.farmer.ham.txt\t4362.2001-04-24.farmer.ham.txt\n",
            "1782.2000-07-28.farmer.ham.txt\t4364.2001-04-24.farmer.ham.txt\n",
            "1783.2000-07-28.farmer.ham.txt\t4365.2001-04-24.farmer.ham.txt\n",
            "1784.2000-07-28.farmer.ham.txt\t4367.2001-04-24.farmer.ham.txt\n",
            "1787.2000-07-28.farmer.ham.txt\t4368.2001-04-24.farmer.ham.txt\n",
            "1788.2000-07-28.farmer.ham.txt\t4369.2001-04-24.farmer.ham.txt\n",
            "1789.2000-07-28.farmer.ham.txt\t4371.2001-04-24.farmer.ham.txt\n",
            "1790.2000-07-28.farmer.ham.txt\t4372.2001-04-24.farmer.ham.txt\n",
            "1791.2000-07-28.farmer.ham.txt\t4374.2001-04-25.farmer.ham.txt\n",
            "1792.2000-07-28.farmer.ham.txt\t4375.2001-04-25.farmer.ham.txt\n",
            "1793.2000-07-28.farmer.ham.txt\t4376.2001-04-25.farmer.ham.txt\n",
            "1795.2000-07-28.farmer.ham.txt\t4378.2001-04-25.farmer.ham.txt\n",
            "1796.2000-07-30.farmer.ham.txt\t4379.2001-04-25.farmer.ham.txt\n",
            "1797.2000-07-31.farmer.ham.txt\t4381.2001-04-25.farmer.ham.txt\n",
            "1798.2000-07-31.farmer.ham.txt\t4383.2001-04-25.farmer.ham.txt\n",
            "1800.2000-07-31.farmer.ham.txt\t4386.2001-04-25.farmer.ham.txt\n",
            "1802.2000-07-31.farmer.ham.txt\t4387.2001-04-25.farmer.ham.txt\n",
            "1804.2000-07-31.farmer.ham.txt\t4388.2001-04-25.farmer.ham.txt\n",
            "1807.2000-07-31.farmer.ham.txt\t4390.2001-04-25.farmer.ham.txt\n",
            "1808.2000-07-31.farmer.ham.txt\t4391.2001-04-26.farmer.ham.txt\n",
            "1810.2000-07-31.farmer.ham.txt\t4393.2001-04-26.farmer.ham.txt\n",
            "1812.2000-07-31.farmer.ham.txt\t4395.2001-04-26.farmer.ham.txt\n",
            "1814.2000-07-31.farmer.ham.txt\t4396.2001-04-26.farmer.ham.txt\n",
            "1815.2000-07-31.farmer.ham.txt\t4397.2001-04-26.farmer.ham.txt\n",
            "1817.2000-07-31.farmer.ham.txt\t4398.2001-04-26.farmer.ham.txt\n",
            "1818.2000-07-31.farmer.ham.txt\t4399.2001-04-26.farmer.ham.txt\n",
            "1819.2000-07-31.farmer.ham.txt\t4400.2001-04-26.farmer.ham.txt\n",
            "1820.2000-07-31.farmer.ham.txt\t4401.2001-04-26.farmer.ham.txt\n",
            "1824.2000-07-31.farmer.ham.txt\t4402.2001-04-26.farmer.ham.txt\n",
            "1826.2000-07-31.farmer.ham.txt\t4404.2001-04-26.farmer.ham.txt\n",
            "1827.2000-07-31.farmer.ham.txt\t4406.2001-04-26.farmer.ham.txt\n",
            "1828.2000-07-31.farmer.ham.txt\t4407.2001-04-26.farmer.ham.txt\n",
            "1830.2000-07-31.farmer.ham.txt\t4408.2001-04-26.farmer.ham.txt\n",
            "1831.2000-08-01.farmer.ham.txt\t4409.2001-04-26.farmer.ham.txt\n",
            "1832.2000-08-01.farmer.ham.txt\t4410.2001-04-26.farmer.ham.txt\n",
            "1833.2000-08-01.farmer.ham.txt\t4413.2001-04-27.farmer.ham.txt\n",
            "1834.2000-08-01.farmer.ham.txt\t4415.2001-04-27.farmer.ham.txt\n",
            "1835.2000-08-01.farmer.ham.txt\t4416.2001-04-27.farmer.ham.txt\n",
            "1836.2000-08-01.farmer.ham.txt\t4418.2001-04-27.farmer.ham.txt\n",
            "1838.2000-08-01.farmer.ham.txt\t4423.2001-04-27.farmer.ham.txt\n",
            "1839.2000-08-01.farmer.ham.txt\t4425.2001-04-27.farmer.ham.txt\n",
            "1840.2000-08-01.farmer.ham.txt\t4426.2001-04-27.farmer.ham.txt\n",
            "1841.2000-08-01.farmer.ham.txt\t4427.2001-04-27.farmer.ham.txt\n",
            "1843.2000-08-02.farmer.ham.txt\t4429.2001-04-27.farmer.ham.txt\n",
            "1845.2000-08-02.farmer.ham.txt\t4431.2001-04-30.farmer.ham.txt\n",
            "1848.2000-08-02.farmer.ham.txt\t4432.2001-04-30.farmer.ham.txt\n",
            "1849.2000-08-02.farmer.ham.txt\t4433.2001-04-30.farmer.ham.txt\n",
            "1851.2000-08-02.farmer.ham.txt\t4434.2001-04-30.farmer.ham.txt\n",
            "1852.2000-08-02.farmer.ham.txt\t4435.2001-04-30.farmer.ham.txt\n",
            "1853.2000-08-02.farmer.ham.txt\t4436.2001-04-30.farmer.ham.txt\n",
            "1856.2000-08-02.farmer.ham.txt\t4438.2001-04-30.farmer.ham.txt\n",
            "1857.2000-08-02.farmer.ham.txt\t4439.2001-04-30.farmer.ham.txt\n",
            "1859.2000-08-03.farmer.ham.txt\t4440.2001-04-30.farmer.ham.txt\n",
            "1860.2000-08-03.farmer.ham.txt\t4443.2001-05-01.farmer.ham.txt\n",
            "1861.2000-08-03.farmer.ham.txt\t4444.2001-05-01.farmer.ham.txt\n",
            "1862.2000-08-03.farmer.ham.txt\t4445.2001-05-01.farmer.ham.txt\n",
            "1864.2000-08-03.farmer.ham.txt\t4447.2001-05-01.farmer.ham.txt\n",
            "1865.2000-08-03.farmer.ham.txt\t4448.2001-05-01.farmer.ham.txt\n",
            "1866.2000-08-04.farmer.ham.txt\t4449.2001-05-01.farmer.ham.txt\n",
            "1867.2000-08-04.farmer.ham.txt\t4451.2001-05-01.farmer.ham.txt\n",
            "1869.2000-08-04.farmer.ham.txt\t4452.2001-05-01.farmer.ham.txt\n",
            "1871.2000-08-06.farmer.ham.txt\t4454.2001-05-02.farmer.ham.txt\n",
            "1872.2000-08-07.farmer.ham.txt\t4457.2001-05-02.farmer.ham.txt\n",
            "1873.2000-08-07.farmer.ham.txt\t4458.2001-05-02.farmer.ham.txt\n",
            "1875.2000-08-07.farmer.ham.txt\t4460.2001-05-02.farmer.ham.txt\n",
            "1876.2000-08-07.farmer.ham.txt\t4461.2001-05-02.farmer.ham.txt\n",
            "1877.2000-08-07.farmer.ham.txt\t4462.2001-05-02.farmer.ham.txt\n",
            "1878.2000-08-07.farmer.ham.txt\t4465.2001-05-02.farmer.ham.txt\n",
            "1880.2000-08-07.farmer.ham.txt\t4466.2001-05-02.farmer.ham.txt\n",
            "1883.2000-08-07.farmer.ham.txt\t4468.2001-05-02.farmer.ham.txt\n",
            "1884.2000-08-07.farmer.ham.txt\t4471.2001-05-03.farmer.ham.txt\n",
            "1885.2000-08-07.farmer.ham.txt\t4474.2001-05-03.farmer.ham.txt\n",
            "1886.2000-08-07.farmer.ham.txt\t4477.2001-05-03.farmer.ham.txt\n",
            "1887.2000-08-07.farmer.ham.txt\t4480.2001-05-03.farmer.ham.txt\n",
            "1888.2000-08-07.farmer.ham.txt\t4484.2001-05-03.farmer.ham.txt\n",
            "1890.2000-08-08.farmer.ham.txt\t4488.2001-05-04.farmer.ham.txt\n",
            "1892.2000-08-08.farmer.ham.txt\t4490.2001-05-04.farmer.ham.txt\n",
            "1893.2000-08-09.farmer.ham.txt\t4491.2001-05-04.farmer.ham.txt\n",
            "1894.2000-08-09.farmer.ham.txt\t4492.2001-05-07.farmer.ham.txt\n",
            "1895.2000-08-09.farmer.ham.txt\t4494.2001-05-07.farmer.ham.txt\n",
            "1896.2000-08-09.farmer.ham.txt\t4495.2001-05-07.farmer.ham.txt\n",
            "1898.2000-08-09.farmer.ham.txt\t4496.2001-05-07.farmer.ham.txt\n",
            "1900.2000-08-09.farmer.ham.txt\t4498.2001-05-07.farmer.ham.txt\n",
            "1901.2000-08-09.farmer.ham.txt\t4499.2001-05-07.farmer.ham.txt\n",
            "1902.2000-08-09.farmer.ham.txt\t4500.2001-05-07.farmer.ham.txt\n",
            "1903.2000-08-09.farmer.ham.txt\t4501.2001-05-07.farmer.ham.txt\n",
            "1904.2000-08-10.farmer.ham.txt\t4502.2001-05-08.farmer.ham.txt\n",
            "1906.2000-08-10.farmer.ham.txt\t4503.2001-05-08.farmer.ham.txt\n",
            "1907.2000-08-10.farmer.ham.txt\t4504.2001-05-08.farmer.ham.txt\n",
            "1908.2000-08-10.farmer.ham.txt\t4506.2001-05-08.farmer.ham.txt\n",
            "1909.2000-08-10.farmer.ham.txt\t4507.2001-05-08.farmer.ham.txt\n",
            "1912.2000-08-10.farmer.ham.txt\t4508.2001-05-08.farmer.ham.txt\n",
            "1913.2000-08-10.farmer.ham.txt\t4509.2001-05-08.farmer.ham.txt\n",
            "1914.2000-08-10.farmer.ham.txt\t4511.2001-05-08.farmer.ham.txt\n",
            "1915.2000-08-10.farmer.ham.txt\t4512.2001-05-08.farmer.ham.txt\n",
            "1916.2000-08-10.farmer.ham.txt\t4514.2001-05-08.farmer.ham.txt\n",
            "1917.2000-08-10.farmer.ham.txt\t4515.2001-05-09.farmer.ham.txt\n",
            "1919.2000-08-11.farmer.ham.txt\t4516.2001-05-09.farmer.ham.txt\n",
            "1920.2000-08-11.farmer.ham.txt\t4519.2001-05-09.farmer.ham.txt\n",
            "1921.2000-08-11.farmer.ham.txt\t4521.2001-05-09.farmer.ham.txt\n",
            "1922.2000-08-11.farmer.ham.txt\t4522.2001-05-09.farmer.ham.txt\n",
            "1923.2000-08-11.farmer.ham.txt\t4523.2001-05-09.farmer.ham.txt\n",
            "1924.2000-08-11.farmer.ham.txt\t4525.2001-05-09.farmer.ham.txt\n",
            "1925.2000-08-11.farmer.ham.txt\t4526.2001-05-09.farmer.ham.txt\n",
            "1927.2000-08-11.farmer.ham.txt\t4527.2001-05-10.farmer.ham.txt\n",
            "1928.2000-08-11.farmer.ham.txt\t4528.2001-05-10.farmer.ham.txt\n",
            "1929.2000-08-11.farmer.ham.txt\t4529.2001-05-10.farmer.ham.txt\n",
            "1930.2000-08-12.farmer.ham.txt\t4530.2001-05-10.farmer.ham.txt\n",
            "1931.2000-08-12.farmer.ham.txt\t4531.2001-05-10.farmer.ham.txt\n",
            "1932.2000-08-13.farmer.ham.txt\t4533.2001-05-10.farmer.ham.txt\n",
            "1933.2000-08-14.farmer.ham.txt\t4534.2001-05-11.farmer.ham.txt\n",
            "1934.2000-08-14.farmer.ham.txt\t4535.2001-05-11.farmer.ham.txt\n",
            "1935.2000-08-14.farmer.ham.txt\t4536.2001-05-11.farmer.ham.txt\n",
            "1937.2000-08-14.farmer.ham.txt\t4538.2001-05-14.farmer.ham.txt\n",
            "1938.2000-08-14.farmer.ham.txt\t4539.2001-05-14.farmer.ham.txt\n",
            "1939.2000-08-14.farmer.ham.txt\t4540.2001-05-14.farmer.ham.txt\n",
            "1940.2000-08-14.farmer.ham.txt\t4541.2001-05-14.farmer.ham.txt\n",
            "1943.2000-08-14.farmer.ham.txt\t4542.2001-05-14.farmer.ham.txt\n",
            "1944.2000-08-14.farmer.ham.txt\t4543.2001-05-15.farmer.ham.txt\n",
            "1945.2000-08-15.farmer.ham.txt\t4544.2001-05-15.farmer.ham.txt\n",
            "1946.2000-08-15.farmer.ham.txt\t4545.2001-05-15.farmer.ham.txt\n",
            "1947.2000-08-15.farmer.ham.txt\t4546.2001-05-16.farmer.ham.txt\n",
            "1950.2000-08-15.farmer.ham.txt\t4549.2001-05-16.farmer.ham.txt\n",
            "1951.2000-08-16.farmer.ham.txt\t4550.2001-05-16.farmer.ham.txt\n",
            "1953.2000-08-16.farmer.ham.txt\t4553.2001-05-16.farmer.ham.txt\n",
            "1955.2000-08-16.farmer.ham.txt\t4555.2001-05-16.farmer.ham.txt\n",
            "1956.2000-08-16.farmer.ham.txt\t4556.2001-05-17.farmer.ham.txt\n",
            "1958.2000-08-16.farmer.ham.txt\t4557.2001-05-17.farmer.ham.txt\n",
            "1959.2000-08-16.farmer.ham.txt\t4559.2001-05-17.farmer.ham.txt\n",
            "1961.2000-08-16.farmer.ham.txt\t4560.2001-05-17.farmer.ham.txt\n",
            "1962.2000-08-16.farmer.ham.txt\t4561.2001-05-17.farmer.ham.txt\n",
            "1963.2000-08-17.farmer.ham.txt\t4563.2001-05-18.farmer.ham.txt\n",
            "1964.2000-08-17.farmer.ham.txt\t4564.2001-05-18.farmer.ham.txt\n",
            "1965.2000-08-17.farmer.ham.txt\t4565.2001-05-18.farmer.ham.txt\n",
            "1967.2000-08-17.farmer.ham.txt\t4567.2001-05-18.farmer.ham.txt\n",
            "1969.2000-08-17.farmer.ham.txt\t4569.2001-05-18.farmer.ham.txt\n",
            "1971.2000-08-17.farmer.ham.txt\t4571.2001-05-18.farmer.ham.txt\n",
            "1972.2000-08-17.farmer.ham.txt\t4572.2001-05-21.farmer.ham.txt\n",
            "1974.2000-08-18.farmer.ham.txt\t4573.2001-05-21.farmer.ham.txt\n",
            "1975.2000-08-18.farmer.ham.txt\t4574.2001-05-21.farmer.ham.txt\n",
            "1976.2000-08-18.farmer.ham.txt\t4575.2001-05-21.farmer.ham.txt\n",
            "1977.2000-08-18.farmer.ham.txt\t4578.2001-05-21.farmer.ham.txt\n",
            "1978.2000-08-19.farmer.ham.txt\t4579.2001-05-21.farmer.ham.txt\n",
            "1979.2000-08-21.farmer.ham.txt\t4580.2001-05-22.farmer.ham.txt\n",
            "1980.2000-08-21.farmer.ham.txt\t4581.2001-05-22.farmer.ham.txt\n",
            "1982.2000-08-21.farmer.ham.txt\t4582.2001-05-22.farmer.ham.txt\n",
            "1983.2000-08-21.farmer.ham.txt\t4583.2001-05-22.farmer.ham.txt\n",
            "1984.2000-08-21.farmer.ham.txt\t4585.2001-05-22.farmer.ham.txt\n",
            "1987.2000-08-21.farmer.ham.txt\t4586.2001-05-22.farmer.ham.txt\n",
            "1988.2000-08-21.farmer.ham.txt\t4587.2001-05-22.farmer.ham.txt\n",
            "1989.2000-08-21.farmer.ham.txt\t4588.2001-05-22.farmer.ham.txt\n",
            "1990.2000-08-21.farmer.ham.txt\t4590.2001-05-22.farmer.ham.txt\n",
            "1991.2000-08-22.farmer.ham.txt\t4591.2001-05-22.farmer.ham.txt\n",
            "1992.2000-08-22.farmer.ham.txt\t4592.2001-05-22.farmer.ham.txt\n",
            "1994.2000-08-22.farmer.ham.txt\t4593.2001-05-23.farmer.ham.txt\n",
            "1995.2000-08-22.farmer.ham.txt\t4594.2001-05-23.farmer.ham.txt\n",
            "1997.2000-08-22.farmer.ham.txt\t4595.2001-05-23.farmer.ham.txt\n",
            "1998.2000-08-22.farmer.ham.txt\t4596.2001-05-23.farmer.ham.txt\n",
            "1999.2000-08-22.farmer.ham.txt\t4597.2001-05-23.farmer.ham.txt\n",
            "2001.2000-08-22.farmer.ham.txt\t4599.2001-05-23.farmer.ham.txt\n",
            "2003.2000-08-22.farmer.ham.txt\t4601.2001-05-23.farmer.ham.txt\n",
            "2004.2000-08-22.farmer.ham.txt\t4603.2001-05-23.farmer.ham.txt\n",
            "2005.2000-08-22.farmer.ham.txt\t4604.2001-05-23.farmer.ham.txt\n",
            "2007.2000-08-23.farmer.ham.txt\t4605.2001-05-24.farmer.ham.txt\n",
            "2008.2000-08-23.farmer.ham.txt\t4607.2001-05-24.farmer.ham.txt\n",
            "2009.2000-08-23.farmer.ham.txt\t4608.2001-05-24.farmer.ham.txt\n",
            "2010.2000-08-23.farmer.ham.txt\t4609.2001-05-24.farmer.ham.txt\n",
            "2011.2000-08-23.farmer.ham.txt\t4610.2001-05-24.farmer.ham.txt\n",
            "2012.2000-08-23.farmer.ham.txt\t4613.2001-05-24.farmer.ham.txt\n",
            "2013.2000-08-23.farmer.ham.txt\t4614.2001-05-24.farmer.ham.txt\n",
            "2015.2000-08-23.farmer.ham.txt\t4616.2001-05-24.farmer.ham.txt\n",
            "2016.2000-08-23.farmer.ham.txt\t4617.2001-05-24.farmer.ham.txt\n",
            "2017.2000-08-24.farmer.ham.txt\t4618.2001-05-24.farmer.ham.txt\n",
            "2019.2000-08-24.farmer.ham.txt\t4619.2001-05-24.farmer.ham.txt\n",
            "2020.2000-08-24.farmer.ham.txt\t4621.2001-05-24.farmer.ham.txt\n",
            "2022.2000-08-24.farmer.ham.txt\t4622.2001-05-24.farmer.ham.txt\n",
            "2023.2000-08-24.farmer.ham.txt\t4623.2001-05-25.farmer.ham.txt\n",
            "2025.2000-08-24.farmer.ham.txt\t4624.2001-05-25.farmer.ham.txt\n",
            "2027.2000-08-24.farmer.ham.txt\t4625.2001-05-25.farmer.ham.txt\n",
            "2029.2000-08-24.farmer.ham.txt\t4626.2001-05-25.farmer.ham.txt\n",
            "2031.2000-08-24.farmer.ham.txt\t4627.2001-05-25.farmer.ham.txt\n",
            "2032.2000-08-24.farmer.ham.txt\t4628.2001-05-29.farmer.ham.txt\n",
            "2033.2000-08-25.farmer.ham.txt\t4630.2001-05-29.farmer.ham.txt\n",
            "2034.2000-08-25.farmer.ham.txt\t4631.2001-05-29.farmer.ham.txt\n",
            "2035.2000-08-25.farmer.ham.txt\t4632.2001-05-29.farmer.ham.txt\n",
            "2036.2000-08-25.farmer.ham.txt\t4633.2001-05-30.farmer.ham.txt\n",
            "2037.2000-08-25.farmer.ham.txt\t4634.2001-05-30.farmer.ham.txt\n",
            "2038.2000-08-25.farmer.ham.txt\t4635.2001-05-30.farmer.ham.txt\n",
            "2039.2000-08-25.farmer.ham.txt\t4636.2001-05-30.farmer.ham.txt\n",
            "2041.2000-08-25.farmer.ham.txt\t4638.2001-05-30.farmer.ham.txt\n",
            "2043.2000-08-25.farmer.ham.txt\t4639.2001-05-31.farmer.ham.txt\n",
            "2044.2000-08-25.farmer.ham.txt\t4640.2001-06-01.farmer.ham.txt\n",
            "2046.2000-08-25.farmer.ham.txt\t4641.2001-06-01.farmer.ham.txt\n",
            "2048.2000-08-25.farmer.ham.txt\t4642.2001-06-04.farmer.ham.txt\n",
            "2049.2000-08-25.farmer.ham.txt\t4644.2001-06-05.farmer.ham.txt\n",
            "2050.2000-08-28.farmer.ham.txt\t4645.2001-06-05.farmer.ham.txt\n",
            "2053.2000-08-28.farmer.ham.txt\t4646.2001-06-06.farmer.ham.txt\n",
            "2054.2000-08-28.farmer.ham.txt\t4648.2001-06-06.farmer.ham.txt\n",
            "2056.2000-08-28.farmer.ham.txt\t4649.2001-06-07.farmer.ham.txt\n",
            "2057.2000-08-28.farmer.ham.txt\t4650.2001-06-07.farmer.ham.txt\n",
            "2058.2000-08-28.farmer.ham.txt\t4651.2001-06-07.farmer.ham.txt\n",
            "2059.2000-08-28.farmer.ham.txt\t4654.2001-06-07.farmer.ham.txt\n",
            "2061.2000-08-29.farmer.ham.txt\t4656.2001-06-08.farmer.ham.txt\n",
            "2062.2000-08-29.farmer.ham.txt\t4659.2001-06-09.farmer.ham.txt\n",
            "2063.2000-08-29.farmer.ham.txt\t4660.2001-06-11.farmer.ham.txt\n",
            "2065.2000-08-29.farmer.ham.txt\t4661.2001-06-12.farmer.ham.txt\n",
            "2066.2000-08-29.farmer.ham.txt\t4662.2001-06-12.farmer.ham.txt\n",
            "2067.2000-08-29.farmer.ham.txt\t4663.2001-06-13.farmer.ham.txt\n",
            "2068.2000-08-29.farmer.ham.txt\t4664.2001-06-13.farmer.ham.txt\n",
            "2069.2000-08-29.farmer.ham.txt\t4666.2001-06-14.farmer.ham.txt\n",
            "2070.2000-08-29.farmer.ham.txt\t4667.2001-06-14.farmer.ham.txt\n",
            "2072.2000-08-29.farmer.ham.txt\t4669.2001-06-14.farmer.ham.txt\n",
            "2074.2000-08-30.farmer.ham.txt\t4670.2001-06-15.farmer.ham.txt\n",
            "2076.2000-08-30.farmer.ham.txt\t4671.2001-06-15.farmer.ham.txt\n",
            "2077.2000-08-30.farmer.ham.txt\t4672.2001-06-15.farmer.ham.txt\n",
            "2079.2000-08-30.farmer.ham.txt\t4673.2001-06-15.farmer.ham.txt\n",
            "2080.2000-08-30.farmer.ham.txt\t4674.2001-06-17.farmer.ham.txt\n",
            "2082.2000-08-30.farmer.ham.txt\t4676.2001-06-17.farmer.ham.txt\n",
            "2084.2000-08-30.farmer.ham.txt\t4679.2001-06-19.farmer.ham.txt\n",
            "2085.2000-08-30.farmer.ham.txt\t4681.2001-06-19.farmer.ham.txt\n",
            "2086.2000-08-30.farmer.ham.txt\t4682.2001-06-19.farmer.ham.txt\n",
            "2088.2000-08-30.farmer.ham.txt\t4683.2001-06-19.farmer.ham.txt\n",
            "2089.2000-08-30.farmer.ham.txt\t4684.2001-06-19.farmer.ham.txt\n",
            "2090.2000-08-30.farmer.ham.txt\t4685.2001-06-19.farmer.ham.txt\n",
            "2091.2000-08-30.farmer.ham.txt\t4686.2001-06-20.farmer.ham.txt\n",
            "2093.2000-08-30.farmer.ham.txt\t4688.2001-06-20.farmer.ham.txt\n",
            "2095.2000-08-30.farmer.ham.txt\t4690.2001-06-20.farmer.ham.txt\n",
            "2096.2000-08-30.farmer.ham.txt\t4691.2001-06-21.farmer.ham.txt\n",
            "2098.2000-08-30.farmer.ham.txt\t4692.2001-06-21.farmer.ham.txt\n",
            "2099.2000-08-30.farmer.ham.txt\t4693.2001-06-21.farmer.ham.txt\n",
            "2100.2000-08-30.farmer.ham.txt\t4694.2001-06-21.farmer.ham.txt\n",
            "2101.2000-08-30.farmer.ham.txt\t4695.2001-06-21.farmer.ham.txt\n",
            "2102.2000-08-30.farmer.ham.txt\t4696.2001-06-22.farmer.ham.txt\n",
            "2103.2000-08-30.farmer.ham.txt\t4699.2001-06-22.farmer.ham.txt\n",
            "2104.2000-08-31.farmer.ham.txt\t4700.2001-06-22.farmer.ham.txt\n",
            "2106.2000-08-31.farmer.ham.txt\t4701.2001-06-25.farmer.ham.txt\n",
            "2107.2000-08-31.farmer.ham.txt\t4702.2001-06-25.farmer.ham.txt\n",
            "2108.2000-08-31.farmer.ham.txt\t4703.2001-06-26.farmer.ham.txt\n",
            "2109.2000-08-31.farmer.ham.txt\t4704.2001-06-26.farmer.ham.txt\n",
            "2112.2000-08-31.farmer.ham.txt\t4705.2001-06-26.farmer.ham.txt\n",
            "2113.2000-09-01.farmer.ham.txt\t4706.2001-06-27.farmer.ham.txt\n",
            "2114.2000-09-01.farmer.ham.txt\t4707.2001-06-27.farmer.ham.txt\n",
            "2116.2000-09-01.farmer.ham.txt\t4708.2001-06-28.farmer.ham.txt\n",
            "2118.2000-09-01.farmer.ham.txt\t4709.2001-06-28.farmer.ham.txt\n",
            "2119.2000-09-01.farmer.ham.txt\t4710.2001-06-28.farmer.ham.txt\n",
            "2121.2000-09-01.farmer.ham.txt\t4711.2001-06-28.farmer.ham.txt\n",
            "2124.2000-09-01.farmer.ham.txt\t4713.2001-06-28.farmer.ham.txt\n",
            "2125.2000-09-01.farmer.ham.txt\t4716.2001-06-29.farmer.ham.txt\n",
            "2126.2000-09-01.farmer.ham.txt\t4717.2001-06-29.farmer.ham.txt\n",
            "2128.2000-09-01.farmer.ham.txt\t4718.2001-06-30.farmer.ham.txt\n",
            "2129.2000-09-01.farmer.ham.txt\t4719.2001-07-02.farmer.ham.txt\n",
            "2130.2000-09-01.farmer.ham.txt\t4721.2001-07-03.farmer.ham.txt\n",
            "2131.2000-09-01.farmer.ham.txt\t4723.2001-07-05.farmer.ham.txt\n",
            "2133.2000-09-01.farmer.ham.txt\t4726.2001-07-06.farmer.ham.txt\n",
            "2134.2000-09-01.farmer.ham.txt\t4728.2001-07-06.farmer.ham.txt\n",
            "2135.2000-09-01.farmer.ham.txt\t4729.2001-07-09.farmer.ham.txt\n",
            "2136.2000-09-01.farmer.ham.txt\t4730.2001-07-09.farmer.ham.txt\n",
            "2137.2000-09-01.farmer.ham.txt\t4731.2001-07-09.farmer.ham.txt\n",
            "2138.2000-09-01.farmer.ham.txt\t4732.2001-07-09.farmer.ham.txt\n",
            "2139.2000-09-01.farmer.ham.txt\t4734.2001-07-09.farmer.ham.txt\n",
            "2141.2000-09-01.farmer.ham.txt\t4736.2001-07-09.farmer.ham.txt\n",
            "2142.2000-09-05.farmer.ham.txt\t4738.2001-07-09.farmer.ham.txt\n",
            "2143.2000-09-05.farmer.ham.txt\t4739.2001-07-10.farmer.ham.txt\n",
            "2145.2000-09-05.farmer.ham.txt\t4742.2001-07-11.farmer.ham.txt\n",
            "2147.2000-09-05.farmer.ham.txt\t4744.2001-07-11.farmer.ham.txt\n",
            "2149.2000-09-05.farmer.ham.txt\t4747.2001-07-11.farmer.ham.txt\n",
            "2150.2000-09-05.farmer.ham.txt\t4748.2001-07-12.farmer.ham.txt\n",
            "2151.2000-09-05.farmer.ham.txt\t4750.2001-07-13.farmer.ham.txt\n",
            "2152.2000-09-05.farmer.ham.txt\t4751.2001-07-13.farmer.ham.txt\n",
            "2154.2000-09-05.farmer.ham.txt\t4752.2001-07-16.farmer.ham.txt\n",
            "2155.2000-09-05.farmer.ham.txt\t4753.2001-07-16.farmer.ham.txt\n",
            "2156.2000-09-05.farmer.ham.txt\t4756.2001-07-16.farmer.ham.txt\n",
            "2157.2000-09-05.farmer.ham.txt\t4757.2001-07-16.farmer.ham.txt\n",
            "2159.2000-09-05.farmer.ham.txt\t4758.2001-07-17.farmer.ham.txt\n",
            "2160.2000-09-05.farmer.ham.txt\t4759.2001-07-17.farmer.ham.txt\n",
            "2161.2000-09-06.farmer.ham.txt\t4760.2001-07-17.farmer.ham.txt\n",
            "2162.2000-09-06.farmer.ham.txt\t4761.2001-07-18.farmer.ham.txt\n",
            "2164.2000-09-06.farmer.ham.txt\t4762.2001-07-18.farmer.ham.txt\n",
            "2166.2000-09-06.farmer.ham.txt\t4763.2001-07-19.farmer.ham.txt\n",
            "2168.2000-09-06.farmer.ham.txt\t4764.2001-07-19.farmer.ham.txt\n",
            "2169.2000-09-06.farmer.ham.txt\t4765.2001-07-19.farmer.ham.txt\n",
            "2170.2000-09-06.farmer.ham.txt\t4767.2001-07-20.farmer.ham.txt\n",
            "2171.2000-09-06.farmer.ham.txt\t4768.2001-07-23.farmer.ham.txt\n",
            "2173.2000-09-06.farmer.ham.txt\t4769.2001-07-23.farmer.ham.txt\n",
            "2174.2000-09-07.farmer.ham.txt\t4770.2001-07-25.farmer.ham.txt\n",
            "2176.2000-09-07.farmer.ham.txt\t4772.2001-07-25.farmer.ham.txt\n",
            "2177.2000-09-07.farmer.ham.txt\t4773.2001-07-25.farmer.ham.txt\n",
            "2178.2000-09-07.farmer.ham.txt\t4775.2001-07-27.farmer.ham.txt\n",
            "2181.2000-09-07.farmer.ham.txt\t4776.2001-07-27.farmer.ham.txt\n",
            "2183.2000-09-07.farmer.ham.txt\t4779.2001-07-27.farmer.ham.txt\n",
            "2184.2000-09-07.farmer.ham.txt\t4780.2001-07-27.farmer.ham.txt\n",
            "2186.2000-09-08.farmer.ham.txt\t4781.2001-07-27.farmer.ham.txt\n",
            "2188.2000-09-08.farmer.ham.txt\t4782.2001-07-27.farmer.ham.txt\n",
            "2189.2000-09-08.farmer.ham.txt\t4783.2001-07-30.farmer.ham.txt\n",
            "2190.2000-09-08.farmer.ham.txt\t4784.2001-07-31.farmer.ham.txt\n",
            "2191.2000-09-08.farmer.ham.txt\t4785.2001-07-31.farmer.ham.txt\n",
            "2193.2000-09-08.farmer.ham.txt\t4786.2001-08-02.farmer.ham.txt\n",
            "2196.2000-09-08.farmer.ham.txt\t4788.2001-08-03.farmer.ham.txt\n",
            "2197.2000-09-09.farmer.ham.txt\t4789.2001-08-03.farmer.ham.txt\n",
            "2199.2000-09-11.farmer.ham.txt\t4791.2001-08-06.farmer.ham.txt\n",
            "2200.2000-09-11.farmer.ham.txt\t4793.2001-08-07.farmer.ham.txt\n",
            "2202.2000-09-11.farmer.ham.txt\t4795.2001-08-07.farmer.ham.txt\n",
            "2203.2000-09-11.farmer.ham.txt\t4797.2001-08-09.farmer.ham.txt\n",
            "2204.2000-09-11.farmer.ham.txt\t4798.2001-08-09.farmer.ham.txt\n",
            "2205.2000-09-12.farmer.ham.txt\t4800.2001-08-09.farmer.ham.txt\n",
            "2207.2000-09-12.farmer.ham.txt\t4801.2001-08-10.farmer.ham.txt\n",
            "2208.2000-09-12.farmer.ham.txt\t4802.2001-08-10.farmer.ham.txt\n",
            "2210.2000-09-12.farmer.ham.txt\t4804.2001-08-10.farmer.ham.txt\n",
            "2212.2000-09-12.farmer.ham.txt\t4805.2001-08-10.farmer.ham.txt\n",
            "2213.2000-09-12.farmer.ham.txt\t4807.2001-08-12.farmer.ham.txt\n",
            "2214.2000-09-12.farmer.ham.txt\t4809.2001-08-13.farmer.ham.txt\n",
            "2216.2000-09-12.farmer.ham.txt\t4811.2001-08-13.farmer.ham.txt\n",
            "2219.2000-09-12.farmer.ham.txt\t4812.2001-08-13.farmer.ham.txt\n",
            "2220.2000-09-12.farmer.ham.txt\t4814.2001-08-14.farmer.ham.txt\n",
            "2221.2000-09-12.farmer.ham.txt\t4816.2001-08-14.farmer.ham.txt\n",
            "2223.2000-09-12.farmer.ham.txt\t4817.2001-08-14.farmer.ham.txt\n",
            "2224.2000-09-12.farmer.ham.txt\t4819.2001-08-14.farmer.ham.txt\n",
            "2225.2000-09-12.farmer.ham.txt\t4820.2001-08-14.farmer.ham.txt\n",
            "2226.2000-09-12.farmer.ham.txt\t4821.2001-08-14.farmer.ham.txt\n",
            "2228.2000-09-13.farmer.ham.txt\t4823.2001-08-15.farmer.ham.txt\n",
            "2230.2000-09-13.farmer.ham.txt\t4825.2001-08-15.farmer.ham.txt\n",
            "2232.2000-09-13.farmer.ham.txt\t4826.2001-08-16.farmer.ham.txt\n",
            "2233.2000-09-13.farmer.ham.txt\t4828.2001-08-17.farmer.ham.txt\n",
            "2235.2000-09-13.farmer.ham.txt\t4829.2001-08-17.farmer.ham.txt\n",
            "2236.2000-09-13.farmer.ham.txt\t4830.2001-08-17.farmer.ham.txt\n",
            "2237.2000-09-13.farmer.ham.txt\t4831.2001-08-21.farmer.ham.txt\n",
            "2238.2000-09-13.farmer.ham.txt\t4832.2001-08-21.farmer.ham.txt\n",
            "2239.2000-09-13.farmer.ham.txt\t4835.2001-08-21.farmer.ham.txt\n",
            "2240.2000-09-14.farmer.ham.txt\t4836.2001-08-21.farmer.ham.txt\n",
            "2241.2000-09-14.farmer.ham.txt\t4837.2001-08-24.farmer.ham.txt\n",
            "2243.2000-09-14.farmer.ham.txt\t4838.2001-08-24.farmer.ham.txt\n",
            "2244.2000-09-14.farmer.ham.txt\t4839.2001-08-24.farmer.ham.txt\n",
            "2245.2000-09-15.farmer.ham.txt\t4840.2001-08-28.farmer.ham.txt\n",
            "2246.2000-09-15.farmer.ham.txt\t4842.2001-08-29.farmer.ham.txt\n",
            "2249.2000-09-15.farmer.ham.txt\t4844.2001-08-29.farmer.ham.txt\n",
            "2250.2000-09-15.farmer.ham.txt\t4846.2001-08-29.farmer.ham.txt\n",
            "2251.2000-09-15.farmer.ham.txt\t4847.2001-08-29.farmer.ham.txt\n",
            "2252.2000-09-15.farmer.ham.txt\t4849.2001-08-30.farmer.ham.txt\n",
            "2253.2000-09-15.farmer.ham.txt\t4851.2001-08-30.farmer.ham.txt\n",
            "2256.2000-09-15.farmer.ham.txt\t4852.2001-08-30.farmer.ham.txt\n",
            "2257.2000-09-15.farmer.ham.txt\t4853.2001-08-30.farmer.ham.txt\n",
            "2259.2000-09-18.farmer.ham.txt\t4855.2001-08-31.farmer.ham.txt\n",
            "2260.2000-09-18.farmer.ham.txt\t4857.2001-09-04.farmer.ham.txt\n",
            "2261.2000-09-18.farmer.ham.txt\t4858.2001-09-04.farmer.ham.txt\n",
            "2262.2000-09-18.farmer.ham.txt\t4860.2001-09-05.farmer.ham.txt\n",
            "2264.2000-09-18.farmer.ham.txt\t4861.2001-09-05.farmer.ham.txt\n",
            "2266.2000-09-18.farmer.ham.txt\t4863.2001-09-06.farmer.ham.txt\n",
            "2267.2000-09-18.farmer.ham.txt\t4865.2001-09-06.farmer.ham.txt\n",
            "2269.2000-09-18.farmer.ham.txt\t4867.2001-09-07.farmer.ham.txt\n",
            "2272.2000-09-18.farmer.ham.txt\t4868.2001-09-07.farmer.ham.txt\n",
            "2273.2000-09-19.farmer.ham.txt\t4869.2001-09-07.farmer.ham.txt\n",
            "2274.2000-09-19.farmer.ham.txt\t4871.2001-09-07.farmer.ham.txt\n",
            "2276.2000-09-19.farmer.ham.txt\t4873.2001-09-07.farmer.ham.txt\n",
            "2277.2000-09-19.farmer.ham.txt\t4874.2001-09-07.farmer.ham.txt\n",
            "2278.2000-09-19.farmer.ham.txt\t4875.2001-09-09.farmer.ham.txt\n",
            "2279.2000-09-19.farmer.ham.txt\t4876.2001-09-10.farmer.ham.txt\n",
            "2282.2000-09-19.farmer.ham.txt\t4879.2001-09-10.farmer.ham.txt\n",
            "2284.2000-09-19.farmer.ham.txt\t4880.2001-09-10.farmer.ham.txt\n",
            "2286.2000-09-19.farmer.ham.txt\t4883.2001-09-10.farmer.ham.txt\n",
            "2288.2000-09-19.farmer.ham.txt\t4884.2001-09-10.farmer.ham.txt\n",
            "2289.2000-09-19.farmer.ham.txt\t4886.2001-09-12.farmer.ham.txt\n",
            "2291.2000-09-19.farmer.ham.txt\t4888.2001-09-12.farmer.ham.txt\n",
            "2292.2000-09-20.farmer.ham.txt\t4889.2001-09-12.farmer.ham.txt\n",
            "2294.2000-09-20.farmer.ham.txt\t4892.2001-09-12.farmer.ham.txt\n",
            "2295.2000-09-20.farmer.ham.txt\t4893.2001-09-12.farmer.ham.txt\n",
            "2297.2000-09-20.farmer.ham.txt\t4895.2001-09-12.farmer.ham.txt\n",
            "2298.2000-09-20.farmer.ham.txt\t4896.2001-09-13.farmer.ham.txt\n",
            "2299.2000-09-20.farmer.ham.txt\t4897.2001-09-13.farmer.ham.txt\n",
            "2300.2000-09-21.farmer.ham.txt\t4899.2001-09-13.farmer.ham.txt\n",
            "2303.2000-09-21.farmer.ham.txt\t4900.2001-09-13.farmer.ham.txt\n",
            "2305.2000-09-21.farmer.ham.txt\t4901.2001-09-13.farmer.ham.txt\n",
            "2306.2000-09-21.farmer.ham.txt\t4902.2001-09-14.farmer.ham.txt\n",
            "2307.2000-09-21.farmer.ham.txt\t4903.2001-09-14.farmer.ham.txt\n",
            "2308.2000-09-21.farmer.ham.txt\t4905.2001-09-14.farmer.ham.txt\n",
            "2309.2000-09-21.farmer.ham.txt\t4907.2001-09-15.farmer.ham.txt\n",
            "2310.2000-09-21.farmer.ham.txt\t4909.2001-09-17.farmer.ham.txt\n",
            "2311.2000-09-21.farmer.ham.txt\t4910.2001-09-17.farmer.ham.txt\n",
            "2312.2000-09-21.farmer.ham.txt\t4912.2001-09-17.farmer.ham.txt\n",
            "2313.2000-09-21.farmer.ham.txt\t4914.2001-09-17.farmer.ham.txt\n",
            "2314.2000-09-21.farmer.ham.txt\t4915.2001-09-18.farmer.ham.txt\n",
            "2315.2000-09-22.farmer.ham.txt\t4916.2001-09-18.farmer.ham.txt\n",
            "2316.2000-09-22.farmer.ham.txt\t4918.2001-09-18.farmer.ham.txt\n",
            "2317.2000-09-22.farmer.ham.txt\t4919.2001-09-19.farmer.ham.txt\n",
            "2318.2000-09-22.farmer.ham.txt\t4920.2001-09-19.farmer.ham.txt\n",
            "2319.2000-09-22.farmer.ham.txt\t4921.2001-09-19.farmer.ham.txt\n",
            "2320.2000-09-22.farmer.ham.txt\t4923.2001-09-20.farmer.ham.txt\n",
            "2321.2000-09-22.farmer.ham.txt\t4925.2001-09-21.farmer.ham.txt\n",
            "2323.2000-09-22.farmer.ham.txt\t4926.2001-09-21.farmer.ham.txt\n",
            "2324.2000-09-22.farmer.ham.txt\t4927.2001-09-21.farmer.ham.txt\n",
            "2325.2000-09-25.farmer.ham.txt\t4928.2001-09-24.farmer.ham.txt\n",
            "2326.2000-09-25.farmer.ham.txt\t4929.2001-09-24.farmer.ham.txt\n",
            "2327.2000-09-25.farmer.ham.txt\t4930.2001-09-25.farmer.ham.txt\n",
            "2328.2000-09-25.farmer.ham.txt\t4932.2001-09-25.farmer.ham.txt\n",
            "2329.2000-09-25.farmer.ham.txt\t4933.2001-09-26.farmer.ham.txt\n",
            "2330.2000-09-25.farmer.ham.txt\t4934.2001-09-26.farmer.ham.txt\n",
            "2331.2000-09-25.farmer.ham.txt\t4936.2001-09-27.farmer.ham.txt\n",
            "2332.2000-09-25.farmer.ham.txt\t4937.2001-09-27.farmer.ham.txt\n",
            "2334.2000-09-25.farmer.ham.txt\t4941.2001-09-27.farmer.ham.txt\n",
            "2335.2000-09-26.farmer.ham.txt\t4942.2001-09-27.farmer.ham.txt\n",
            "2336.2000-09-26.farmer.ham.txt\t4945.2001-09-28.farmer.ham.txt\n",
            "2337.2000-09-26.farmer.ham.txt\t4946.2001-09-28.farmer.ham.txt\n",
            "2339.2000-09-26.farmer.ham.txt\t4948.2001-10-01.farmer.ham.txt\n",
            "2341.2000-09-26.farmer.ham.txt\t4949.2001-10-01.farmer.ham.txt\n",
            "2342.2000-09-26.farmer.ham.txt\t4950.2001-10-01.farmer.ham.txt\n",
            "2343.2000-09-26.farmer.ham.txt\t4951.2001-10-01.farmer.ham.txt\n",
            "2344.2000-09-26.farmer.ham.txt\t4953.2001-10-02.farmer.ham.txt\n",
            "2345.2000-09-26.farmer.ham.txt\t4954.2001-10-03.farmer.ham.txt\n",
            "2346.2000-09-26.farmer.ham.txt\t4956.2001-10-03.farmer.ham.txt\n",
            "2349.2000-09-26.farmer.ham.txt\t4957.2001-10-04.farmer.ham.txt\n",
            "2350.2000-09-26.farmer.ham.txt\t4959.2001-10-04.farmer.ham.txt\n",
            "2351.2000-09-26.farmer.ham.txt\t4960.2001-10-04.farmer.ham.txt\n",
            "2352.2000-09-26.farmer.ham.txt\t4961.2001-10-05.farmer.ham.txt\n",
            "2355.2000-09-26.farmer.ham.txt\t4962.2001-10-09.farmer.ham.txt\n",
            "2356.2000-09-26.farmer.ham.txt\t4963.2001-10-10.farmer.ham.txt\n",
            "2357.2000-09-27.farmer.ham.txt\t4965.2001-10-11.farmer.ham.txt\n",
            "2359.2000-09-27.farmer.ham.txt\t4966.2001-10-11.farmer.ham.txt\n",
            "2360.2000-09-27.farmer.ham.txt\t4967.2001-10-11.farmer.ham.txt\n",
            "2361.2000-09-27.farmer.ham.txt\t4968.2001-10-12.farmer.ham.txt\n",
            "2363.2000-09-27.farmer.ham.txt\t4970.2001-10-12.farmer.ham.txt\n",
            "2366.2000-09-27.farmer.ham.txt\t4972.2001-10-12.farmer.ham.txt\n",
            "2368.2000-09-27.farmer.ham.txt\t4974.2001-10-12.farmer.ham.txt\n",
            "2369.2000-09-28.farmer.ham.txt\t4975.2001-10-15.farmer.ham.txt\n",
            "2370.2000-09-28.farmer.ham.txt\t4976.2001-10-15.farmer.ham.txt\n",
            "2372.2000-09-28.farmer.ham.txt\t4977.2001-10-15.farmer.ham.txt\n",
            "2373.2000-09-28.farmer.ham.txt\t4978.2001-10-15.farmer.ham.txt\n",
            "2375.2000-09-28.farmer.ham.txt\t4980.2001-10-15.farmer.ham.txt\n",
            "2376.2000-09-28.farmer.ham.txt\t4981.2001-10-15.farmer.ham.txt\n",
            "2378.2000-09-28.farmer.ham.txt\t4982.2001-10-16.farmer.ham.txt\n",
            "2379.2000-09-28.farmer.ham.txt\t4983.2001-10-16.farmer.ham.txt\n",
            "2380.2000-09-28.farmer.ham.txt\t4986.2001-10-17.farmer.ham.txt\n",
            "2382.2000-09-28.farmer.ham.txt\t4987.2001-10-18.farmer.ham.txt\n",
            "2383.2000-09-28.farmer.ham.txt\t4989.2001-10-18.farmer.ham.txt\n",
            "2384.2000-09-28.farmer.ham.txt\t4992.2001-10-18.farmer.ham.txt\n",
            "2385.2000-09-28.farmer.ham.txt\t4995.2001-10-19.farmer.ham.txt\n",
            "2386.2000-09-28.farmer.ham.txt\t4996.2001-10-19.farmer.ham.txt\n",
            "2387.2000-09-28.farmer.ham.txt\t4997.2001-10-22.farmer.ham.txt\n",
            "2388.2000-09-29.farmer.ham.txt\t4998.2001-10-22.farmer.ham.txt\n",
            "2389.2000-09-29.farmer.ham.txt\t4999.2001-10-23.farmer.ham.txt\n",
            "2390.2000-09-29.farmer.ham.txt\t5000.2001-10-23.farmer.ham.txt\n",
            "2392.2000-09-29.farmer.ham.txt\t5001.2001-10-24.farmer.ham.txt\n",
            "2393.2000-09-29.farmer.ham.txt\t5003.2001-10-24.farmer.ham.txt\n",
            "2394.2000-09-29.farmer.ham.txt\t5004.2001-10-24.farmer.ham.txt\n",
            "2395.2000-09-29.farmer.ham.txt\t5005.2001-10-24.farmer.ham.txt\n",
            "2396.2000-09-29.farmer.ham.txt\t5008.2001-10-25.farmer.ham.txt\n",
            "2397.2000-09-29.farmer.ham.txt\t5010.2001-10-25.farmer.ham.txt\n",
            "2400.2000-09-29.farmer.ham.txt\t5012.2001-10-25.farmer.ham.txt\n",
            "2401.2000-09-29.farmer.ham.txt\t5013.2001-10-26.farmer.ham.txt\n",
            "2402.2000-09-29.farmer.ham.txt\t5014.2001-10-26.farmer.ham.txt\n",
            "2404.2000-09-29.farmer.ham.txt\t5015.2001-10-26.farmer.ham.txt\n",
            "2405.2000-09-29.farmer.ham.txt\t5016.2001-10-29.farmer.ham.txt\n",
            "2407.2000-09-29.farmer.ham.txt\t5017.2001-10-30.farmer.ham.txt\n",
            "2409.2000-10-02.farmer.ham.txt\t5019.2001-10-30.farmer.ham.txt\n",
            "2411.2000-10-02.farmer.ham.txt\t5021.2001-10-30.farmer.ham.txt\n",
            "2412.2000-10-02.farmer.ham.txt\t5022.2001-10-30.farmer.ham.txt\n",
            "2413.2000-10-02.farmer.ham.txt\t5023.2001-10-30.farmer.ham.txt\n",
            "2414.2000-10-02.farmer.ham.txt\t5024.2001-10-30.farmer.ham.txt\n",
            "2415.2000-10-02.farmer.ham.txt\t5025.2001-10-31.farmer.ham.txt\n",
            "2418.2000-10-02.farmer.ham.txt\t5026.2001-10-31.farmer.ham.txt\n",
            "2419.2000-10-02.farmer.ham.txt\t5027.2001-10-31.farmer.ham.txt\n",
            "2420.2000-10-02.farmer.ham.txt\t5029.2001-10-31.farmer.ham.txt\n",
            "2422.2000-10-02.farmer.ham.txt\t5030.2001-10-31.farmer.ham.txt\n",
            "2424.2000-10-02.farmer.ham.txt\t5033.2001-10-31.farmer.ham.txt\n",
            "2425.2000-10-02.farmer.ham.txt\t5034.2001-11-01.farmer.ham.txt\n",
            "2426.2000-10-03.farmer.ham.txt\t5035.2001-11-02.farmer.ham.txt\n",
            "2427.2000-10-03.farmer.ham.txt\t5037.2001-11-02.farmer.ham.txt\n",
            "2428.2000-10-03.farmer.ham.txt\t5038.2001-11-05.farmer.ham.txt\n",
            "2429.2000-10-03.farmer.ham.txt\t5040.2001-11-05.farmer.ham.txt\n",
            "2431.2000-10-03.farmer.ham.txt\t5041.2001-11-06.farmer.ham.txt\n",
            "2432.2000-10-03.farmer.ham.txt\t5043.2001-11-06.farmer.ham.txt\n",
            "2434.2000-10-03.farmer.ham.txt\t5044.2001-11-06.farmer.ham.txt\n",
            "2436.2000-10-03.farmer.ham.txt\t5045.2001-11-06.farmer.ham.txt\n",
            "2438.2000-10-03.farmer.ham.txt\t5046.2001-11-06.farmer.ham.txt\n",
            "2439.2000-10-03.farmer.ham.txt\t5047.2001-11-06.farmer.ham.txt\n",
            "2440.2000-10-03.farmer.ham.txt\t5048.2001-11-07.farmer.ham.txt\n",
            "2441.2000-10-04.farmer.ham.txt\t5049.2001-11-07.farmer.ham.txt\n",
            "2443.2000-10-04.farmer.ham.txt\t5050.2001-11-07.farmer.ham.txt\n",
            "2444.2000-10-04.farmer.ham.txt\t5052.2001-11-07.farmer.ham.txt\n",
            "2445.2000-10-04.farmer.ham.txt\t5053.2001-11-08.farmer.ham.txt\n",
            "2446.2000-10-04.farmer.ham.txt\t5054.2001-11-08.farmer.ham.txt\n",
            "2448.2000-10-05.farmer.ham.txt\t5056.2001-11-08.farmer.ham.txt\n",
            "2449.2000-10-05.farmer.ham.txt\t5059.2001-11-08.farmer.ham.txt\n",
            "2450.2000-10-05.farmer.ham.txt\t5061.2001-11-09.farmer.ham.txt\n",
            "2451.2000-10-05.farmer.ham.txt\t5062.2001-11-09.farmer.ham.txt\n",
            "2453.2000-10-05.farmer.ham.txt\t5063.2001-11-12.farmer.ham.txt\n",
            "2454.2000-10-05.farmer.ham.txt\t5064.2001-11-12.farmer.ham.txt\n",
            "2456.2000-10-05.farmer.ham.txt\t5065.2001-11-13.farmer.ham.txt\n",
            "2457.2000-10-05.farmer.ham.txt\t5067.2001-11-13.farmer.ham.txt\n",
            "2459.2000-10-05.farmer.ham.txt\t5069.2001-11-14.farmer.ham.txt\n",
            "2460.2000-10-05.farmer.ham.txt\t5070.2001-11-14.farmer.ham.txt\n",
            "2461.2000-10-05.farmer.ham.txt\t5073.2001-11-14.farmer.ham.txt\n",
            "2463.2000-10-05.farmer.ham.txt\t5074.2001-11-14.farmer.ham.txt\n",
            "2464.2000-10-05.farmer.ham.txt\t5075.2001-11-15.farmer.ham.txt\n",
            "2465.2000-10-05.farmer.ham.txt\t5076.2001-11-19.farmer.ham.txt\n",
            "2467.2000-10-05.farmer.ham.txt\t5077.2001-11-19.farmer.ham.txt\n",
            "2469.2000-10-05.farmer.ham.txt\t5078.2001-11-20.farmer.ham.txt\n",
            "2470.2000-10-05.farmer.ham.txt\t5080.2001-11-20.farmer.ham.txt\n",
            "2471.2000-10-06.farmer.ham.txt\t5082.2001-11-21.farmer.ham.txt\n",
            "2473.2000-10-06.farmer.ham.txt\t5084.2001-11-26.farmer.ham.txt\n",
            "2474.2000-10-06.farmer.ham.txt\t5085.2001-11-26.farmer.ham.txt\n",
            "2476.2000-10-06.farmer.ham.txt\t5086.2001-11-27.farmer.ham.txt\n",
            "2477.2000-10-06.farmer.ham.txt\t5088.2001-11-27.farmer.ham.txt\n",
            "2478.2000-10-06.farmer.ham.txt\t5091.2001-11-29.farmer.ham.txt\n",
            "2479.2000-10-06.farmer.ham.txt\t5092.2001-11-29.farmer.ham.txt\n",
            "2481.2000-10-09.farmer.ham.txt\t5093.2001-11-30.farmer.ham.txt\n",
            "2482.2000-10-09.farmer.ham.txt\t5094.2001-11-30.farmer.ham.txt\n",
            "2485.2000-10-09.farmer.ham.txt\t5095.2001-12-02.farmer.ham.txt\n",
            "2486.2000-10-10.farmer.ham.txt\t5097.2001-12-04.farmer.ham.txt\n",
            "2487.2000-10-10.farmer.ham.txt\t5098.2001-12-05.farmer.ham.txt\n",
            "2489.2000-10-10.farmer.ham.txt\t5100.2001-12-07.farmer.ham.txt\n",
            "2492.2000-10-10.farmer.ham.txt\t5102.2001-12-08.farmer.ham.txt\n",
            "2493.2000-10-10.farmer.ham.txt\t5104.2001-12-11.farmer.ham.txt\n",
            "2494.2000-10-10.farmer.ham.txt\t5106.2001-12-11.farmer.ham.txt\n",
            "2496.2000-10-10.farmer.ham.txt\t5108.2001-12-11.farmer.ham.txt\n",
            "2497.2000-10-10.farmer.ham.txt\t5109.2001-12-11.farmer.ham.txt\n",
            "2499.2000-10-10.farmer.ham.txt\t5111.2001-12-11.farmer.ham.txt\n",
            "2501.2000-10-10.farmer.ham.txt\t5113.2001-12-11.farmer.ham.txt\n",
            "2502.2000-10-10.farmer.ham.txt\t5114.2001-12-11.farmer.ham.txt\n",
            "2503.2000-10-10.farmer.ham.txt\t5116.2001-12-11.farmer.ham.txt\n",
            "2504.2000-10-10.farmer.ham.txt\t5117.2001-12-12.farmer.ham.txt\n",
            "2506.2000-10-10.farmer.ham.txt\t5118.2001-12-12.farmer.ham.txt\n",
            "2507.2000-10-11.farmer.ham.txt\t5120.2001-12-13.farmer.ham.txt\n",
            "2509.2000-10-11.farmer.ham.txt\t5121.2001-12-13.farmer.ham.txt\n",
            "2510.2000-10-11.farmer.ham.txt\t5122.2001-12-13.farmer.ham.txt\n",
            "2513.2000-10-11.farmer.ham.txt\t5124.2001-12-13.farmer.ham.txt\n",
            "2515.2000-10-11.farmer.ham.txt\t5125.2001-12-14.farmer.ham.txt\n",
            "2516.2000-10-11.farmer.ham.txt\t5126.2001-12-14.farmer.ham.txt\n",
            "2517.2000-10-12.farmer.ham.txt\t5127.2001-12-14.farmer.ham.txt\n",
            "2519.2000-10-12.farmer.ham.txt\t5129.2001-12-17.farmer.ham.txt\n",
            "2521.2000-10-12.farmer.ham.txt\t5130.2001-12-17.farmer.ham.txt\n",
            "2523.2000-10-13.farmer.ham.txt\t5131.2001-12-19.farmer.ham.txt\n",
            "2524.2000-10-13.farmer.ham.txt\t5133.2001-12-20.farmer.ham.txt\n",
            "2525.2000-10-13.farmer.ham.txt\t5134.2001-12-20.farmer.ham.txt\n",
            "2527.2000-10-13.farmer.ham.txt\t5135.2001-12-20.farmer.ham.txt\n",
            "2528.2000-10-13.farmer.ham.txt\t5137.2001-12-26.farmer.ham.txt\n",
            "2531.2000-10-13.farmer.ham.txt\t5139.2002-01-02.farmer.ham.txt\n",
            "2532.2000-10-13.farmer.ham.txt\t5140.2002-01-02.farmer.ham.txt\n",
            "2533.2000-10-13.farmer.ham.txt\t5141.2002-01-02.farmer.ham.txt\n",
            "2534.2000-10-13.farmer.ham.txt\t5142.2002-01-02.farmer.ham.txt\n",
            "2535.2000-10-14.farmer.ham.txt\t5144.2002-01-04.farmer.ham.txt\n",
            "2536.2000-10-16.farmer.ham.txt\t5146.2002-01-04.farmer.ham.txt\n",
            "2537.2000-10-16.farmer.ham.txt\t5147.2002-01-04.farmer.ham.txt\n",
            "2538.2000-10-16.farmer.ham.txt\t5148.2002-01-04.farmer.ham.txt\n",
            "2541.2000-10-16.farmer.ham.txt\t5149.2002-01-04.farmer.ham.txt\n",
            "2542.2000-10-16.farmer.ham.txt\t5150.2002-01-07.farmer.ham.txt\n",
            "2543.2000-10-16.farmer.ham.txt\t5151.2002-01-07.farmer.ham.txt\n",
            "2544.2000-10-16.farmer.ham.txt\t5152.2002-01-07.farmer.ham.txt\n",
            "2545.2000-10-16.farmer.ham.txt\t5153.2002-01-07.farmer.ham.txt\n",
            "2546.2000-10-16.farmer.ham.txt\t5156.2002-01-07.farmer.ham.txt\n",
            "2547.2000-10-16.farmer.ham.txt\t5158.2002-01-07.farmer.ham.txt\n",
            "2548.2000-10-17.farmer.ham.txt\t5159.2002-01-07.farmer.ham.txt\n",
            "2550.2000-10-17.farmer.ham.txt\t5161.2002-01-08.farmer.ham.txt\n",
            "2551.2000-10-17.farmer.ham.txt\t5162.2002-01-09.farmer.ham.txt\n",
            "2553.2000-10-17.farmer.ham.txt\t5165.2002-01-09.farmer.ham.txt\n",
            "2556.2000-10-17.farmer.ham.txt\t5166.2002-01-09.farmer.ham.txt\n",
            "2558.2000-10-17.farmer.ham.txt\t5168.2002-01-10.farmer.ham.txt\n",
            "2559.2000-10-17.farmer.ham.txt\t5169.2002-01-11.farmer.ham.txt\n",
            "2560.2000-10-17.farmer.ham.txt\t5172.2002-01-11.farmer.ham.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLqTwzJoyRz"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "import os\n",
        "import codecs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJl6H8UmMu22"
      },
      "source": [
        "def init_lists(folder):\n",
        "    key_list = []\n",
        "    file_list = os.listdir(folder)\n",
        "    for filename in file_list:\n",
        "        f = codecs.open(folder + filename, 'r', encoding='utf-8', errors='ignore')\n",
        "        key_list.append(f.read())\n",
        "    f.close()\n",
        "    return key_list\n",
        "\n",
        "all_mails = list()\n",
        "spam = init_lists('./enron1/spam/')\n",
        "ham = init_lists('./enron1/ham/')\n",
        "# リストにした迷惑メール(spam)と、通常のメール(ham)を別のリストにコピーし、迷惑メールの場合はラベルを1に、そうでない場合は0にする\n",
        "all_mails = [(mail, '1') for mail in spam]\n",
        "all_mails += [(mail, '0') for mail in ham]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6chOK7N1t4"
      },
      "source": [
        "import pandas as pd\n",
        "# DataFrameにメールの文面とラベルを列に設定してロードする\n",
        "df = pd.DataFrame(all_mails, columns=['text', 'label'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GH8UEqbOiAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "12c1e7e3-e3dc-4032-b80e-9641d247c275"
      },
      "source": [
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text label\n",
              "0     Subject: homeowners - get more money in your p...     1\n",
              "1     Subject: pain is killing you\\r\\nsun , 05 dec 2...     1\n",
              "2     Subject: vulgar\\r\\nmuniz ,\\r\\ngovenment don ' ...     1\n",
              "3     Subject: special offers - various\\r\\ntoday ' s...     1\n",
              "4     Subject: down . load - dvd , mp 3 , music , pl...     1\n",
              "...                                                 ...   ...\n",
              "5167  Subject: re : basin production from ga 213\\r\\n...     0\n",
              "5168  Subject: fw : calpine daily gas nomination\\r\\n...     0\n",
              "5169  Subject: purchase and sale nominations - eastr...     0\n",
              "5170  Subject: the houston expl dec 2000\\r\\ndarren :...     0\n",
              "5171  Subject: eastrans nomination change effective ...     0\n",
              "\n",
              "[5172 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddd4db0b-15f5-4264-83e4-e8fa4d8a1ff5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: homeowners - get more money in your p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: pain is killing you\\r\\nsun , 05 dec 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: vulgar\\r\\nmuniz ,\\r\\ngovenment don ' ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: special offers - various\\r\\ntoday ' s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: down . load - dvd , mp 3 , music , pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>Subject: re : basin production from ga 213\\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>Subject: fw : calpine daily gas nomination\\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>Subject: purchase and sale nominations - eastr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>Subject: the houston expl dec 2000\\r\\ndarren :...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>Subject: eastrans nomination change effective ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd4db0b-15f5-4264-83e4-e8fa4d8a1ff5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddd4db0b-15f5-4264-83e4-e8fa4d8a1ff5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddd4db0b-15f5-4264-83e4-e8fa4d8a1ff5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-917e81d8-9f31-4115-a9e7-0160685ce814\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-917e81d8-9f31-4115-a9e7-0160685ce814')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-917e81d8-9f31-4115-a9e7-0160685ce814 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e557a82e-213d-4fc1-84f1-48d60aa715f6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e557a82e-213d-4fc1-84f1-48d60aa715f6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5172,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4994,\n        \"samples\": [\n          \"Subject: dell pentium 4 2 . 8 ghz system\\r\\n$ 585 . 00\\r\\nthis dell system features a powerful\\r\\ncombination with the intel pentium 4 2 . 8 ghz processor\\r\\nand 256 mb ram . a large 40 gb hard disk drive plays host\\r\\nto microsoft windows xp home edition . a cd - rw drive ,\\r\\ndvd - rom drive and a floppy disk drive are all\\r\\npre - installed . integrated graphics and integrated audio\\r\\nare included to get you up and running\\r\\n.\\r\\nprocessor\\r\\nram\\r\\nhdd\\r\\ndrive\\r\\no / s\\r\\nothers\\r\\np 4 2 . 8 ghz\\r\\n256 mb\\r\\n40 gb\\r\\ndvd / cdrw + fdd\\r\\nwinxp home\\r\\nvga + sound\\r\\nvisit : http : / / www . computron - me . com for deals !\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonewww . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact customerservice @ computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\ntel + 971 4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4 8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa - canada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for export only\\r\\n*\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective ownerstoshiba for export\\r\\nonly\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 8 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\",\n          \"Subject: nb real vallum , x . anax , l . evitra . . soma . . much more . . . . . . us p ` harmacies\\r\\nverrotst trapsgewijs wetswijzigingen\\r\\nthe biggest phaermacy store ! save over 80 % ! more than 3 , 000 , 000 satiqsfied\\r\\ncustomers this year !\\r\\norder these pills : ; ^ so + m + a p / n / termin v / a / lium . xan @ x\\r\\nwe ship us international low price , overnite delivery , privacy !\\r\\nq w http : / / vbfd . is . baewo . com / 29 /\\r\\nit was at a five o ' clock tea . a young man came to the hostess to apologize\\r\\nfor his lateness . so good of you to come , mr . jones , and where is your\\r\\nbrother ? you see we ' re very busy in the office and only one of us could\\r\\ncome , so we tossed up for it . how nice ! and so original , too ! and you\\r\\nwon ? no , said the young man absently , i lost !\\r\\na man goes to church and starts talking to god . he says : god , what is a\\r\\nmillion dollars to you ? and god says : a penny , then the man says : god ,\\r\\nwhat is a million years to you ? and god says : a second , then the man\\r\\nsays : god , can i have a penny ? and god says in a second\\r\\ninsatisfecha 3 barbirrucioo 2 lupanaria , manaza marcescente .\\r\\n\",\n          \"Subject: hpl nom for february 3 , 2001\\r\\n( see attached file : hplno 203 . xls )\\r\\n- hplno 203 . xls\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsbz6P6dO6RS"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# TfidfVectorizerを初期化する。stop_wordsにenglishを指定し、一般的な単語を除外する\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\", lowercase=False, max_features=10000)\n",
        "\n",
        "X = tfidf.fit_transform(df['text'])\n",
        "column_names = tfidf.get_feature_names_out()\n",
        "\n",
        "# Xにベクトル化した値を整形して代入\n",
        "X = pd.DataFrame(X.toarray())\n",
        "X = X.astype('float')\n",
        "# カラム名を設定\n",
        "X.columns = column_names\n",
        "y = df['label'].astype('float')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSy_aU8Cixg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e8ad90f8-045a-4b06-d8c8-4c65a95f5ab7"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>000000</th>\n",
              "      <th>000000000002858</th>\n",
              "      <th>000000000049773</th>\n",
              "      <th>000080</th>\n",
              "      <th>000099</th>\n",
              "      <th>0001</th>\n",
              "      <th>00018</th>\n",
              "      <th>00020608</th>\n",
              "      <th>0004</th>\n",
              "      <th>0005</th>\n",
              "      <th>0008</th>\n",
              "      <th>001</th>\n",
              "      <th>0010</th>\n",
              "      <th>001001</th>\n",
              "      <th>0012</th>\n",
              "      <th>001452</th>\n",
              "      <th>002</th>\n",
              "      <th>0022</th>\n",
              "      <th>00221</th>\n",
              "      <th>0025</th>\n",
              "      <th>0027</th>\n",
              "      <th>0028</th>\n",
              "      <th>0029</th>\n",
              "      <th>00298</th>\n",
              "      <th>003</th>\n",
              "      <th>0030</th>\n",
              "      <th>003002</th>\n",
              "      <th>0031</th>\n",
              "      <th>0033</th>\n",
              "      <th>0038</th>\n",
              "      <th>004</th>\n",
              "      <th>0042</th>\n",
              "      <th>0043</th>\n",
              "      <th>0044</th>\n",
              "      <th>0045</th>\n",
              "      <th>0046</th>\n",
              "      <th>0047</th>\n",
              "      <th>...</th>\n",
              "      <th>zv</th>\n",
              "      <th>zve</th>\n",
              "      <th>zvikydqu</th>\n",
              "      <th>zvjc</th>\n",
              "      <th>zvp</th>\n",
              "      <th>zvrkxjmex</th>\n",
              "      <th>zvx</th>\n",
              "      <th>zw</th>\n",
              "      <th>zwallet</th>\n",
              "      <th>zwdm</th>\n",
              "      <th>zwftnqlp</th>\n",
              "      <th>zwiers</th>\n",
              "      <th>zwmdjvr</th>\n",
              "      <th>zwoegen</th>\n",
              "      <th>zwu</th>\n",
              "      <th>zxaghur</th>\n",
              "      <th>zxgwvpiadobe</th>\n",
              "      <th>zxgwvpihere</th>\n",
              "      <th>zxgwvpiimg</th>\n",
              "      <th>zxgwvpimacromedia</th>\n",
              "      <th>zxgwvpimicrosoft</th>\n",
              "      <th>zxgwvpinorton</th>\n",
              "      <th>zxjcxz</th>\n",
              "      <th>zxklh</th>\n",
              "      <th>zxzmcnbf</th>\n",
              "      <th>zyban</th>\n",
              "      <th>zyjvit</th>\n",
              "      <th>zykfe</th>\n",
              "      <th>zyl</th>\n",
              "      <th>zynsdirnh</th>\n",
              "      <th>zynve</th>\n",
              "      <th>zyqtaqlt</th>\n",
              "      <th>zyrtec</th>\n",
              "      <th>zyyqywp</th>\n",
              "      <th>zzezrjok</th>\n",
              "      <th>zzn</th>\n",
              "      <th>zzo</th>\n",
              "      <th>zzocb</th>\n",
              "      <th>zzso</th>\n",
              "      <th>zzsyt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.511833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.180055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>0.049459</td>\n",
              "      <td>0.015846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 50157 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            00       000  0000  000000  ...  zzo  zzocb  zzso  zzsyt\n",
              "0     0.511833  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "1     0.180055  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "2     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "3     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "4     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "...        ...       ...   ...     ...  ...  ...    ...   ...    ...\n",
              "5167  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5168  0.049459  0.015846   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5169  0.000000  0.023266   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5170  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5171  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "\n",
              "[5172 rows x 50157 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna-integration[lightgbm]"
      ],
      "metadata": {
        "id": "MPSxHcqse1Og",
        "outputId": "a9b66356-78ec-4a63-8b38-b4df31df3efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna-integration[lightgbm]\n",
            "  Downloading optuna_integration-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.4.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (1.15.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[lightgbm]) (3.2.3)\n",
            "Downloading optuna_integration-4.4.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM6apRkrlvoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4df6aff-9061-45e1-95a2-ccea7225c9d4"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna.integration.lightgbm as olgb\n",
        "import optuna\n",
        "\n",
        "# データセットを訓練用とテスト用に分割\n",
        "X_train, X_test, y_train, y_test =\\\n",
        " train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "# LightGBM用のデータセットに変換\n",
        "train = olgb.Dataset(X_train, y_train)\n",
        "\n",
        "# パラメータの設定\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "}\n",
        "\n",
        "# 交差検証を使用したハイパーパラメータの探索\n",
        "tuner = olgb.LightGBMTunerCV(params, train, num_boost_round=100)\n",
        "\n",
        "# ハイパーパラメータ探索の実行\n",
        "tuner.run()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-22 09:35:16,469] A new study created in memory with name: no-name-d114bbc5-d02b-4873-a5cf-8bac42ea4e0a\n",
            "feature_fraction, val_score: 0.082816:  14%|#4        | 1/7 [00:21<02:09, 21.52s/it][I 2025-07-22 09:35:38,005] Trial 0 finished with value: 0.08281594958089092 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.08281594958089092.\n",
            "feature_fraction, val_score: 0.076224:  29%|##8       | 2/7 [00:44<01:51, 22.20s/it][I 2025-07-22 09:36:00,690] Trial 1 finished with value: 0.07622352982026406 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.07622352982026406.\n",
            "feature_fraction, val_score: 0.075160:  43%|####2     | 3/7 [01:08<01:32, 23.05s/it][I 2025-07-22 09:36:24,752] Trial 2 finished with value: 0.07516012472625867 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.07516012472625867.\n",
            "feature_fraction, val_score: 0.075160:  57%|#####7    | 4/7 [01:29<01:06, 22.22s/it][I 2025-07-22 09:36:45,696] Trial 3 finished with value: 0.07820574801789187 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.07516012472625867.\n",
            "feature_fraction, val_score: 0.074482:  71%|#######1  | 5/7 [01:51<00:44, 22.22s/it][I 2025-07-22 09:37:07,917] Trial 4 finished with value: 0.0744822125582136 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.0744822125582136.\n",
            "feature_fraction, val_score: 0.074482:  86%|########5 | 6/7 [02:11<00:21, 21.35s/it][I 2025-07-22 09:37:27,590] Trial 5 finished with value: 0.08107131178111271 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.0744822125582136.\n",
            "feature_fraction, val_score: 0.074482: 100%|##########| 7/7 [02:31<00:00, 20.93s/it][I 2025-07-22 09:37:47,634] Trial 6 finished with value: 0.08236479705610483 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.0744822125582136.\n",
            "feature_fraction, val_score: 0.074482: 100%|##########| 7/7 [02:31<00:00, 21.59s/it]\n",
            "num_leaves, val_score: 0.074482:   5%|5         | 1/20 [00:34<10:57, 34.59s/it][I 2025-07-22 09:38:22,242] Trial 7 finished with value: 0.07611778233272418 and parameters: {'num_leaves': 215}. Best is trial 4 with value: 0.0744822125582136.\n",
            "num_leaves, val_score: 0.074482:  10%|#         | 2/20 [01:07<10:05, 33.66s/it][I 2025-07-22 09:38:55,247] Trial 8 finished with value: 0.07611778233272418 and parameters: {'num_leaves': 203}. Best is trial 4 with value: 0.0744822125582136.\n",
            "num_leaves, val_score: 0.074482:  15%|#5        | 3/20 [01:41<09:32, 33.70s/it][I 2025-07-22 09:39:29,002] Trial 9 finished with value: 0.07611778503370233 and parameters: {'num_leaves': 153}. Best is trial 4 with value: 0.0744822125582136.\n",
            "num_leaves, val_score: 0.074482:  20%|##        | 4/20 [01:57<07:07, 26.74s/it][I 2025-07-22 09:39:45,065] Trial 10 finished with value: 0.1277337043096975 and parameters: {'num_leaves': 6}. Best is trial 4 with value: 0.0744822125582136.\n",
            "num_leaves, val_score: 0.073493:  25%|##5       | 5/20 [02:19<06:17, 25.18s/it][I 2025-07-22 09:40:07,487] Trial 11 finished with value: 0.07349253767661759 and parameters: {'num_leaves': 34}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  30%|###       | 6/20 [02:40<05:33, 23.82s/it][I 2025-07-22 09:40:28,650] Trial 12 finished with value: 0.07430463494951353 and parameters: {'num_leaves': 25}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  35%|###5      | 7/20 [02:59<04:48, 22.19s/it][I 2025-07-22 09:40:47,487] Trial 13 finished with value: 0.07884156532868886 and parameters: {'num_leaves': 17}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  40%|####      | 8/20 [03:28<04:50, 24.24s/it][I 2025-07-22 09:41:16,119] Trial 14 finished with value: 0.0758543254670589 and parameters: {'num_leaves': 80}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  45%|####5     | 9/20 [03:56<04:39, 25.38s/it][I 2025-07-22 09:41:44,002] Trial 15 finished with value: 0.07624948658219104 and parameters: {'num_leaves': 82}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  50%|#####     | 10/20 [04:21<04:14, 25.44s/it][I 2025-07-22 09:42:09,584] Trial 16 finished with value: 0.07526524521635633 and parameters: {'num_leaves': 62}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  55%|#####5    | 11/20 [04:46<03:45, 25.03s/it][I 2025-07-22 09:42:33,683] Trial 17 finished with value: 0.07463779550749253 and parameters: {'num_leaves': 47}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  60%|######    | 12/20 [05:19<03:41, 27.69s/it][I 2025-07-22 09:43:07,451] Trial 18 finished with value: 0.07611776097071317 and parameters: {'num_leaves': 128}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073493:  65%|######5   | 13/20 [05:51<03:23, 29.02s/it][I 2025-07-22 09:43:39,535] Trial 19 finished with value: 0.07575388119116933 and parameters: {'num_leaves': 121}. Best is trial 11 with value: 0.07349253767661759.\n",
            "num_leaves, val_score: 0.073094:  70%|#######   | 14/20 [06:14<02:43, 27.20s/it][I 2025-07-22 09:44:02,511] Trial 20 finished with value: 0.07309354827315744 and parameters: {'num_leaves': 40}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094:  75%|#######5  | 15/20 [06:37<02:08, 25.76s/it][I 2025-07-22 09:44:24,931] Trial 21 finished with value: 0.07309376021027272 and parameters: {'num_leaves': 35}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094:  80%|########  | 16/20 [07:01<01:41, 25.32s/it][I 2025-07-22 09:44:49,237] Trial 22 finished with value: 0.07463779550749253 and parameters: {'num_leaves': 47}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094:  85%|########5 | 17/20 [07:31<01:20, 26.83s/it][I 2025-07-22 09:45:19,584] Trial 23 finished with value: 0.07558648057713635 and parameters: {'num_leaves': 103}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094:  90%|######### | 18/20 [07:54<00:51, 25.60s/it][I 2025-07-22 09:45:42,302] Trial 24 finished with value: 0.07444979057762362 and parameters: {'num_leaves': 38}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094:  95%|#########5| 19/20 [08:09<00:22, 22.25s/it][I 2025-07-22 09:45:56,748] Trial 25 finished with value: 0.2679805895042827 and parameters: {'num_leaves': 2}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094: 100%|##########| 20/20 [08:43<00:00, 25.78s/it][I 2025-07-22 09:46:30,755] Trial 26 finished with value: 0.0761177788064217 and parameters: {'num_leaves': 170}. Best is trial 20 with value: 0.07309354827315744.\n",
            "num_leaves, val_score: 0.073094: 100%|##########| 20/20 [08:43<00:00, 26.16s/it]\n",
            "bagging, val_score: 0.073094:  10%|#         | 1/10 [00:23<03:28, 23.20s/it][I 2025-07-22 09:46:53,971] Trial 27 finished with value: 0.08742737667991572 and parameters: {'bagging_fraction': 0.45519356964856955, 'bagging_freq': 4}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  20%|##        | 2/10 [00:46<03:07, 23.40s/it][I 2025-07-22 09:47:17,508] Trial 28 finished with value: 0.07328171069478487 and parameters: {'bagging_fraction': 0.9913985920891426, 'bagging_freq': 1}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  30%|###       | 3/10 [01:10<02:44, 23.44s/it][I 2025-07-22 09:47:40,993] Trial 29 finished with value: 0.0740932364817706 and parameters: {'bagging_fraction': 0.9597057855058059, 'bagging_freq': 1}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  40%|####      | 4/10 [01:34<02:21, 23.58s/it][I 2025-07-22 09:48:04,793] Trial 30 finished with value: 0.07470751837392473 and parameters: {'bagging_fraction': 0.975507897877254, 'bagging_freq': 1}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  50%|#####     | 5/10 [01:57<01:57, 23.50s/it][I 2025-07-22 09:48:28,160] Trial 31 finished with value: 0.07736459700999634 and parameters: {'bagging_fraction': 0.681182916718682, 'bagging_freq': 7}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  60%|######    | 6/10 [02:48<02:11, 32.76s/it][I 2025-07-22 09:49:18,874] Trial 32 finished with value: 0.07313552592294473 and parameters: {'bagging_fraction': 0.7617001030972879, 'bagging_freq': 3}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  70%|#######   | 7/10 [03:18<01:36, 32.11s/it][I 2025-07-22 09:49:49,654] Trial 33 finished with value: 0.07480320663778058 and parameters: {'bagging_fraction': 0.7785046601598901, 'bagging_freq': 3}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  80%|########  | 8/10 [03:54<01:06, 33.35s/it][I 2025-07-22 09:50:25,653] Trial 34 finished with value: 0.07385286492074968 and parameters: {'bagging_fraction': 0.7573618424237858, 'bagging_freq': 2}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094:  90%|######### | 9/10 [04:20<00:31, 31.05s/it][I 2025-07-22 09:50:51,652] Trial 35 finished with value: 0.07890950614560029 and parameters: {'bagging_fraction': 0.5916746593955352, 'bagging_freq': 4}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094: 100%|##########| 10/10 [04:47<00:00, 29.79s/it][I 2025-07-22 09:51:18,630] Trial 36 finished with value: 0.07499025796713138 and parameters: {'bagging_fraction': 0.875136058900337, 'bagging_freq': 6}. Best is trial 20 with value: 0.07309354827315744.\n",
            "bagging, val_score: 0.073094: 100%|##########| 10/10 [04:47<00:00, 28.79s/it]\n",
            "feature_fraction_stage2, val_score: 0.073094:  33%|###3      | 1/3 [00:24<00:49, 24.78s/it][I 2025-07-22 09:51:43,426] Trial 37 finished with value: 0.07460762316997852 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 20 with value: 0.07309354827315744.\n",
            "feature_fraction_stage2, val_score: 0.073094:  67%|######6   | 2/3 [00:50<00:25, 25.09s/it][I 2025-07-22 09:52:08,729] Trial 38 finished with value: 0.07622514533587368 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 20 with value: 0.07309354827315744.\n",
            "feature_fraction_stage2, val_score: 0.073094: 100%|##########| 3/3 [01:13<00:00, 24.33s/it][I 2025-07-22 09:52:32,158] Trial 39 finished with value: 0.07485281106199862 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 20 with value: 0.07309354827315744.\n",
            "feature_fraction_stage2, val_score: 0.073094: 100%|##########| 3/3 [01:13<00:00, 24.51s/it]\n",
            "regularization_factors, val_score: 0.073079:   5%|5         | 1/20 [00:23<07:24, 23.38s/it][I 2025-07-22 09:52:55,559] Trial 40 finished with value: 0.0730788993303298 and parameters: {'lambda_l1': 7.471632835283888e-06, 'lambda_l2': 3.6913572212623507e-05}. Best is trial 40 with value: 0.0730788993303298.\n",
            "regularization_factors, val_score: 0.073079:  10%|#         | 2/20 [00:46<07:01, 23.40s/it][I 2025-07-22 09:53:18,969] Trial 41 finished with value: 0.07307892905324118 and parameters: {'lambda_l1': 4.616204222067442e-06, 'lambda_l2': 4.632774925995958e-05}. Best is trial 40 with value: 0.0730788993303298.\n",
            "regularization_factors, val_score: 0.073079:  15%|#5        | 3/20 [01:10<06:38, 23.44s/it][I 2025-07-22 09:53:42,463] Trial 42 finished with value: 0.07307892083852138 and parameters: {'lambda_l1': 4.019061127249666e-06, 'lambda_l2': 4.509377827424472e-05}. Best is trial 40 with value: 0.0730788993303298.\n",
            "regularization_factors, val_score: 0.073079:  20%|##        | 4/20 [01:34<06:17, 23.59s/it][I 2025-07-22 09:54:06,280] Trial 43 finished with value: 0.07328095243423974 and parameters: {'lambda_l1': 6.758546531766698e-06, 'lambda_l2': 4.8524706835637335e-05}. Best is trial 40 with value: 0.0730788993303298.\n",
            "regularization_factors, val_score: 0.072853:  25%|##5       | 5/20 [01:58<05:56, 23.75s/it][I 2025-07-22 09:54:30,321] Trial 44 finished with value: 0.07285286152099386 and parameters: {'lambda_l1': 8.762717279894856e-06, 'lambda_l2': 3.121304518012025e-05}. Best is trial 44 with value: 0.07285286152099386.\n",
            "regularization_factors, val_score: 0.072853:  30%|###       | 6/20 [02:22<05:33, 23.82s/it][I 2025-07-22 09:54:54,265] Trial 45 finished with value: 0.07285287039631481 and parameters: {'lambda_l1': 4.811757668839254e-06, 'lambda_l2': 3.670455781855565e-05}. Best is trial 44 with value: 0.07285286152099386.\n",
            "regularization_factors, val_score: 0.072853:  35%|###5      | 7/20 [02:45<05:09, 23.79s/it][I 2025-07-22 09:55:18,006] Trial 46 finished with value: 0.07292874154406977 and parameters: {'lambda_l1': 5.010378410823216e-06, 'lambda_l2': 2.0166307518678107e-05}. Best is trial 44 with value: 0.07285286152099386.\n",
            "regularization_factors, val_score: 0.072853:  40%|####      | 8/20 [03:09<04:44, 23.70s/it][I 2025-07-22 09:55:41,513] Trial 47 finished with value: 0.07285282701001225 and parameters: {'lambda_l1': 5.458359694213558e-06, 'lambda_l2': 2.7897763822310828e-05}. Best is trial 47 with value: 0.07285282701001225.\n",
            "regularization_factors, val_score: 0.072853:  45%|####5     | 9/20 [03:32<04:17, 23.42s/it][I 2025-07-22 09:56:04,315] Trial 48 finished with value: 0.0729287568100426 and parameters: {'lambda_l1': 7.097543336389755e-06, 'lambda_l2': 2.1039889344151124e-05}. Best is trial 47 with value: 0.07285282701001225.\n",
            "regularization_factors, val_score: 0.072853:  50%|#####     | 10/20 [03:55<03:53, 23.38s/it][I 2025-07-22 09:56:27,613] Trial 49 finished with value: 0.07292867412903961 and parameters: {'lambda_l1': 4.767495608313443e-06, 'lambda_l2': 8.150384638806321e-06}. Best is trial 47 with value: 0.07285282701001225.\n",
            "regularization_factors, val_score: 0.072853:  55%|#####5    | 11/20 [04:18<03:30, 23.34s/it][I 2025-07-22 09:56:50,846] Trial 50 finished with value: 0.0729542468559714 and parameters: {'lambda_l1': 7.463098740236245e-07, 'lambda_l2': 1.2157096065129278e-07}. Best is trial 47 with value: 0.07285282701001225.\n",
            "regularization_factors, val_score: 0.072853:  60%|######    | 12/20 [04:41<03:06, 23.30s/it][I 2025-07-22 09:57:14,047] Trial 51 finished with value: 0.072928774789606 and parameters: {'lambda_l1': 1.3814382754487515e-05, 'lambda_l2': 1.8182295335285304e-05}. Best is trial 47 with value: 0.07285282701001225.\n",
            "regularization_factors, val_score: 0.072734:  65%|######5   | 13/20 [05:05<02:43, 23.32s/it][I 2025-07-22 09:57:37,418] Trial 52 finished with value: 0.07273430577255767 and parameters: {'lambda_l1': 0.00010957203027680049, 'lambda_l2': 7.5743032068933585e-06}. Best is trial 52 with value: 0.07273430577255767.\n",
            "regularization_factors, val_score: 0.072129:  70%|#######   | 14/20 [05:29<02:20, 23.50s/it][I 2025-07-22 09:58:01,325] Trial 53 finished with value: 0.0721290798642904 and parameters: {'lambda_l1': 0.0003232200506022254, 'lambda_l2': 1.3559942823983291e-06}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129:  75%|#######5  | 15/20 [05:59<02:07, 25.51s/it][I 2025-07-22 09:58:31,507] Trial 54 finished with value: 0.07441237973408374 and parameters: {'lambda_l1': 0.0027548043218171003, 'lambda_l2': 5.219276383911176e-07}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129:  80%|########  | 16/20 [06:22<01:39, 24.82s/it][I 2025-07-22 09:58:54,734] Trial 55 finished with value: 0.07224277244996727 and parameters: {'lambda_l1': 0.0003023706111788904, 'lambda_l2': 1.1163667081414758e-06}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129:  85%|########5 | 17/20 [06:45<01:13, 24.36s/it][I 2025-07-22 09:59:18,023] Trial 56 finished with value: 0.07377757814612769 and parameters: {'lambda_l1': 0.0004218935500892619, 'lambda_l2': 9.884479885044057e-07}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129:  90%|######### | 18/20 [07:09<00:48, 24.09s/it][I 2025-07-22 09:59:41,465] Trial 57 finished with value: 0.07432129744841728 and parameters: {'lambda_l1': 0.00018370256930316683, 'lambda_l2': 0.002702729773918274}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129:  95%|#########5| 19/20 [07:33<00:24, 24.19s/it][I 2025-07-22 10:00:05,883] Trial 58 finished with value: 0.07261350904136832 and parameters: {'lambda_l1': 0.00021689697848116621, 'lambda_l2': 1.2244708995432226e-06}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129: 100%|##########| 20/20 [07:56<00:00, 23.64s/it][I 2025-07-22 10:00:28,259] Trial 59 finished with value: 0.08546729770112298 and parameters: {'lambda_l1': 0.00036571446899535877, 'lambda_l2': 4.159286558099957}. Best is trial 53 with value: 0.0721290798642904.\n",
            "regularization_factors, val_score: 0.072129: 100%|##########| 20/20 [07:56<00:00, 23.80s/it]\n",
            "min_child_samples, val_score: 0.072129:  20%|##        | 1/5 [00:19<01:17, 19.50s/it][I 2025-07-22 10:00:47,774] Trial 60 finished with value: 0.09106325388402307 and parameters: {'min_child_samples': 50}. Best is trial 53 with value: 0.0721290798642904.\n",
            "min_child_samples, val_score: 0.072129:  40%|####      | 2/5 [00:37<00:56, 18.82s/it][I 2025-07-22 10:01:06,125] Trial 61 finished with value: 0.12794044242449354 and parameters: {'min_child_samples': 100}. Best is trial 53 with value: 0.0721290798642904.\n",
            "min_child_samples, val_score: 0.072129:  60%|######    | 3/5 [01:07<00:47, 23.85s/it][I 2025-07-22 10:01:35,964] Trial 62 finished with value: 0.07277682480093366 and parameters: {'min_child_samples': 5}. Best is trial 53 with value: 0.0721290798642904.\n",
            "min_child_samples, val_score: 0.072129:  80%|########  | 4/5 [01:34<00:24, 24.83s/it][I 2025-07-22 10:02:02,285] Trial 63 finished with value: 0.07246421768001929 and parameters: {'min_child_samples': 10}. Best is trial 53 with value: 0.0721290798642904.\n",
            "min_child_samples, val_score: 0.072129: 100%|##########| 5/5 [01:56<00:00, 23.93s/it][I 2025-07-22 10:02:24,634] Trial 64 finished with value: 0.07686253324491846 and parameters: {'min_child_samples': 25}. Best is trial 53 with value: 0.0721290798642904.\n",
            "min_child_samples, val_score: 0.072129: 100%|##########| 5/5 [01:56<00:00, 23.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRzES3x3h39u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3ed3d3-f85d-4609-a759-312b96d35211"
      },
      "source": [
        "print(\"Best score:\", 1 - tuner.best_score)\n",
        "best_params = tuner.best_params\n",
        "\n",
        "print(\"Best Params: \")\n",
        "for key, value in best_params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.9278709201357096\n",
            "Best Params: \n",
            "    objective: binary\n",
            "    verbosity: -1\n",
            "    boosting_type: gbdt\n",
            "    feature_pre_filter: False\n",
            "    lambda_l1: 0.0003232200506022254\n",
            "    lambda_l2: 1.3559942823983291e-06\n",
            "    num_leaves: 40\n",
            "    feature_fraction: 0.4\n",
            "    bagging_fraction: 1.0\n",
            "    bagging_freq: 0\n",
            "    min_child_samples: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrsH156viBTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b5de29-d8d6-45d4-a230-c4e473df885d"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# 訓練データとテストデータを設定\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "# ハイパーパラメータ探索で特定した値を設定\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'lambda_l1': best_params['lambda_l1'],\n",
        "    'lambda_l2': best_params['lambda_l2'],\n",
        "    'num_leaves': best_params['num_leaves'],\n",
        "    'feature_fraction': best_params['feature_fraction'],\n",
        "    'bagging_fraction': best_params['bagging_fraction'],\n",
        "    'bagging_freq': best_params['bagging_freq'],\n",
        "    'min_child_samples': best_params['min_child_samples']\n",
        "}\n",
        "\n",
        "# 訓練の実施\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100\n",
        ")\n",
        "\n",
        "# テスト用データを使って予測する\n",
        "preds = gbm.predict(X_test)\n",
        "# 返り値は確率になっているので四捨五入する\n",
        "pred_labels = np.rint(preds)\n",
        "# 正解率と混同行列の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred_labels)))\n",
        "print(confusion_matrix(y_test, pred_labels))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.55072 %\n",
            "[[726  13]\n",
            " [  2 294]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyVAAWRyjzXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "8cffb3b7-039c-4665-b315-5470199b6aba"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "lgb.plot_importance(gbm, figsize=(12, 6), max_num_features=10)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4xugBNu57WA",
        "outputId": "d533c96d-4550-457d-8c9d-bd3367a2ceeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spam_rows = (df.label == '1')\n",
        "spam_data = df[spam_rows]\n",
        "\n",
        "count = 0\n",
        "for i in spam_data['text']:\n",
        "    count = count + i.count('subject')\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGDnU49e6ji4",
        "outputId": "e8c3737a-6b5e-4885-8498-28c271e2c315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "legit_rows = (df.label == '0')\n",
        "legit_data = df[legit_rows]\n",
        "\n",
        "count = 0\n",
        "for i in legit_data['text']:\n",
        "    count = count + i.count('subject')\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2025/07/22 ここまで。２章の練習問題をやっておく。p39"
      ],
      "metadata": {
        "id": "Ua9b5wVNmzxl"
      }
    }
  ]
}